{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This project is an introduction to deep learning for image classification using [Keras](https://keras.io/) and [Tensorflow](https://www.tensorflow.org/) and the [Sequential API](https://keras.io/guides/sequential_model/). In it, I build and optimize a multi-layer perceptron feed-forward neural network to classify images from the [KMINST](http://codh.rois.ac.jp/kmnist/index.html.en) dataset. Then, I implement a convolutional neural network and optimize its layers and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout, Rescaling\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.optimizers import SGD, RMSprop, Adam\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "from os import cpu_count\n",
    "\n",
    "plt.style.use('seaborn-dark')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download, Load, Visualize, and Reshape the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,) (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.load('data/kmnist-train-imgs.npz')['arr_0']\n",
    "y_train = np.load('data/kmnist-train-labels.npz')['arr_0']\n",
    "X_test = np.load('data/kmnist-test-imgs.npz')['arr_0']\n",
    "y_test = np.load('data/kmnist-test-labels.npz')['arr_0']\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like the [MNIST](https://www.tensorflow.org/datasets/catalog/mnist) dataset, we have 60,000 images in the training set and 10,000 images in the test set. Each image is 28x28 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0 118 255 255 124   1   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  36 238 255 146   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  12 203 255 220  14   0   0   0  11\n",
      "  132  95 187  95   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 149 255 251  66   0   0   0   7 168\n",
      "  136  10 223 245  67   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  51 247 255 156   1   0   0   0 130 201\n",
      "    9   0 158 255 170   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  11 212 255 226  22   0   0   0  79 240  38\n",
      "    0   0 143 255 197   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 148 255 255 107   0   0   0  33 237 121   0\n",
      "    0   0 144 255 222   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 205 255 178   3   0   0   1 179 208   5   0\n",
      "    0   0 126 255 166   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   7 245 255  76   0   0   0 124 254 108   0   0\n",
      "    0   0  91 255 156   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  23 255 239  12   0   0  62 250 225   8   0   0\n",
      "    0   0  78 255 197   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  48 255 192   0   0  16 207 252  84   0   0   0\n",
      "    0   0  81 255 178   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  53 255 148   0   0 133 255 148   0   0   0   0\n",
      "    0   0  73 255 157   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  95 255 143   0 105 252 220  17   0   0   0   0\n",
      "    0   0  79 255  96   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 149 255 121  58 246 254  79   0   0   0   0   7\n",
      "   53   1 102 255 100   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 202 255 213 233 255 186   2   0   0   0   0   0\n",
      "   10  47 132 255  97   0   0   0   0   0]\n",
      " [  0   0   0   0   0  16 246 255 255 255 230  19   0   0   0   0   0   0\n",
      "    0   0 144 255  95   0   0   0   0   0]\n",
      " [  0   0   0   0   0  89 255 255 255 243  71   0   0   0   0   0   0   0\n",
      "    0   0 157 255 105   0   0   0   0   0]\n",
      " [  0   0   0   0   0 192 255 255 254  54   0   0   0   0   0   0   0   0\n",
      "    0   0 189 255 104   0   0   0   0   0]\n",
      " [  0   0   0   0  45 252 255 255 252  28   0   0   0   0   0   0   0   0\n",
      "    0   3 233 255 116   0   0   0   0   0]\n",
      " [  0   0   0   0 161 255 255 255 251  23   0   0   0   0   0   0   0   0\n",
      "    0   1 223 255 178   7   0   0   0   0]\n",
      " [  0   0   0  56 252 255 255 255 249  17   0   0   0   0   0   0   0   0\n",
      "    0   0 159 255 255 181  12   0   0   0]\n",
      " [  0   0   0 180 255 255 255 255 250  18   0   0   0   0   0   0   0   0\n",
      "    0   0  39 245 255 255 177   0   0   0]\n",
      " [  0   0  15 252 255 255 255 255 237   5   0   0   0   0   0   0   0   0\n",
      "    0   0   0  97 253 255 231   0   0   0]\n",
      " [  0   0  17 254 243 224 255 255 239   6   0   0   0   0   0   0   0   0\n",
      "    0   0   0  24 241 255 213   0   0   0]\n",
      " [  0   0   5 150  70 103 255 255 168   0   0   0   0   0   0   0   0   0\n",
      "    0   0  35 222 255 174  21   0   0   0]\n",
      " [  0   0   0   0   0  65 255 254  62   0   0   0   0   0   0   0   0   0\n",
      "    0  59 227 246  93   2   0   0   0   0]\n",
      " [  0   0   0   0   0  30 253 186   2   0   0   0   0   0   0   0   0   0\n",
      "   24 240 240  76   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   8 144  26   0   0   0   0   0   0   0   0   0   0\n",
      "  122 255  90   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, just as in the MNIST dataset, the images are grayscale with a value of 0-255 indicating the darkness of the pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Count')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(y_train)\n",
    "plt.title('Training Labels Histogram', fontsize=20)\n",
    "plt.xlabel('Class', fontsize=15)\n",
    "plt.ylabel('Count', fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our labels are 0-9 and we have a very balanced training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Samples of each class\n",
    "Let's look at several samples of each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [2, 12, 29, 37, 38, 49, 76, 88, 93, 100],\n",
       " 1: [3, 8, 9, 11, 16, 32, 46, 51, 52, 53],\n",
       " 2: [5, 26, 55, 56, 74, 79, 90, 91, 105, 122],\n",
       " 3: [21, 54, 59, 69, 73, 80, 98, 107, 112, 146],\n",
       " 4: [4, 6, 58, 62, 77, 109, 113, 116, 121, 147],\n",
       " 5: [10, 13, 19, 23, 33, 35, 50, 60, 61, 85],\n",
       " 6: [15, 24, 25, 28, 31, 41, 48, 57, 63, 64],\n",
       " 7: [1, 14, 17, 20, 22, 27, 42, 43, 44, 66],\n",
       " 8: [0, 7, 36, 39, 40, 45, 67, 68, 78, 92],\n",
       " 9: [18, 30, 34, 47, 71, 72, 82, 83, 101, 103]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = 10\n",
    "label_sample_indexes = dict()\n",
    "for label in set(y_train):\n",
    "    label_sample_indexes[label] = [i for i,x in enumerate(y_train) if x==label][0:samples]\n",
    "label_sample_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x1440 with 100 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = label_sample_indexes.keys()\n",
    "_, axes = plt.subplots(nrows=len(labels), ncols=samples, figsize=(10, 20))\n",
    "for ax_row, label in zip(axes, labels):\n",
    "    for ax, image in zip(ax_row, X_train[label_sample_indexes[label]]):\n",
    "        ax.set_axis_off()\n",
    "        ax.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "        ax.set_title(f\"Training: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping the Data\n",
    "\n",
    "Here I will flatten the image itself into a 1D array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "train_shape = X_train.shape\n",
    "X_train_flattened = X_train.reshape(train_shape[0], train_shape[1] * train_shape[2])\n",
    "test_shape = X_test.shape\n",
    "X_test_flattened = X_test.reshape(test_shape[0], test_shape[1] * test_shape[2])\n",
    "\n",
    "print(X_train_flattened.shape, X_test_flattened.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average: 0.800933357655329\n",
      "Std dev: 0.9999999999997488\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler(with_mean=False, with_std=True)\n",
    "X_train_scaled = scaler.fit_transform(X_train_flattened)\n",
    "X_test_scaled = scaler.transform(X_test_flattened)\n",
    "print(\"Average:\", np.mean(X_train_scaled[:, 350]))\n",
    "print(\"Std dev:\", np.std(X_train_scaled[:, 350]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with Logistic Regression\n",
    "\n",
    "As in the example, first I'll perform a logistic regression classification to compare, later, with the deep learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 65.45\n",
      "Confusion Matrix:\n",
      "[[666   7  10  49  39  90  10  30  45  54]\n",
      " [  2 660  59  19  24  19  76  13  30  98]\n",
      " [  5  41 583  34  29  25  96  16  52 119]\n",
      " [  2  43  47 751  10  34  37  20  18  38]\n",
      " [ 57  59  43  35 564  15  49  25  27 126]\n",
      " [ 12  43  58  17  17 684  50   6  57  56]\n",
      " [  6  30  93  15  18  13 744  32   7  42]\n",
      " [ 20  38  22  25  86  32  77 510  79 111]\n",
      " [  4  62  57  55   5  29  60  11 654  63]\n",
      " [ 11  63  51   8  47  23  25  12  31 729]]\n"
     ]
    }
   ],
   "source": [
    "sgd = SGDClassifier(loss=\"log\", n_jobs=cpu_count())\n",
    "sgd.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_predicted = sgd.predict(X_test_scaled)\n",
    "\n",
    "acc = 100. * accuracy_score(y_test, y_predicted)\n",
    "cm = confusion_matrix(y_test, y_predicted)\n",
    "\n",
    "print(f\"Accuracy: {acc:.2f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logistic regression performed with an accuracy of about 65%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with Multi-Layer Perceptron\n",
    "\n",
    "For this multiclass classification problem I will choose the [sparse_categorical_crossentropy](https://keras.io/api/losses/probabilistic_losses/#sparsecategoricalcrossentropy-class) for the probabilistic loss function since we have a multiclass problem and our classes are represented as integers (i.e., not one-hot encoded). I'll also begin with the [SGD](https://keras.io/api/optimizers/sgd/) optimizer as I have worked with this the most in class so far.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=2, n_neurons=8, dropout=None, loss='sparse_categorical_crossentropy', optimizer=SGD()):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(28, 28)))\n",
    "    model.add(Rescaling(scale=1./255))\n",
    "    model.add(Flatten())\n",
    "    for hidden_layer in range(n_hidden):\n",
    "        model.add(Dense(n_neurons, activation='relu'))\n",
    "        if dropout:\n",
    "            model.add(Dropout(dropout))\n",
    "    model.add(Dense(len(labels), activation='softmax'))\n",
    "    model.summary()\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_predict(model, batch_size=256, epochs=10):\n",
    "    model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs)\n",
    "    predicted_probabilities = model.predict(X_test)\n",
    "    predicted_classes = np.argmax(predicted_probabilities, axis=1)\n",
    "    acc = 100. * accuracy_score(y_test, predicted_classes)\n",
    "    cm = confusion_matrix(y_test, predicted_classes)\n",
    "\n",
    "    return acc, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling (Rescaling)       (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 8)                 6280      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,442\n",
      "Trainable params: 6,442\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "235/235 [==============================] - 0s 771us/step - loss: 2.1218 - accuracy: 0.2137\n",
      "Epoch 2/10\n",
      "235/235 [==============================] - 0s 767us/step - loss: 1.7675 - accuracy: 0.4309\n",
      "Epoch 3/10\n",
      "235/235 [==============================] - 0s 760us/step - loss: 1.5186 - accuracy: 0.5258\n",
      "Epoch 4/10\n",
      "235/235 [==============================] - 0s 784us/step - loss: 1.3664 - accuracy: 0.5683\n",
      "Epoch 5/10\n",
      "235/235 [==============================] - 0s 771us/step - loss: 1.2622 - accuracy: 0.5939\n",
      "Epoch 6/10\n",
      "235/235 [==============================] - 0s 754us/step - loss: 1.1788 - accuracy: 0.6146\n",
      "Epoch 7/10\n",
      "235/235 [==============================] - 0s 754us/step - loss: 1.1091 - accuracy: 0.6324\n",
      "Epoch 8/10\n",
      "235/235 [==============================] - 0s 754us/step - loss: 1.0506 - accuracy: 0.6509\n",
      "Epoch 9/10\n",
      "235/235 [==============================] - 0s 754us/step - loss: 1.0004 - accuracy: 0.6735\n",
      "Epoch 10/10\n",
      "235/235 [==============================] - 0s 754us/step - loss: 0.9562 - accuracy: 0.6932\n"
     ]
    }
   ],
   "source": [
    "acc, cm = fit_and_predict(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 54.26%\n",
      "Confusion Matrix:\n",
      "[[737   1   1  10  76  59   1  50  35  30]\n",
      " [  7 538 125  10  22   0  98   8 134  58]\n",
      " [  2 135 357  36  54   4 148  69 143  52]\n",
      " [ 10  80  24 662  19  24  15  12 152   2]\n",
      " [ 68  37  94  26 596  10  60  42  30  37]\n",
      " [  7  64  76  16  31 252 262   1 267  24]\n",
      " [  2  50 131   5  95   1 654  26  32   4]\n",
      " [ 14  88 108  11 163   0  12 475  16 113]\n",
      " [ 15 155  31  65  39  63  38   8 561  25]\n",
      " [ 30  93 117   2  86   1  14  48  15 594]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {acc:.2f}%\")\n",
    "print(f\"Confusion Matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_1 (Rescaling)     (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                7850      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "235/235 [==============================] - 0s 750us/step - loss: 1.6741 - accuracy: 0.5051\n",
      "Epoch 2/25\n",
      "235/235 [==============================] - 0s 746us/step - loss: 1.1824 - accuracy: 0.6854\n",
      "Epoch 3/25\n",
      "235/235 [==============================] - 0s 737us/step - loss: 1.0196 - accuracy: 0.7168\n",
      "Epoch 4/25\n",
      "235/235 [==============================] - 0s 746us/step - loss: 0.9323 - accuracy: 0.7398\n",
      "Epoch 5/25\n",
      "235/235 [==============================] - 0s 750us/step - loss: 0.8766 - accuracy: 0.7548\n",
      "Epoch 6/25\n",
      "235/235 [==============================] - 0s 737us/step - loss: 0.8375 - accuracy: 0.7647\n",
      "Epoch 7/25\n",
      "235/235 [==============================] - 0s 742us/step - loss: 0.8083 - accuracy: 0.7713\n",
      "Epoch 8/25\n",
      "235/235 [==============================] - 0s 737us/step - loss: 0.7856 - accuracy: 0.7764\n",
      "Epoch 9/25\n",
      "235/235 [==============================] - 0s 733us/step - loss: 0.7673 - accuracy: 0.7809\n",
      "Epoch 10/25\n",
      "235/235 [==============================] - 0s 742us/step - loss: 0.7522 - accuracy: 0.7844\n",
      "Epoch 11/25\n",
      "235/235 [==============================] - 0s 737us/step - loss: 0.7394 - accuracy: 0.7874\n",
      "Epoch 12/25\n",
      "235/235 [==============================] - 0s 733us/step - loss: 0.7285 - accuracy: 0.7899\n",
      "Epoch 13/25\n",
      "235/235 [==============================] - 0s 733us/step - loss: 0.7190 - accuracy: 0.7918\n",
      "Epoch 14/25\n",
      "235/235 [==============================] - 0s 737us/step - loss: 0.7107 - accuracy: 0.7940\n",
      "Epoch 15/25\n",
      "235/235 [==============================] - 0s 737us/step - loss: 0.7033 - accuracy: 0.7958\n",
      "Epoch 16/25\n",
      "235/235 [==============================] - 0s 750us/step - loss: 0.6966 - accuracy: 0.7972\n",
      "Epoch 17/25\n",
      "235/235 [==============================] - 0s 733us/step - loss: 0.6907 - accuracy: 0.7993\n",
      "Epoch 18/25\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.6853 - accuracy: 0.8008\n",
      "Epoch 19/25\n",
      "235/235 [==============================] - 0s 737us/step - loss: 0.6804 - accuracy: 0.8021\n",
      "Epoch 20/25\n",
      "235/235 [==============================] - 0s 746us/step - loss: 0.6758 - accuracy: 0.8028\n",
      "Epoch 21/25\n",
      "235/235 [==============================] - 0s 737us/step - loss: 0.6717 - accuracy: 0.8043\n",
      "Epoch 22/25\n",
      "235/235 [==============================] - 0s 746us/step - loss: 0.6678 - accuracy: 0.8056\n",
      "Epoch 23/25\n",
      "235/235 [==============================] - 0s 737us/step - loss: 0.6642 - accuracy: 0.8061\n",
      "Epoch 24/25\n",
      "235/235 [==============================] - 0s 737us/step - loss: 0.6609 - accuracy: 0.8069\n",
      "Epoch 25/25\n",
      "235/235 [==============================] - 0s 733us/step - loss: 0.6578 - accuracy: 0.8077\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_2 (Rescaling)     (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                7850      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 0s 759us/step - loss: 1.6894 - accuracy: 0.4947\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 0s 737us/step - loss: 1.1828 - accuracy: 0.6834\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 0s 729us/step - loss: 1.0196 - accuracy: 0.7182\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 0s 733us/step - loss: 0.9329 - accuracy: 0.7385\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 0s 733us/step - loss: 0.8776 - accuracy: 0.7524\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 0s 729us/step - loss: 0.8387 - accuracy: 0.7625\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 0s 737us/step - loss: 0.8096 - accuracy: 0.7700\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 0s 733us/step - loss: 0.7869 - accuracy: 0.7752\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 0s 729us/step - loss: 0.7686 - accuracy: 0.7801\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 0s 733us/step - loss: 0.7535 - accuracy: 0.7833\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 0s 729us/step - loss: 0.7407 - accuracy: 0.7864\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 0s 733us/step - loss: 0.7299 - accuracy: 0.7890\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 0s 742us/step - loss: 0.7204 - accuracy: 0.7911\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 0s 733us/step - loss: 0.7120 - accuracy: 0.7933\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 0s 729us/step - loss: 0.7045 - accuracy: 0.7952\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 0s 733us/step - loss: 0.6980 - accuracy: 0.7965\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 0s 733us/step - loss: 0.6920 - accuracy: 0.7983\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 0s 733us/step - loss: 0.6866 - accuracy: 0.7997\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 0s 742us/step - loss: 0.6816 - accuracy: 0.8010\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 0s 733us/step - loss: 0.6771 - accuracy: 0.8024\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 0s 729us/step - loss: 0.6730 - accuracy: 0.8029\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 0s 737us/step - loss: 0.6691 - accuracy: 0.8044\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 0s 733us/step - loss: 0.6655 - accuracy: 0.8052\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 0s 742us/step - loss: 0.6621 - accuracy: 0.8059\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 0s 737us/step - loss: 0.6590 - accuracy: 0.8069\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 0s 742us/step - loss: 0.6560 - accuracy: 0.8077\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 0s 729us/step - loss: 0.6533 - accuracy: 0.8088\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 0s 733us/step - loss: 0.6507 - accuracy: 0.8096\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 0s 733us/step - loss: 0.6483 - accuracy: 0.8104\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 0s 746us/step - loss: 0.6459 - accuracy: 0.8108\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 0s 733us/step - loss: 0.6437 - accuracy: 0.8116\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.6417 - accuracy: 0.8120\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 0s 742us/step - loss: 0.6396 - accuracy: 0.8124\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 0s 729us/step - loss: 0.6378 - accuracy: 0.8130\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 0s 750us/step - loss: 0.6359 - accuracy: 0.8133\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 0s 746us/step - loss: 0.6341 - accuracy: 0.8140\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 0s 742us/step - loss: 0.6325 - accuracy: 0.8144\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 0s 729us/step - loss: 0.6309 - accuracy: 0.8149\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 0s 733us/step - loss: 0.6294 - accuracy: 0.8158\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 0s 729us/step - loss: 0.6279 - accuracy: 0.8155\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 0s 729us/step - loss: 0.6265 - accuracy: 0.8159\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 0s 737us/step - loss: 0.6252 - accuracy: 0.8164\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 0s 733us/step - loss: 0.6239 - accuracy: 0.8164\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 0s 733us/step - loss: 0.6226 - accuracy: 0.8171\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 0s 733us/step - loss: 0.6214 - accuracy: 0.8173\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 0s 733us/step - loss: 0.6202 - accuracy: 0.8179\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 0s 737us/step - loss: 0.6191 - accuracy: 0.8183\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 0s 742us/step - loss: 0.6180 - accuracy: 0.8185\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 0s 733us/step - loss: 0.6169 - accuracy: 0.8185\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 0s 729us/step - loss: 0.6159 - accuracy: 0.8190\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_3 (Rescaling)     (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                7850      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.9367 - accuracy: 0.7334\n",
      "Epoch 2/25\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.6527 - accuracy: 0.8083\n",
      "Epoch 3/25\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.6177 - accuracy: 0.8181\n",
      "Epoch 4/25\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.6019 - accuracy: 0.8230\n",
      "Epoch 5/25\n",
      "235/235 [==============================] - 0s 754us/step - loss: 0.5924 - accuracy: 0.8258\n",
      "Epoch 6/25\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5856 - accuracy: 0.8295\n",
      "Epoch 7/25\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5806 - accuracy: 0.8288\n",
      "Epoch 8/25\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5767 - accuracy: 0.8303\n",
      "Epoch 9/25\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5729 - accuracy: 0.8321\n",
      "Epoch 10/25\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5700 - accuracy: 0.8326\n",
      "Epoch 11/25\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5673 - accuracy: 0.8338\n",
      "Epoch 12/25\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5649 - accuracy: 0.8350\n",
      "Epoch 13/25\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5632 - accuracy: 0.8346\n",
      "Epoch 14/25\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5612 - accuracy: 0.8353\n",
      "Epoch 15/25\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5595 - accuracy: 0.8355\n",
      "Epoch 16/25\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5581 - accuracy: 0.8372\n",
      "Epoch 17/25\n",
      "235/235 [==============================] - 0s 754us/step - loss: 0.5565 - accuracy: 0.8370\n",
      "Epoch 18/25\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5549 - accuracy: 0.8371\n",
      "Epoch 19/25\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5539 - accuracy: 0.8375\n",
      "Epoch 20/25\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5528 - accuracy: 0.8377\n",
      "Epoch 21/25\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5516 - accuracy: 0.8377\n",
      "Epoch 22/25\n",
      "235/235 [==============================] - 0s 793us/step - loss: 0.5504 - accuracy: 0.8383\n",
      "Epoch 23/25\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5497 - accuracy: 0.8386\n",
      "Epoch 24/25\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5488 - accuracy: 0.8392\n",
      "Epoch 25/25\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5476 - accuracy: 0.8391\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_4 (Rescaling)     (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 10)                7850      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.9547 - accuracy: 0.7282\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.6535 - accuracy: 0.8082\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 0s 793us/step - loss: 0.6179 - accuracy: 0.8184\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 0s 754us/step - loss: 0.6021 - accuracy: 0.8223\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 0s 754us/step - loss: 0.5926 - accuracy: 0.8266\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 0s 754us/step - loss: 0.5860 - accuracy: 0.8278\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5805 - accuracy: 0.8298\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 0s 768us/step - loss: 0.5765 - accuracy: 0.8311\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5729 - accuracy: 0.8319\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5697 - accuracy: 0.8327\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5669 - accuracy: 0.8346\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5654 - accuracy: 0.8344\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5633 - accuracy: 0.8363\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5611 - accuracy: 0.8355\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5593 - accuracy: 0.8364\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5576 - accuracy: 0.8369\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5562 - accuracy: 0.8370\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5553 - accuracy: 0.8376\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5541 - accuracy: 0.8375\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5528 - accuracy: 0.8380\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5519 - accuracy: 0.8377\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5507 - accuracy: 0.8388\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5501 - accuracy: 0.8385\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5490 - accuracy: 0.8389\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5483 - accuracy: 0.8391\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5473 - accuracy: 0.8395\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5468 - accuracy: 0.8393\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5459 - accuracy: 0.8397\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5450 - accuracy: 0.8400\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5443 - accuracy: 0.8406\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5442 - accuracy: 0.8403\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5429 - accuracy: 0.8401\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5425 - accuracy: 0.8413\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5422 - accuracy: 0.8407\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5416 - accuracy: 0.8407\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5407 - accuracy: 0.8408\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 0s 806us/step - loss: 0.5406 - accuracy: 0.8402\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5400 - accuracy: 0.8405\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5399 - accuracy: 0.8411\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5395 - accuracy: 0.8410\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5391 - accuracy: 0.8419\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5385 - accuracy: 0.8422\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5380 - accuracy: 0.8416\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5375 - accuracy: 0.8412\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5372 - accuracy: 0.8417\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5368 - accuracy: 0.8423\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5368 - accuracy: 0.8418\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5364 - accuracy: 0.8423\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5357 - accuracy: 0.8419\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5358 - accuracy: 0.8429\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_5 (Rescaling)     (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 10)                7850      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "235/235 [==============================] - 0s 767us/step - loss: 1.0112 - accuracy: 0.7091\n",
      "Epoch 2/25\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.6799 - accuracy: 0.8032\n",
      "Epoch 3/25\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.6326 - accuracy: 0.8146\n",
      "Epoch 4/25\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.6115 - accuracy: 0.8208\n",
      "Epoch 5/25\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5990 - accuracy: 0.8230\n",
      "Epoch 6/25\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5905 - accuracy: 0.8270\n",
      "Epoch 7/25\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5839 - accuracy: 0.8289\n",
      "Epoch 8/25\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5791 - accuracy: 0.8298\n",
      "Epoch 9/25\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5745 - accuracy: 0.8321\n",
      "Epoch 10/25\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5721 - accuracy: 0.8321\n",
      "Epoch 11/25\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5690 - accuracy: 0.8329\n",
      "Epoch 12/25\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5658 - accuracy: 0.8339\n",
      "Epoch 13/25\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5635 - accuracy: 0.8345\n",
      "Epoch 14/25\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5619 - accuracy: 0.8350\n",
      "Epoch 15/25\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5593 - accuracy: 0.8360\n",
      "Epoch 16/25\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5584 - accuracy: 0.8367\n",
      "Epoch 17/25\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5562 - accuracy: 0.8363\n",
      "Epoch 18/25\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5547 - accuracy: 0.8364\n",
      "Epoch 19/25\n",
      "235/235 [==============================] - 0s 780us/step - loss: 0.5533 - accuracy: 0.8374\n",
      "Epoch 20/25\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5522 - accuracy: 0.8373\n",
      "Epoch 21/25\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5507 - accuracy: 0.8390\n",
      "Epoch 22/25\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5499 - accuracy: 0.8382\n",
      "Epoch 23/25\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5487 - accuracy: 0.8390\n",
      "Epoch 24/25\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5478 - accuracy: 0.8393\n",
      "Epoch 25/25\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5472 - accuracy: 0.8386\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_6 (Rescaling)     (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                7850      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.7389 - accuracy: 0.7798\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.6108 - accuracy: 0.8206\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5936 - accuracy: 0.8253\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5845 - accuracy: 0.8291\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5784 - accuracy: 0.8299\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5742 - accuracy: 0.8314\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5696 - accuracy: 0.8327\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5674 - accuracy: 0.8332\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5643 - accuracy: 0.8339\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5613 - accuracy: 0.8353\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5600 - accuracy: 0.8357\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5580 - accuracy: 0.8358\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5561 - accuracy: 0.8365\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5551 - accuracy: 0.8368\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5533 - accuracy: 0.8369\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5522 - accuracy: 0.8380\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5507 - accuracy: 0.8378\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5498 - accuracy: 0.8382\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5491 - accuracy: 0.8377\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5476 - accuracy: 0.8389\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5466 - accuracy: 0.8388\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5462 - accuracy: 0.8392\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5452 - accuracy: 0.8391\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5443 - accuracy: 0.8399\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5436 - accuracy: 0.8405\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5429 - accuracy: 0.8398\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5423 - accuracy: 0.8395\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5418 - accuracy: 0.8399\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5405 - accuracy: 0.8400\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5403 - accuracy: 0.8398\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5400 - accuracy: 0.8402\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5391 - accuracy: 0.8414\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5393 - accuracy: 0.8401\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5382 - accuracy: 0.8399\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5377 - accuracy: 0.8405\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5374 - accuracy: 0.8410\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5367 - accuracy: 0.8401\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5366 - accuracy: 0.8416\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5360 - accuracy: 0.8416\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5353 - accuracy: 0.8411\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5353 - accuracy: 0.8413\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 0s 801us/step - loss: 0.5354 - accuracy: 0.8406\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5346 - accuracy: 0.8418\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 0s 784us/step - loss: 0.5345 - accuracy: 0.8417\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5339 - accuracy: 0.8414\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 0s 773us/step - loss: 0.5336 - accuracy: 0.8414\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5327 - accuracy: 0.8413\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5329 - accuracy: 0.8418\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5326 - accuracy: 0.8424\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5320 - accuracy: 0.8425\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_7 (Rescaling)     (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 10)                7850      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "235/235 [==============================] - 0s 742us/step - loss: 1.6762 - accuracy: 0.4979\n",
      "Epoch 2/25\n",
      "235/235 [==============================] - 0s 737us/step - loss: 1.1941 - accuracy: 0.6793\n",
      "Epoch 3/25\n",
      "235/235 [==============================] - 0s 763us/step - loss: 1.0296 - accuracy: 0.7136\n",
      "Epoch 4/25\n",
      "235/235 [==============================] - 0s 737us/step - loss: 0.9405 - accuracy: 0.7360\n",
      "Epoch 5/25\n",
      "235/235 [==============================] - 0s 737us/step - loss: 0.8832 - accuracy: 0.7511\n",
      "Epoch 6/25\n",
      "235/235 [==============================] - 0s 737us/step - loss: 0.8429 - accuracy: 0.7614\n",
      "Epoch 7/25\n",
      "235/235 [==============================] - 0s 733us/step - loss: 0.8129 - accuracy: 0.7692\n",
      "Epoch 8/25\n",
      "235/235 [==============================] - 0s 739us/step - loss: 0.7896 - accuracy: 0.7746\n",
      "Epoch 9/25\n",
      "235/235 [==============================] - 0s 737us/step - loss: 0.7708 - accuracy: 0.7785\n",
      "Epoch 10/25\n",
      "235/235 [==============================] - 0s 737us/step - loss: 0.7552 - accuracy: 0.7831\n",
      "Epoch 11/25\n",
      "235/235 [==============================] - 0s 737us/step - loss: 0.7422 - accuracy: 0.7860\n",
      "Epoch 12/25\n",
      "235/235 [==============================] - 0s 737us/step - loss: 0.7311 - accuracy: 0.7886\n",
      "Epoch 13/25\n",
      "235/235 [==============================] - 0s 742us/step - loss: 0.7214 - accuracy: 0.7908\n",
      "Epoch 14/25\n",
      "235/235 [==============================] - 0s 746us/step - loss: 0.7129 - accuracy: 0.7930\n",
      "Epoch 15/25\n",
      "235/235 [==============================] - 0s 737us/step - loss: 0.7054 - accuracy: 0.7950\n",
      "Epoch 16/25\n",
      "235/235 [==============================] - 0s 742us/step - loss: 0.6987 - accuracy: 0.7968\n",
      "Epoch 17/25\n",
      "235/235 [==============================] - 0s 742us/step - loss: 0.6926 - accuracy: 0.7983\n",
      "Epoch 18/25\n",
      "235/235 [==============================] - 0s 733us/step - loss: 0.6870 - accuracy: 0.7997\n",
      "Epoch 19/25\n",
      "235/235 [==============================] - 0s 737us/step - loss: 0.6821 - accuracy: 0.8011\n",
      "Epoch 20/25\n",
      "235/235 [==============================] - 0s 746us/step - loss: 0.6775 - accuracy: 0.8026\n",
      "Epoch 21/25\n",
      "235/235 [==============================] - 0s 733us/step - loss: 0.6733 - accuracy: 0.8033\n",
      "Epoch 22/25\n",
      "235/235 [==============================] - 0s 737us/step - loss: 0.6693 - accuracy: 0.8040\n",
      "Epoch 23/25\n",
      "235/235 [==============================] - 0s 737us/step - loss: 0.6657 - accuracy: 0.8053\n",
      "Epoch 24/25\n",
      "235/235 [==============================] - 0s 733us/step - loss: 0.6623 - accuracy: 0.8063\n",
      "Epoch 25/25\n",
      "235/235 [==============================] - 0s 737us/step - loss: 0.6592 - accuracy: 0.8069\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_8 (Rescaling)     (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 10)                7850      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 0s 737us/step - loss: 1.6905 - accuracy: 0.5075\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 0s 742us/step - loss: 1.1843 - accuracy: 0.6884\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 0s 729us/step - loss: 1.0217 - accuracy: 0.7196\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 0s 733us/step - loss: 0.9351 - accuracy: 0.7394\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 0s 784us/step - loss: 0.8796 - accuracy: 0.7529\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 0s 737us/step - loss: 0.8405 - accuracy: 0.7625\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 0s 733us/step - loss: 0.8112 - accuracy: 0.7707\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 0s 737us/step - loss: 0.7883 - accuracy: 0.7758\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 0s 737us/step - loss: 0.7698 - accuracy: 0.7802\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 0s 733us/step - loss: 0.7546 - accuracy: 0.7839\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 0s 742us/step - loss: 0.7417 - accuracy: 0.7873\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 0s 746us/step - loss: 0.7307 - accuracy: 0.7896\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 0s 742us/step - loss: 0.7211 - accuracy: 0.7913\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 0s 729us/step - loss: 0.7126 - accuracy: 0.7933\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 0s 733us/step - loss: 0.7052 - accuracy: 0.7952\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 0s 737us/step - loss: 0.6985 - accuracy: 0.7974\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 0s 742us/step - loss: 0.6924 - accuracy: 0.7988\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 0s 733us/step - loss: 0.6870 - accuracy: 0.7997\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 0s 750us/step - loss: 0.6820 - accuracy: 0.8010\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 0s 733us/step - loss: 0.6774 - accuracy: 0.8021\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 0s 742us/step - loss: 0.6732 - accuracy: 0.8031\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 0s 733us/step - loss: 0.6693 - accuracy: 0.8044\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 0s 746us/step - loss: 0.6656 - accuracy: 0.8052\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 0s 742us/step - loss: 0.6623 - accuracy: 0.8063\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 0s 733us/step - loss: 0.6591 - accuracy: 0.8073\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 0s 733us/step - loss: 0.6561 - accuracy: 0.8080\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 0s 733us/step - loss: 0.6534 - accuracy: 0.8089\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 0s 733us/step - loss: 0.6508 - accuracy: 0.8097\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 0s 746us/step - loss: 0.6483 - accuracy: 0.8103\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 0s 733us/step - loss: 0.6459 - accuracy: 0.8109\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 0s 729us/step - loss: 0.6437 - accuracy: 0.8112\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 0s 733us/step - loss: 0.6416 - accuracy: 0.8123\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 0s 742us/step - loss: 0.6396 - accuracy: 0.8123\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 0s 737us/step - loss: 0.6377 - accuracy: 0.8130\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 0s 746us/step - loss: 0.6359 - accuracy: 0.8135\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 0s 737us/step - loss: 0.6341 - accuracy: 0.8140\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 0s 737us/step - loss: 0.6324 - accuracy: 0.8142\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 0s 733us/step - loss: 0.6309 - accuracy: 0.8150\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 0s 733us/step - loss: 0.6293 - accuracy: 0.8153\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 0s 737us/step - loss: 0.6278 - accuracy: 0.8156\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.6264 - accuracy: 0.8162\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 0s 737us/step - loss: 0.6250 - accuracy: 0.8165\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 0s 733us/step - loss: 0.6237 - accuracy: 0.8168\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 0s 742us/step - loss: 0.6225 - accuracy: 0.8170\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 0s 733us/step - loss: 0.6212 - accuracy: 0.8176\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 0s 780us/step - loss: 0.6200 - accuracy: 0.8179\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 0s 733us/step - loss: 0.6189 - accuracy: 0.8185\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 0s 729us/step - loss: 0.6178 - accuracy: 0.8184\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 0s 729us/step - loss: 0.6167 - accuracy: 0.8188\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 0s 729us/step - loss: 0.6156 - accuracy: 0.8190\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_9 (Rescaling)     (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 10)                7850      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.9562 - accuracy: 0.7268\n",
      "Epoch 2/25\n",
      "235/235 [==============================] - 0s 754us/step - loss: 0.6553 - accuracy: 0.8070\n",
      "Epoch 3/25\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.6188 - accuracy: 0.8183\n",
      "Epoch 4/25\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.6029 - accuracy: 0.8217\n",
      "Epoch 5/25\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5930 - accuracy: 0.8256\n",
      "Epoch 6/25\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5862 - accuracy: 0.8285\n",
      "Epoch 7/25\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5806 - accuracy: 0.8296\n",
      "Epoch 8/25\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5768 - accuracy: 0.8313\n",
      "Epoch 9/25\n",
      "235/235 [==============================] - 0s 754us/step - loss: 0.5730 - accuracy: 0.8325\n",
      "Epoch 10/25\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5704 - accuracy: 0.8325\n",
      "Epoch 11/25\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5676 - accuracy: 0.8340\n",
      "Epoch 12/25\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5654 - accuracy: 0.8343\n",
      "Epoch 13/25\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5634 - accuracy: 0.8350\n",
      "Epoch 14/25\n",
      "235/235 [==============================] - 0s 754us/step - loss: 0.5614 - accuracy: 0.8357\n",
      "Epoch 15/25\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5596 - accuracy: 0.8363\n",
      "Epoch 16/25\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5581 - accuracy: 0.8365\n",
      "Epoch 17/25\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5565 - accuracy: 0.8367\n",
      "Epoch 18/25\n",
      "235/235 [==============================] - 0s 754us/step - loss: 0.5548 - accuracy: 0.8381\n",
      "Epoch 19/25\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5542 - accuracy: 0.8370\n",
      "Epoch 20/25\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5530 - accuracy: 0.8377\n",
      "Epoch 21/25\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5518 - accuracy: 0.8377\n",
      "Epoch 22/25\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5506 - accuracy: 0.8381\n",
      "Epoch 23/25\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5497 - accuracy: 0.8381\n",
      "Epoch 24/25\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5485 - accuracy: 0.8397\n",
      "Epoch 25/25\n",
      "235/235 [==============================] - 0s 754us/step - loss: 0.5482 - accuracy: 0.8396\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_10 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 10)                7850      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.9353 - accuracy: 0.7339\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.6538 - accuracy: 0.8077\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.6175 - accuracy: 0.8179\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.6014 - accuracy: 0.8240\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5923 - accuracy: 0.8260\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5854 - accuracy: 0.8287\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5801 - accuracy: 0.8299\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5767 - accuracy: 0.8313\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5729 - accuracy: 0.8329\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 0s 797us/step - loss: 0.5701 - accuracy: 0.8324\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5675 - accuracy: 0.8341\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5649 - accuracy: 0.8353\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5628 - accuracy: 0.8354\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5612 - accuracy: 0.8357\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5596 - accuracy: 0.8362\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5579 - accuracy: 0.8367\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5562 - accuracy: 0.8365\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5554 - accuracy: 0.8371\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5536 - accuracy: 0.8375\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5525 - accuracy: 0.8379\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5517 - accuracy: 0.8386\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5505 - accuracy: 0.8386\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5496 - accuracy: 0.8380\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5486 - accuracy: 0.8393\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5480 - accuracy: 0.8397\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5469 - accuracy: 0.8385\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5464 - accuracy: 0.8392\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5457 - accuracy: 0.8399\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5447 - accuracy: 0.8397\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5444 - accuracy: 0.8398\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5437 - accuracy: 0.8399\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5431 - accuracy: 0.8403\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 0s 754us/step - loss: 0.5425 - accuracy: 0.8414\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5422 - accuracy: 0.8401\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5416 - accuracy: 0.8409\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5409 - accuracy: 0.8412\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5401 - accuracy: 0.8415\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5400 - accuracy: 0.8409\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5399 - accuracy: 0.8413\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5394 - accuracy: 0.8411\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5387 - accuracy: 0.8417\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5384 - accuracy: 0.8417\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 0s 754us/step - loss: 0.5380 - accuracy: 0.8412\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5378 - accuracy: 0.8418\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 0s 760us/step - loss: 0.5372 - accuracy: 0.8424\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5370 - accuracy: 0.8412\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5368 - accuracy: 0.8421\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5364 - accuracy: 0.8423\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5361 - accuracy: 0.8417\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5355 - accuracy: 0.8414\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_11 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_11 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 10)                7850      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "235/235 [==============================] - 0s 784us/step - loss: 0.7225 - accuracy: 0.7834\n",
      "Epoch 2/25\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.6080 - accuracy: 0.8214\n",
      "Epoch 3/25\n",
      "235/235 [==============================] - 0s 780us/step - loss: 0.5916 - accuracy: 0.8262\n",
      "Epoch 4/25\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5829 - accuracy: 0.8299\n",
      "Epoch 5/25\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5766 - accuracy: 0.8319\n",
      "Epoch 6/25\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5729 - accuracy: 0.8316\n",
      "Epoch 7/25\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5689 - accuracy: 0.8330\n",
      "Epoch 8/25\n",
      "235/235 [==============================] - 0s 768us/step - loss: 0.5663 - accuracy: 0.8340\n",
      "Epoch 9/25\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5633 - accuracy: 0.8354\n",
      "Epoch 10/25\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5609 - accuracy: 0.8356\n",
      "Epoch 11/25\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5587 - accuracy: 0.8357\n",
      "Epoch 12/25\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5574 - accuracy: 0.8358\n",
      "Epoch 13/25\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5553 - accuracy: 0.8373\n",
      "Epoch 14/25\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5541 - accuracy: 0.8367\n",
      "Epoch 15/25\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5528 - accuracy: 0.8371\n",
      "Epoch 16/25\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5514 - accuracy: 0.8386\n",
      "Epoch 17/25\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5504 - accuracy: 0.8377\n",
      "Epoch 18/25\n",
      "235/235 [==============================] - 0s 788us/step - loss: 0.5495 - accuracy: 0.8386\n",
      "Epoch 19/25\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5483 - accuracy: 0.8386\n",
      "Epoch 20/25\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5474 - accuracy: 0.8391\n",
      "Epoch 21/25\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5462 - accuracy: 0.8393\n",
      "Epoch 22/25\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5455 - accuracy: 0.8397\n",
      "Epoch 23/25\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5447 - accuracy: 0.8397\n",
      "Epoch 24/25\n",
      "235/235 [==============================] - 0s 784us/step - loss: 0.5441 - accuracy: 0.8397\n",
      "Epoch 25/25\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5428 - accuracy: 0.8398\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_12 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_12 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 10)                7850      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 0s 801us/step - loss: 0.7273 - accuracy: 0.7827\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 0s 793us/step - loss: 0.6087 - accuracy: 0.8195\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 0s 793us/step - loss: 0.5926 - accuracy: 0.8251\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 0s 806us/step - loss: 0.5840 - accuracy: 0.8294\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 0s 793us/step - loss: 0.5780 - accuracy: 0.8310\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 0s 793us/step - loss: 0.5730 - accuracy: 0.8323\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 0s 797us/step - loss: 0.5696 - accuracy: 0.8327\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 0s 793us/step - loss: 0.5661 - accuracy: 0.8345\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 0s 797us/step - loss: 0.5636 - accuracy: 0.8345\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 0s 793us/step - loss: 0.5613 - accuracy: 0.8352\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 0s 797us/step - loss: 0.5595 - accuracy: 0.8353\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 0s 801us/step - loss: 0.5580 - accuracy: 0.8362\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 0s 788us/step - loss: 0.5554 - accuracy: 0.8375\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 0s 788us/step - loss: 0.5545 - accuracy: 0.8370\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 0s 827us/step - loss: 0.5528 - accuracy: 0.8371\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 0s 793us/step - loss: 0.5519 - accuracy: 0.8377\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 0s 788us/step - loss: 0.5505 - accuracy: 0.8381\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 0s 801us/step - loss: 0.5493 - accuracy: 0.8388\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 0s 793us/step - loss: 0.5482 - accuracy: 0.8391\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 0s 793us/step - loss: 0.5469 - accuracy: 0.8390\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 0s 788us/step - loss: 0.5460 - accuracy: 0.8390\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 0s 784us/step - loss: 0.5460 - accuracy: 0.8385\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 0s 810us/step - loss: 0.5443 - accuracy: 0.8393\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 0s 788us/step - loss: 0.5442 - accuracy: 0.8393\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 0s 788us/step - loss: 0.5436 - accuracy: 0.8400\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 0s 793us/step - loss: 0.5426 - accuracy: 0.8400\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 0s 788us/step - loss: 0.5420 - accuracy: 0.8403\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 0s 788us/step - loss: 0.5414 - accuracy: 0.8400\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 0s 806us/step - loss: 0.5409 - accuracy: 0.8402\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 0s 793us/step - loss: 0.5405 - accuracy: 0.8400\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 0s 797us/step - loss: 0.5397 - accuracy: 0.8412\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 0s 793us/step - loss: 0.5392 - accuracy: 0.8407\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 0s 788us/step - loss: 0.5388 - accuracy: 0.8402\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 0s 806us/step - loss: 0.5379 - accuracy: 0.8408\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 0s 793us/step - loss: 0.5381 - accuracy: 0.8414\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 0s 793us/step - loss: 0.5369 - accuracy: 0.8410\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 0s 788us/step - loss: 0.5370 - accuracy: 0.8413\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 0s 793us/step - loss: 0.5364 - accuracy: 0.8407\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 0s 806us/step - loss: 0.5357 - accuracy: 0.8408\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 0s 797us/step - loss: 0.5356 - accuracy: 0.8418\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 0s 793us/step - loss: 0.5356 - accuracy: 0.8421\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 0s 793us/step - loss: 0.5351 - accuracy: 0.8419\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 0s 790us/step - loss: 0.5346 - accuracy: 0.8421\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 0s 788us/step - loss: 0.5343 - accuracy: 0.8417\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 0s 801us/step - loss: 0.5343 - accuracy: 0.8421\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 0s 797us/step - loss: 0.5337 - accuracy: 0.8423\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 0s 788us/step - loss: 0.5334 - accuracy: 0.8419\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 0s 793us/step - loss: 0.5330 - accuracy: 0.8418\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 0s 797us/step - loss: 0.5326 - accuracy: 0.8422\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 0s 797us/step - loss: 0.5323 - accuracy: 0.8419\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_13 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_13 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 10)                7850      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "235/235 [==============================] - 0s 793us/step - loss: 1.7122 - accuracy: 0.5007\n",
      "Epoch 2/25\n",
      "235/235 [==============================] - 0s 759us/step - loss: 1.1961 - accuracy: 0.6816\n",
      "Epoch 3/25\n",
      "235/235 [==============================] - 0s 750us/step - loss: 1.0307 - accuracy: 0.7143\n",
      "Epoch 4/25\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.9420 - accuracy: 0.7353\n",
      "Epoch 5/25\n",
      "235/235 [==============================] - 0s 754us/step - loss: 0.8851 - accuracy: 0.7502\n",
      "Epoch 6/25\n",
      "235/235 [==============================] - 0s 750us/step - loss: 0.8451 - accuracy: 0.7605\n",
      "Epoch 7/25\n",
      "235/235 [==============================] - 0s 750us/step - loss: 0.8152 - accuracy: 0.7678\n",
      "Epoch 8/25\n",
      "235/235 [==============================] - 0s 746us/step - loss: 0.7918 - accuracy: 0.7735\n",
      "Epoch 9/25\n",
      "235/235 [==============================] - 0s 750us/step - loss: 0.7730 - accuracy: 0.7782\n",
      "Epoch 10/25\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.7574 - accuracy: 0.7821\n",
      "Epoch 11/25\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.7443 - accuracy: 0.7856\n",
      "Epoch 12/25\n",
      "235/235 [==============================] - 0s 754us/step - loss: 0.7331 - accuracy: 0.7888\n",
      "Epoch 13/25\n",
      "235/235 [==============================] - 0s 750us/step - loss: 0.7233 - accuracy: 0.7912\n",
      "Epoch 14/25\n",
      "235/235 [==============================] - 0s 750us/step - loss: 0.7148 - accuracy: 0.7935\n",
      "Epoch 15/25\n",
      "235/235 [==============================] - 0s 750us/step - loss: 0.7072 - accuracy: 0.7953\n",
      "Epoch 16/25\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.7004 - accuracy: 0.7967\n",
      "Epoch 17/25\n",
      "235/235 [==============================] - 0s 750us/step - loss: 0.6942 - accuracy: 0.7981\n",
      "Epoch 18/25\n",
      "235/235 [==============================] - 0s 754us/step - loss: 0.6886 - accuracy: 0.7995\n",
      "Epoch 19/25\n",
      "235/235 [==============================] - 0s 750us/step - loss: 0.6836 - accuracy: 0.8014\n",
      "Epoch 20/25\n",
      "235/235 [==============================] - 0s 746us/step - loss: 0.6789 - accuracy: 0.8025\n",
      "Epoch 21/25\n",
      "235/235 [==============================] - 0s 750us/step - loss: 0.6746 - accuracy: 0.8031\n",
      "Epoch 22/25\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.6707 - accuracy: 0.8041\n",
      "Epoch 23/25\n",
      "235/235 [==============================] - 0s 750us/step - loss: 0.6670 - accuracy: 0.8051\n",
      "Epoch 24/25\n",
      "235/235 [==============================] - 0s 750us/step - loss: 0.6635 - accuracy: 0.8060\n",
      "Epoch 25/25\n",
      "235/235 [==============================] - 0s 746us/step - loss: 0.6603 - accuracy: 0.8067\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_14 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_14 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 10)                7850      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 1.6804 - accuracy: 0.5111\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 1.1901 - accuracy: 0.6877\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 0s 802us/step - loss: 1.0270 - accuracy: 0.7183\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 0s 750us/step - loss: 0.9395 - accuracy: 0.7372\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 0s 750us/step - loss: 0.8834 - accuracy: 0.7513\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.8438 - accuracy: 0.7617\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 0s 754us/step - loss: 0.8141 - accuracy: 0.7693\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 0s 751us/step - loss: 0.7911 - accuracy: 0.7745\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 0s 750us/step - loss: 0.7723 - accuracy: 0.7799\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 0s 754us/step - loss: 0.7569 - accuracy: 0.7834\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 0s 754us/step - loss: 0.7439 - accuracy: 0.7865\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.7327 - accuracy: 0.7894\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 0s 754us/step - loss: 0.7230 - accuracy: 0.7915\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 0s 750us/step - loss: 0.7145 - accuracy: 0.7933\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 0s 750us/step - loss: 0.7069 - accuracy: 0.7953\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 0s 746us/step - loss: 0.7001 - accuracy: 0.7968\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 0s 750us/step - loss: 0.6941 - accuracy: 0.7980\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.6885 - accuracy: 0.7994\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 0s 754us/step - loss: 0.6835 - accuracy: 0.8009\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 0s 750us/step - loss: 0.6789 - accuracy: 0.8017\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 0s 746us/step - loss: 0.6746 - accuracy: 0.8026\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 0s 746us/step - loss: 0.6707 - accuracy: 0.8038\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 0s 754us/step - loss: 0.6669 - accuracy: 0.8046\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.6636 - accuracy: 0.8057\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 0s 750us/step - loss: 0.6603 - accuracy: 0.8065\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.6573 - accuracy: 0.8072\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 0s 754us/step - loss: 0.6545 - accuracy: 0.8081\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 0s 754us/step - loss: 0.6519 - accuracy: 0.8087\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.6494 - accuracy: 0.8094\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 0s 754us/step - loss: 0.6470 - accuracy: 0.8100\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.6448 - accuracy: 0.8103\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 0s 754us/step - loss: 0.6426 - accuracy: 0.8112\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 0s 750us/step - loss: 0.6406 - accuracy: 0.8113\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 0s 754us/step - loss: 0.6386 - accuracy: 0.8119\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.6368 - accuracy: 0.8127\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.6351 - accuracy: 0.8129\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.6334 - accuracy: 0.8134\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 0s 750us/step - loss: 0.6317 - accuracy: 0.8139\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 0s 750us/step - loss: 0.6302 - accuracy: 0.8145\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 0s 754us/step - loss: 0.6287 - accuracy: 0.8146\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.6273 - accuracy: 0.8154\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.6259 - accuracy: 0.8155\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 0s 746us/step - loss: 0.6246 - accuracy: 0.8160\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 0s 784us/step - loss: 0.6233 - accuracy: 0.8165\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.6221 - accuracy: 0.8166\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.6208 - accuracy: 0.8168\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.6197 - accuracy: 0.8175\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 0s 754us/step - loss: 0.6186 - accuracy: 0.8176\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 0s 750us/step - loss: 0.6175 - accuracy: 0.8182\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 0s 754us/step - loss: 0.6164 - accuracy: 0.8181\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_15 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_15 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 10)                7850      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "235/235 [==============================] - 0s 780us/step - loss: 0.9425 - accuracy: 0.7299\n",
      "Epoch 2/25\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.6540 - accuracy: 0.8079\n",
      "Epoch 3/25\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.6179 - accuracy: 0.8178\n",
      "Epoch 4/25\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.6020 - accuracy: 0.8231\n",
      "Epoch 5/25\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5924 - accuracy: 0.8251\n",
      "Epoch 6/25\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5856 - accuracy: 0.8285\n",
      "Epoch 7/25\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5806 - accuracy: 0.8284\n",
      "Epoch 8/25\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5760 - accuracy: 0.8311\n",
      "Epoch 9/25\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5728 - accuracy: 0.8328\n",
      "Epoch 10/25\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5697 - accuracy: 0.8328\n",
      "Epoch 11/25\n",
      "235/235 [==============================] - 0s 774us/step - loss: 0.5672 - accuracy: 0.8343\n",
      "Epoch 12/25\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5650 - accuracy: 0.8348\n",
      "Epoch 13/25\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5628 - accuracy: 0.8351\n",
      "Epoch 14/25\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5613 - accuracy: 0.8359\n",
      "Epoch 15/25\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5592 - accuracy: 0.8364\n",
      "Epoch 16/25\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5579 - accuracy: 0.8372\n",
      "Epoch 17/25\n",
      "235/235 [==============================] - 0s 788us/step - loss: 0.5563 - accuracy: 0.8375\n",
      "Epoch 18/25\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5552 - accuracy: 0.8377\n",
      "Epoch 19/25\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5537 - accuracy: 0.8373\n",
      "Epoch 20/25\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5525 - accuracy: 0.8382\n",
      "Epoch 21/25\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5516 - accuracy: 0.8384\n",
      "Epoch 22/25\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5504 - accuracy: 0.8383\n",
      "Epoch 23/25\n",
      "235/235 [==============================] - 0s 780us/step - loss: 0.5494 - accuracy: 0.8385\n",
      "Epoch 24/25\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5488 - accuracy: 0.8386\n",
      "Epoch 25/25\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5479 - accuracy: 0.8393\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_16 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_16 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 10)                7850      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 0s 784us/step - loss: 0.9350 - accuracy: 0.7366\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.6526 - accuracy: 0.8084\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.6172 - accuracy: 0.8185\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.6016 - accuracy: 0.8226\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5926 - accuracy: 0.8259\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5855 - accuracy: 0.8285\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 0s 780us/step - loss: 0.5801 - accuracy: 0.8301\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5766 - accuracy: 0.8309\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5733 - accuracy: 0.8319\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5699 - accuracy: 0.8328\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5673 - accuracy: 0.8339\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 0s 768us/step - loss: 0.5649 - accuracy: 0.8344\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5630 - accuracy: 0.8341\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5602 - accuracy: 0.8357\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5594 - accuracy: 0.8360\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5576 - accuracy: 0.8359\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5565 - accuracy: 0.8371\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5551 - accuracy: 0.8375\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5537 - accuracy: 0.8378\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5531 - accuracy: 0.8383\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 0s 754us/step - loss: 0.5520 - accuracy: 0.8380\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5504 - accuracy: 0.8389\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5495 - accuracy: 0.8392\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5486 - accuracy: 0.8397\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5485 - accuracy: 0.8385\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5473 - accuracy: 0.8391\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5469 - accuracy: 0.8396\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5455 - accuracy: 0.8395\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5449 - accuracy: 0.8401\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5445 - accuracy: 0.8394\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 0s 797us/step - loss: 0.5436 - accuracy: 0.8400\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5431 - accuracy: 0.8403\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5425 - accuracy: 0.8407\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5424 - accuracy: 0.8404\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 0s 780us/step - loss: 0.5417 - accuracy: 0.8408\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5416 - accuracy: 0.8411\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5410 - accuracy: 0.8408\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5398 - accuracy: 0.8411\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5397 - accuracy: 0.8417\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5397 - accuracy: 0.8417\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5393 - accuracy: 0.8420\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5385 - accuracy: 0.8407\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5383 - accuracy: 0.8410\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5377 - accuracy: 0.8414\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5373 - accuracy: 0.8411\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5371 - accuracy: 0.8421\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5366 - accuracy: 0.8416\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5363 - accuracy: 0.8419\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5358 - accuracy: 0.8419\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5357 - accuracy: 0.8427\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_17 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_17 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 10)                7850      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "235/235 [==============================] - 0s 801us/step - loss: 0.7268 - accuracy: 0.7822\n",
      "Epoch 2/25\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.6090 - accuracy: 0.8211\n",
      "Epoch 3/25\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5934 - accuracy: 0.8259\n",
      "Epoch 4/25\n",
      "235/235 [==============================] - 0s 784us/step - loss: 0.5829 - accuracy: 0.8289\n",
      "Epoch 5/25\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5772 - accuracy: 0.8310\n",
      "Epoch 6/25\n",
      "235/235 [==============================] - 0s 921us/step - loss: 0.5730 - accuracy: 0.8323\n",
      "Epoch 7/25\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5693 - accuracy: 0.8334\n",
      "Epoch 8/25\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5656 - accuracy: 0.8349\n",
      "Epoch 9/25\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5628 - accuracy: 0.8347\n",
      "Epoch 10/25\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5617 - accuracy: 0.8354\n",
      "Epoch 11/25\n",
      "235/235 [==============================] - 0s 788us/step - loss: 0.5589 - accuracy: 0.8364\n",
      "Epoch 12/25\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5572 - accuracy: 0.8368\n",
      "Epoch 13/25\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5560 - accuracy: 0.8370\n",
      "Epoch 14/25\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5538 - accuracy: 0.8378\n",
      "Epoch 15/25\n",
      "235/235 [==============================] - 0s 780us/step - loss: 0.5527 - accuracy: 0.8376\n",
      "Epoch 16/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5521 - accuracy: 0.8373\n",
      "Epoch 17/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5504 - accuracy: 0.8381\n",
      "Epoch 18/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5493 - accuracy: 0.8388\n",
      "Epoch 19/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5482 - accuracy: 0.8383\n",
      "Epoch 20/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5470 - accuracy: 0.8389\n",
      "Epoch 21/25\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5464 - accuracy: 0.8391\n",
      "Epoch 22/25\n",
      "235/235 [==============================] - 0s 801us/step - loss: 0.5455 - accuracy: 0.8394\n",
      "Epoch 23/25\n",
      "235/235 [==============================] - 0s 780us/step - loss: 0.5447 - accuracy: 0.8392\n",
      "Epoch 24/25\n",
      "235/235 [==============================] - 0s 793us/step - loss: 0.5440 - accuracy: 0.8399\n",
      "Epoch 25/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5426 - accuracy: 0.8401\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_18 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_18 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 10)                7850      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 0s 780us/step - loss: 0.7260 - accuracy: 0.7825\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 0s 810us/step - loss: 0.6081 - accuracy: 0.8210\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 0s 831us/step - loss: 0.5927 - accuracy: 0.8250\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5831 - accuracy: 0.8287\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5772 - accuracy: 0.8303\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5727 - accuracy: 0.8320\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5694 - accuracy: 0.8329\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 0s 814us/step - loss: 0.5657 - accuracy: 0.8343\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5635 - accuracy: 0.8350\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 0s 788us/step - loss: 0.5613 - accuracy: 0.8359\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5589 - accuracy: 0.8364\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5574 - accuracy: 0.8365\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 0s 773us/step - loss: 0.5557 - accuracy: 0.8371\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5540 - accuracy: 0.8378\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 0s 780us/step - loss: 0.5528 - accuracy: 0.8376\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5515 - accuracy: 0.8377\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5503 - accuracy: 0.8382\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5494 - accuracy: 0.8387\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 0s 788us/step - loss: 0.5489 - accuracy: 0.8388\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5473 - accuracy: 0.8383\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5464 - accuracy: 0.8392\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5456 - accuracy: 0.8394\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5454 - accuracy: 0.8396\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5440 - accuracy: 0.8392\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5435 - accuracy: 0.8388\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5428 - accuracy: 0.8400\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 0s 810us/step - loss: 0.5418 - accuracy: 0.8395\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5414 - accuracy: 0.8401\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5406 - accuracy: 0.8404\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 0s 780us/step - loss: 0.5407 - accuracy: 0.8402\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5390 - accuracy: 0.8409\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5389 - accuracy: 0.8409\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5387 - accuracy: 0.8412\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5384 - accuracy: 0.8404\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5381 - accuracy: 0.8407\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5374 - accuracy: 0.8410\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5367 - accuracy: 0.8413\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5367 - accuracy: 0.8412\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5359 - accuracy: 0.8414\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5355 - accuracy: 0.8414\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5357 - accuracy: 0.8413\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5345 - accuracy: 0.8417\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5342 - accuracy: 0.8410\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5341 - accuracy: 0.8419\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5342 - accuracy: 0.8421\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5335 - accuracy: 0.8414\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5329 - accuracy: 0.8412\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 0s 801us/step - loss: 0.5332 - accuracy: 0.8428\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5317 - accuracy: 0.8426\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5324 - accuracy: 0.8427\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_19 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_19 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 10)                7850      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "235/235 [==============================] - 0s 771us/step - loss: 1.6974 - accuracy: 0.5056\n",
      "Epoch 2/25\n",
      "235/235 [==============================] - 0s 754us/step - loss: 1.1893 - accuracy: 0.6837\n",
      "Epoch 3/25\n",
      "235/235 [==============================] - 0s 746us/step - loss: 1.0258 - accuracy: 0.7160\n",
      "Epoch 4/25\n",
      "235/235 [==============================] - 0s 746us/step - loss: 0.9390 - accuracy: 0.7373\n",
      "Epoch 5/25\n",
      "235/235 [==============================] - 0s 742us/step - loss: 0.8834 - accuracy: 0.7514\n",
      "Epoch 6/25\n",
      "235/235 [==============================] - 0s 733us/step - loss: 0.8442 - accuracy: 0.7611\n",
      "Epoch 7/25\n",
      "235/235 [==============================] - 0s 737us/step - loss: 0.8148 - accuracy: 0.7687\n",
      "Epoch 8/25\n",
      "235/235 [==============================] - 0s 742us/step - loss: 0.7917 - accuracy: 0.7739\n",
      "Epoch 9/25\n",
      "235/235 [==============================] - 0s 746us/step - loss: 0.7731 - accuracy: 0.7786\n",
      "Epoch 10/25\n",
      "235/235 [==============================] - 0s 746us/step - loss: 0.7577 - accuracy: 0.7821\n",
      "Epoch 11/25\n",
      "235/235 [==============================] - 0s 742us/step - loss: 0.7447 - accuracy: 0.7854\n",
      "Epoch 12/25\n",
      "235/235 [==============================] - 0s 742us/step - loss: 0.7335 - accuracy: 0.7885\n",
      "Epoch 13/25\n",
      "235/235 [==============================] - 0s 737us/step - loss: 0.7238 - accuracy: 0.7910\n",
      "Epoch 14/25\n",
      "235/235 [==============================] - 0s 737us/step - loss: 0.7152 - accuracy: 0.7928\n",
      "Epoch 15/25\n",
      "235/235 [==============================] - 0s 746us/step - loss: 0.7076 - accuracy: 0.7949\n",
      "Epoch 16/25\n",
      "235/235 [==============================] - 0s 742us/step - loss: 0.7008 - accuracy: 0.7967\n",
      "Epoch 17/25\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.6946 - accuracy: 0.7977\n",
      "Epoch 18/25\n",
      "235/235 [==============================] - 0s 737us/step - loss: 0.6891 - accuracy: 0.7993\n",
      "Epoch 19/25\n",
      "235/235 [==============================] - 0s 737us/step - loss: 0.6839 - accuracy: 0.8008\n",
      "Epoch 20/25\n",
      "235/235 [==============================] - 0s 742us/step - loss: 0.6793 - accuracy: 0.8026\n",
      "Epoch 21/25\n",
      "235/235 [==============================] - 0s 754us/step - loss: 0.6750 - accuracy: 0.8037\n",
      "Epoch 22/25\n",
      "235/235 [==============================] - 0s 742us/step - loss: 0.6711 - accuracy: 0.8045\n",
      "Epoch 23/25\n",
      "235/235 [==============================] - 0s 737us/step - loss: 0.6673 - accuracy: 0.8055\n",
      "Epoch 24/25\n",
      "235/235 [==============================] - 0s 733us/step - loss: 0.6639 - accuracy: 0.8063\n",
      "Epoch 25/25\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.6606 - accuracy: 0.8079\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_20 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_20 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 10)                7850      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 0s 746us/step - loss: 1.7025 - accuracy: 0.4901\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 0s 754us/step - loss: 1.1882 - accuracy: 0.6827\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 0s 776us/step - loss: 1.0237 - accuracy: 0.7154\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 0s 742us/step - loss: 0.9361 - accuracy: 0.7360\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 0s 754us/step - loss: 0.8800 - accuracy: 0.7506\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 0s 750us/step - loss: 0.8406 - accuracy: 0.7609\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.8110 - accuracy: 0.7687\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 0s 742us/step - loss: 0.7880 - accuracy: 0.7751\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 0s 742us/step - loss: 0.7693 - accuracy: 0.7796\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 0s 746us/step - loss: 0.7539 - accuracy: 0.7831\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.7410 - accuracy: 0.7864\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 0s 750us/step - loss: 0.7299 - accuracy: 0.7891\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 0s 746us/step - loss: 0.7203 - accuracy: 0.7918\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 0s 746us/step - loss: 0.7118 - accuracy: 0.7941\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 0s 750us/step - loss: 0.7043 - accuracy: 0.7960\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 0s 742us/step - loss: 0.6976 - accuracy: 0.7979\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.6915 - accuracy: 0.7990\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 0s 746us/step - loss: 0.6860 - accuracy: 0.8007\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 0s 750us/step - loss: 0.6810 - accuracy: 0.8015\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 0s 746us/step - loss: 0.6764 - accuracy: 0.8027\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 0s 742us/step - loss: 0.6722 - accuracy: 0.8037\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 0s 746us/step - loss: 0.6684 - accuracy: 0.8047\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.6647 - accuracy: 0.8060\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 0s 780us/step - loss: 0.6614 - accuracy: 0.8066\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 0s 742us/step - loss: 0.6581 - accuracy: 0.8078\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 0s 742us/step - loss: 0.6552 - accuracy: 0.8087\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 0s 742us/step - loss: 0.6525 - accuracy: 0.8093\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.6498 - accuracy: 0.8096\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 0s 750us/step - loss: 0.6474 - accuracy: 0.8108\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 0s 742us/step - loss: 0.6450 - accuracy: 0.8113\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 0s 742us/step - loss: 0.6428 - accuracy: 0.8119\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 0s 754us/step - loss: 0.6408 - accuracy: 0.8125\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 0s 742us/step - loss: 0.6387 - accuracy: 0.8129\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.6369 - accuracy: 0.8136\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 0s 742us/step - loss: 0.6351 - accuracy: 0.8140\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 0s 746us/step - loss: 0.6333 - accuracy: 0.8146\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 0s 742us/step - loss: 0.6316 - accuracy: 0.8149\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 0s 742us/step - loss: 0.6300 - accuracy: 0.8153\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 0s 750us/step - loss: 0.6285 - accuracy: 0.8160\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 0s 754us/step - loss: 0.6270 - accuracy: 0.8162\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 0s 780us/step - loss: 0.6256 - accuracy: 0.8163\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 0s 754us/step - loss: 0.6243 - accuracy: 0.8174\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 0s 737us/step - loss: 0.6230 - accuracy: 0.8173\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 0s 746us/step - loss: 0.6217 - accuracy: 0.8178\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 0s 750us/step - loss: 0.6205 - accuracy: 0.8184\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.6193 - accuracy: 0.8183\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 0s 742us/step - loss: 0.6182 - accuracy: 0.8185\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 0s 742us/step - loss: 0.6171 - accuracy: 0.8186\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 0s 737us/step - loss: 0.6160 - accuracy: 0.8194\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 0s 742us/step - loss: 0.6150 - accuracy: 0.8194\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_21 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_21 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 10)                7850      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "235/235 [==============================] - 0s 823us/step - loss: 0.9336 - accuracy: 0.7332\n",
      "Epoch 2/25\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.6521 - accuracy: 0.8096\n",
      "Epoch 3/25\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.6167 - accuracy: 0.8183\n",
      "Epoch 4/25\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.6013 - accuracy: 0.8230\n",
      "Epoch 5/25\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5918 - accuracy: 0.8261\n",
      "Epoch 6/25\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5851 - accuracy: 0.8278\n",
      "Epoch 7/25\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5798 - accuracy: 0.8303\n",
      "Epoch 8/25\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5761 - accuracy: 0.8316\n",
      "Epoch 9/25\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5729 - accuracy: 0.8322\n",
      "Epoch 10/25\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5695 - accuracy: 0.8332\n",
      "Epoch 11/25\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5667 - accuracy: 0.8338\n",
      "Epoch 12/25\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5649 - accuracy: 0.8348\n",
      "Epoch 13/25\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5626 - accuracy: 0.8353\n",
      "Epoch 14/25\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5608 - accuracy: 0.8353\n",
      "Epoch 15/25\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5591 - accuracy: 0.8367\n",
      "Epoch 16/25\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5573 - accuracy: 0.8367\n",
      "Epoch 17/25\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5559 - accuracy: 0.8373\n",
      "Epoch 18/25\n",
      "235/235 [==============================] - 0s 793us/step - loss: 0.5546 - accuracy: 0.8373\n",
      "Epoch 19/25\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5537 - accuracy: 0.8381\n",
      "Epoch 20/25\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5525 - accuracy: 0.8376\n",
      "Epoch 21/25\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5512 - accuracy: 0.8383\n",
      "Epoch 22/25\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5506 - accuracy: 0.8382\n",
      "Epoch 23/25\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5490 - accuracy: 0.8390\n",
      "Epoch 24/25\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5485 - accuracy: 0.8392\n",
      "Epoch 25/25\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5477 - accuracy: 0.8385\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_22 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_22 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 10)                7850      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 0s 831us/step - loss: 0.9485 - accuracy: 0.7292\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.6531 - accuracy: 0.8088\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.6174 - accuracy: 0.8187\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.6017 - accuracy: 0.8228\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5928 - accuracy: 0.8258\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5855 - accuracy: 0.8287\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5806 - accuracy: 0.8302\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5762 - accuracy: 0.8317\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5732 - accuracy: 0.8325\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5697 - accuracy: 0.8338\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5677 - accuracy: 0.8346\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5653 - accuracy: 0.8354\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5627 - accuracy: 0.8359\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5612 - accuracy: 0.8365\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5591 - accuracy: 0.8362\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5576 - accuracy: 0.8370\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5565 - accuracy: 0.8371\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 0s 814us/step - loss: 0.5548 - accuracy: 0.8375\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5537 - accuracy: 0.8377\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5530 - accuracy: 0.8375\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5517 - accuracy: 0.8392\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 0s 775us/step - loss: 0.5503 - accuracy: 0.8385\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5497 - accuracy: 0.8383\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5485 - accuracy: 0.8396\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5478 - accuracy: 0.8397\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5469 - accuracy: 0.8396\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5464 - accuracy: 0.8392\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5455 - accuracy: 0.8403\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 0s 780us/step - loss: 0.5452 - accuracy: 0.8400\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5443 - accuracy: 0.8397\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5435 - accuracy: 0.8395\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 0s 801us/step - loss: 0.5432 - accuracy: 0.8400\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5425 - accuracy: 0.8400\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 0s 772us/step - loss: 0.5420 - accuracy: 0.8408\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5414 - accuracy: 0.8412\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5411 - accuracy: 0.8409\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5406 - accuracy: 0.8412\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5404 - accuracy: 0.8409\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 0s 806us/step - loss: 0.5397 - accuracy: 0.8417\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 0s 780us/step - loss: 0.5393 - accuracy: 0.8415\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 0s 768us/step - loss: 0.5386 - accuracy: 0.8413\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5383 - accuracy: 0.8413\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5380 - accuracy: 0.8410\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 0s 780us/step - loss: 0.5378 - accuracy: 0.8419\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5368 - accuracy: 0.8422\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 0s 780us/step - loss: 0.5370 - accuracy: 0.8419\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5363 - accuracy: 0.8423\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5364 - accuracy: 0.8418\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5360 - accuracy: 0.8421\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 0s 772us/step - loss: 0.5356 - accuracy: 0.8423\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_23 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_23 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 10)                7850      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "235/235 [==============================] - 0s 780us/step - loss: 0.7280 - accuracy: 0.7833\n",
      "Epoch 2/25\n",
      "235/235 [==============================] - 0s 797us/step - loss: 0.6086 - accuracy: 0.8200\n",
      "Epoch 3/25\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5924 - accuracy: 0.8258\n",
      "Epoch 4/25\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5831 - accuracy: 0.8289\n",
      "Epoch 5/25\n",
      "235/235 [==============================] - 0s 780us/step - loss: 0.5776 - accuracy: 0.8298\n",
      "Epoch 6/25\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5732 - accuracy: 0.8318\n",
      "Epoch 7/25\n",
      "235/235 [==============================] - 0s 797us/step - loss: 0.5694 - accuracy: 0.8327\n",
      "Epoch 8/25\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5664 - accuracy: 0.8344\n",
      "Epoch 9/25\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5638 - accuracy: 0.8346\n",
      "Epoch 10/25\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5608 - accuracy: 0.8357\n",
      "Epoch 11/25\n",
      "235/235 [==============================] - 0s 810us/step - loss: 0.5592 - accuracy: 0.8363\n",
      "Epoch 12/25\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5573 - accuracy: 0.8364\n",
      "Epoch 13/25\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5559 - accuracy: 0.8373\n",
      "Epoch 14/25\n",
      "235/235 [==============================] - 0s 784us/step - loss: 0.5540 - accuracy: 0.8375\n",
      "Epoch 15/25\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5530 - accuracy: 0.8371\n",
      "Epoch 16/25\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5515 - accuracy: 0.8375\n",
      "Epoch 17/25\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5501 - accuracy: 0.8380\n",
      "Epoch 18/25\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5487 - accuracy: 0.8380\n",
      "Epoch 19/25\n",
      "235/235 [==============================] - 0s 780us/step - loss: 0.5478 - accuracy: 0.8386\n",
      "Epoch 20/25\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5468 - accuracy: 0.8387\n",
      "Epoch 21/25\n",
      "235/235 [==============================] - 0s 806us/step - loss: 0.5462 - accuracy: 0.8386\n",
      "Epoch 22/25\n",
      "235/235 [==============================] - 0s 784us/step - loss: 0.5455 - accuracy: 0.8403\n",
      "Epoch 23/25\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5446 - accuracy: 0.8403\n",
      "Epoch 24/25\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5442 - accuracy: 0.8403\n",
      "Epoch 25/25\n",
      "235/235 [==============================] - 0s 810us/step - loss: 0.5435 - accuracy: 0.8399\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_24 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_24 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 10)                7850      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 0s 784us/step - loss: 0.7256 - accuracy: 0.7833\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 0s 801us/step - loss: 0.6081 - accuracy: 0.8204\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5926 - accuracy: 0.8265\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5831 - accuracy: 0.8301\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 0s 797us/step - loss: 0.5774 - accuracy: 0.8310\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5728 - accuracy: 0.8323\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5691 - accuracy: 0.8340\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5663 - accuracy: 0.8339\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 0s 769us/step - loss: 0.5640 - accuracy: 0.8346\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5609 - accuracy: 0.8350\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5596 - accuracy: 0.8355\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5575 - accuracy: 0.8364\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5557 - accuracy: 0.8367\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5539 - accuracy: 0.8371\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5531 - accuracy: 0.8378\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5514 - accuracy: 0.8383\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5504 - accuracy: 0.8379\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5495 - accuracy: 0.8381\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 0s 801us/step - loss: 0.5480 - accuracy: 0.8389\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5468 - accuracy: 0.8390\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5463 - accuracy: 0.8390\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5461 - accuracy: 0.8388\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5447 - accuracy: 0.8396\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5436 - accuracy: 0.8393\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5432 - accuracy: 0.8396\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 0s 797us/step - loss: 0.5430 - accuracy: 0.8393\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5421 - accuracy: 0.8399\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5411 - accuracy: 0.8401\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5409 - accuracy: 0.8404\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 0s 797us/step - loss: 0.5406 - accuracy: 0.8400\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 0s 784us/step - loss: 0.5396 - accuracy: 0.8400\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 0s 827us/step - loss: 0.5391 - accuracy: 0.8406\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 0s 831us/step - loss: 0.5384 - accuracy: 0.8407\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 0s 823us/step - loss: 0.5383 - accuracy: 0.8399\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5377 - accuracy: 0.8411\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5370 - accuracy: 0.8413\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5368 - accuracy: 0.8418\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5361 - accuracy: 0.8412\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5358 - accuracy: 0.8412\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 0s 810us/step - loss: 0.5351 - accuracy: 0.8413\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5351 - accuracy: 0.8412\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5352 - accuracy: 0.8420\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5341 - accuracy: 0.8420\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 0s 797us/step - loss: 0.5340 - accuracy: 0.8424\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 0s 780us/step - loss: 0.5339 - accuracy: 0.8416\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5335 - accuracy: 0.8422\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5333 - accuracy: 0.8419\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 0s 801us/step - loss: 0.5329 - accuracy: 0.8419\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5324 - accuracy: 0.8424\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5323 - accuracy: 0.8419\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_25 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_25 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 10)                7850      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "235/235 [==============================] - 0s 742us/step - loss: 1.7301 - accuracy: 0.4823\n",
      "Epoch 2/25\n",
      "235/235 [==============================] - 0s 733us/step - loss: 1.1965 - accuracy: 0.6790\n",
      "Epoch 3/25\n",
      "235/235 [==============================] - 0s 733us/step - loss: 1.0289 - accuracy: 0.7134\n",
      "Epoch 4/25\n",
      "235/235 [==============================] - 0s 733us/step - loss: 0.9402 - accuracy: 0.7351\n",
      "Epoch 5/25\n",
      "235/235 [==============================] - 0s 742us/step - loss: 0.8835 - accuracy: 0.7506\n",
      "Epoch 6/25\n",
      "235/235 [==============================] - 0s 733us/step - loss: 0.8436 - accuracy: 0.7610\n",
      "Epoch 7/25\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.8139 - accuracy: 0.7680\n",
      "Epoch 8/25\n",
      "235/235 [==============================] - 0s 742us/step - loss: 0.7906 - accuracy: 0.7740\n",
      "Epoch 9/25\n",
      "235/235 [==============================] - 0s 733us/step - loss: 0.7719 - accuracy: 0.7789\n",
      "Epoch 10/25\n",
      "235/235 [==============================] - 0s 810us/step - loss: 0.7565 - accuracy: 0.7826\n",
      "Epoch 11/25\n",
      "235/235 [==============================] - 0s 750us/step - loss: 0.7434 - accuracy: 0.7858\n",
      "Epoch 12/25\n",
      "235/235 [==============================] - 0s 733us/step - loss: 0.7323 - accuracy: 0.7884\n",
      "Epoch 13/25\n",
      "235/235 [==============================] - 0s 742us/step - loss: 0.7225 - accuracy: 0.7908\n",
      "Epoch 14/25\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.7140 - accuracy: 0.7928\n",
      "Epoch 15/25\n",
      "235/235 [==============================] - 0s 733us/step - loss: 0.7065 - accuracy: 0.7942\n",
      "Epoch 16/25\n",
      "235/235 [==============================] - 0s 737us/step - loss: 0.6997 - accuracy: 0.7964\n",
      "Epoch 17/25\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.6936 - accuracy: 0.7977\n",
      "Epoch 18/25\n",
      "235/235 [==============================] - 0s 750us/step - loss: 0.6881 - accuracy: 0.7993\n",
      "Epoch 19/25\n",
      "235/235 [==============================] - 0s 742us/step - loss: 0.6831 - accuracy: 0.8008\n",
      "Epoch 20/25\n",
      "235/235 [==============================] - 0s 733us/step - loss: 0.6784 - accuracy: 0.8020\n",
      "Epoch 21/25\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.6742 - accuracy: 0.8037\n",
      "Epoch 22/25\n",
      "235/235 [==============================] - 0s 750us/step - loss: 0.6702 - accuracy: 0.8045\n",
      "Epoch 23/25\n",
      "235/235 [==============================] - 0s 737us/step - loss: 0.6666 - accuracy: 0.8052\n",
      "Epoch 24/25\n",
      "235/235 [==============================] - 0s 737us/step - loss: 0.6632 - accuracy: 0.8065\n",
      "Epoch 25/25\n",
      "235/235 [==============================] - 0s 733us/step - loss: 0.6600 - accuracy: 0.8072\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_26 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_26 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 10)                7850      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 0s 806us/step - loss: 1.7143 - accuracy: 0.4906\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 0s 742us/step - loss: 1.1935 - accuracy: 0.6817\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 0s 737us/step - loss: 1.0260 - accuracy: 0.7157\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 0s 746us/step - loss: 0.9373 - accuracy: 0.7369\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.8807 - accuracy: 0.7515\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 0s 737us/step - loss: 0.8412 - accuracy: 0.7620\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 0s 754us/step - loss: 0.8115 - accuracy: 0.7689\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 0s 780us/step - loss: 0.7886 - accuracy: 0.7748\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 0s 733us/step - loss: 0.7700 - accuracy: 0.7790\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 0s 737us/step - loss: 0.7547 - accuracy: 0.7826\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 0s 733us/step - loss: 0.7417 - accuracy: 0.7864\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.7307 - accuracy: 0.7892\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 0s 742us/step - loss: 0.7211 - accuracy: 0.7919\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 0s 737us/step - loss: 0.7126 - accuracy: 0.7945\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 0s 780us/step - loss: 0.7051 - accuracy: 0.7959\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 0s 733us/step - loss: 0.6984 - accuracy: 0.7978\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 0s 737us/step - loss: 0.6924 - accuracy: 0.7990\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 0s 750us/step - loss: 0.6870 - accuracy: 0.8006\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 0s 780us/step - loss: 0.6820 - accuracy: 0.8019\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 0s 742us/step - loss: 0.6774 - accuracy: 0.8031\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.6732 - accuracy: 0.8041\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 0s 737us/step - loss: 0.6693 - accuracy: 0.8052\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 0s 742us/step - loss: 0.6656 - accuracy: 0.8062\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 0s 750us/step - loss: 0.6623 - accuracy: 0.8068\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 0s 797us/step - loss: 0.6591 - accuracy: 0.8077\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 0s 737us/step - loss: 0.6562 - accuracy: 0.8085\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 0s 737us/step - loss: 0.6533 - accuracy: 0.8094\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 0s 737us/step - loss: 0.6508 - accuracy: 0.8100\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.6482 - accuracy: 0.8109\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 0s 746us/step - loss: 0.6459 - accuracy: 0.8118\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 0s 742us/step - loss: 0.6437 - accuracy: 0.8121\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.6416 - accuracy: 0.8129\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 0s 733us/step - loss: 0.6396 - accuracy: 0.8134\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 0s 729us/step - loss: 0.6377 - accuracy: 0.8140\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 0s 750us/step - loss: 0.6359 - accuracy: 0.8142\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 0s 793us/step - loss: 0.6341 - accuracy: 0.8149\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 0s 737us/step - loss: 0.6325 - accuracy: 0.8151\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 0s 746us/step - loss: 0.6308 - accuracy: 0.8156\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 0s 737us/step - loss: 0.6293 - accuracy: 0.8162\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 0s 748us/step - loss: 0.6278 - accuracy: 0.8164\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 0s 742us/step - loss: 0.6264 - accuracy: 0.8166\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.6251 - accuracy: 0.8171\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.6237 - accuracy: 0.8174\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 0s 737us/step - loss: 0.6224 - accuracy: 0.8181\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 0s 729us/step - loss: 0.6213 - accuracy: 0.8180\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.6201 - accuracy: 0.8187\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 0s 754us/step - loss: 0.6189 - accuracy: 0.8190\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 0s 746us/step - loss: 0.6178 - accuracy: 0.8195\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 0s 737us/step - loss: 0.6167 - accuracy: 0.8196\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 0s 784us/step - loss: 0.6157 - accuracy: 0.8199\n",
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_27 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_27 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 10)                7850      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "235/235 [==============================] - 0s 831us/step - loss: 0.9445 - accuracy: 0.7326\n",
      "Epoch 2/25\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.6554 - accuracy: 0.8055\n",
      "Epoch 3/25\n",
      "235/235 [==============================] - 0s 754us/step - loss: 0.6188 - accuracy: 0.8168\n",
      "Epoch 4/25\n",
      "235/235 [==============================] - 0s 750us/step - loss: 0.6026 - accuracy: 0.8219\n",
      "Epoch 5/25\n",
      "235/235 [==============================] - 0s 789us/step - loss: 0.5933 - accuracy: 0.8258\n",
      "Epoch 6/25\n",
      "235/235 [==============================] - 0s 750us/step - loss: 0.5863 - accuracy: 0.8274\n",
      "Epoch 7/25\n",
      "235/235 [==============================] - 0s 781us/step - loss: 0.5811 - accuracy: 0.8295\n",
      "Epoch 8/25\n",
      "235/235 [==============================] - 0s 801us/step - loss: 0.5768 - accuracy: 0.8306\n",
      "Epoch 9/25\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5731 - accuracy: 0.8322\n",
      "Epoch 10/25\n",
      "235/235 [==============================] - 0s 750us/step - loss: 0.5705 - accuracy: 0.8338\n",
      "Epoch 11/25\n",
      "235/235 [==============================] - 0s 789us/step - loss: 0.5674 - accuracy: 0.8332\n",
      "Epoch 12/25\n",
      "235/235 [==============================] - 0s 772us/step - loss: 0.5652 - accuracy: 0.8342\n",
      "Epoch 13/25\n",
      "235/235 [==============================] - 0s 750us/step - loss: 0.5633 - accuracy: 0.8354\n",
      "Epoch 14/25\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5609 - accuracy: 0.8350\n",
      "Epoch 15/25\n",
      "235/235 [==============================] - 0s 784us/step - loss: 0.5596 - accuracy: 0.8364\n",
      "Epoch 16/25\n",
      "235/235 [==============================] - 0s 754us/step - loss: 0.5580 - accuracy: 0.8363\n",
      "Epoch 17/25\n",
      "235/235 [==============================] - 0s 754us/step - loss: 0.5565 - accuracy: 0.8372\n",
      "Epoch 18/25\n",
      "235/235 [==============================] - 0s 810us/step - loss: 0.5550 - accuracy: 0.8366\n",
      "Epoch 19/25\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5540 - accuracy: 0.8381\n",
      "Epoch 20/25\n",
      "235/235 [==============================] - 0s 751us/step - loss: 0.5527 - accuracy: 0.8377\n",
      "Epoch 21/25\n",
      "235/235 [==============================] - 0s 793us/step - loss: 0.5516 - accuracy: 0.8383\n",
      "Epoch 22/25\n",
      "235/235 [==============================] - 0s 754us/step - loss: 0.5509 - accuracy: 0.8383\n",
      "Epoch 23/25\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5498 - accuracy: 0.8383\n",
      "Epoch 24/25\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5492 - accuracy: 0.8390\n",
      "Epoch 25/25\n",
      "235/235 [==============================] - 0s 793us/step - loss: 0.5479 - accuracy: 0.8389\n",
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_28 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_28 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 10)                7850      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.9483 - accuracy: 0.7296\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.6540 - accuracy: 0.8073\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.6179 - accuracy: 0.8185\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 0s 788us/step - loss: 0.6019 - accuracy: 0.8232\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5923 - accuracy: 0.8265\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5851 - accuracy: 0.8281\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 0s 793us/step - loss: 0.5806 - accuracy: 0.8303\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5760 - accuracy: 0.8323\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5727 - accuracy: 0.8332\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 0s 750us/step - loss: 0.5699 - accuracy: 0.8328\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 0s 793us/step - loss: 0.5673 - accuracy: 0.8342\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5646 - accuracy: 0.8342\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5630 - accuracy: 0.8355\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 0s 797us/step - loss: 0.5613 - accuracy: 0.8354\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5593 - accuracy: 0.8356\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5578 - accuracy: 0.8367\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 0s 797us/step - loss: 0.5566 - accuracy: 0.8372\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 0s 780us/step - loss: 0.5551 - accuracy: 0.8371\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5536 - accuracy: 0.8376\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5527 - accuracy: 0.8373\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 0s 793us/step - loss: 0.5516 - accuracy: 0.8380\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5502 - accuracy: 0.8386\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5500 - accuracy: 0.8384\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5482 - accuracy: 0.8399\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5481 - accuracy: 0.8396\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5471 - accuracy: 0.8385\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5465 - accuracy: 0.8392\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 0s 793us/step - loss: 0.5454 - accuracy: 0.8395\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5451 - accuracy: 0.8401\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5443 - accuracy: 0.8405\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5439 - accuracy: 0.8404\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 0s 797us/step - loss: 0.5430 - accuracy: 0.8403\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5425 - accuracy: 0.8411\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 0s 768us/step - loss: 0.5424 - accuracy: 0.8410\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 0s 797us/step - loss: 0.5411 - accuracy: 0.8410\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5411 - accuracy: 0.8404\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5405 - accuracy: 0.8404\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5401 - accuracy: 0.8409\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 0s 797us/step - loss: 0.5398 - accuracy: 0.8411\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5394 - accuracy: 0.8408\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5386 - accuracy: 0.8411\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 0s 806us/step - loss: 0.5383 - accuracy: 0.8411\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 0s 754us/step - loss: 0.5377 - accuracy: 0.8413\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5376 - accuracy: 0.8416\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5372 - accuracy: 0.8416\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 0s 810us/step - loss: 0.5371 - accuracy: 0.8421\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5362 - accuracy: 0.8423\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5365 - accuracy: 0.8421\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 0s 788us/step - loss: 0.5361 - accuracy: 0.8417\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 0s 759us/step - loss: 0.5359 - accuracy: 0.8418\n",
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_29 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_29 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 10)                7850      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "235/235 [==============================] - 0s 801us/step - loss: 0.7323 - accuracy: 0.7810\n",
      "Epoch 2/25\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.6105 - accuracy: 0.8196\n",
      "Epoch 3/25\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5939 - accuracy: 0.8253\n",
      "Epoch 4/25\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5843 - accuracy: 0.8279\n",
      "Epoch 5/25\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5788 - accuracy: 0.8301\n",
      "Epoch 6/25\n",
      "235/235 [==============================] - 0s 806us/step - loss: 0.5740 - accuracy: 0.8312\n",
      "Epoch 7/25\n",
      "235/235 [==============================] - 0s 776us/step - loss: 0.5697 - accuracy: 0.8332\n",
      "Epoch 8/25\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5674 - accuracy: 0.8334\n",
      "Epoch 9/25\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5650 - accuracy: 0.8341\n",
      "Epoch 10/25\n",
      "235/235 [==============================] - 0s 811us/step - loss: 0.5616 - accuracy: 0.8356\n",
      "Epoch 11/25\n",
      "235/235 [==============================] - 0s 767us/step - loss: 0.5597 - accuracy: 0.8349\n",
      "Epoch 12/25\n",
      "235/235 [==============================] - 0s 791us/step - loss: 0.5580 - accuracy: 0.8360\n",
      "Epoch 13/25\n",
      "235/235 [==============================] - 0s 797us/step - loss: 0.5561 - accuracy: 0.8361\n",
      "Epoch 14/25\n",
      "235/235 [==============================] - 0s 784us/step - loss: 0.5551 - accuracy: 0.8361\n",
      "Epoch 15/25\n",
      "235/235 [==============================] - 0s 763us/step - loss: 0.5531 - accuracy: 0.8367\n",
      "Epoch 16/25\n",
      "235/235 [==============================] - 0s 768us/step - loss: 0.5523 - accuracy: 0.8377\n",
      "Epoch 17/25\n",
      "235/235 [==============================] - 0s 801us/step - loss: 0.5507 - accuracy: 0.8382\n",
      "Epoch 18/25\n",
      "235/235 [==============================] - 0s 780us/step - loss: 0.5498 - accuracy: 0.8379\n",
      "Epoch 19/25\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.5489 - accuracy: 0.8388\n",
      "Epoch 20/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5480 - accuracy: 0.8389\n",
      "Epoch 21/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5462 - accuracy: 0.8387\n",
      "Epoch 22/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5455 - accuracy: 0.8395\n",
      "Epoch 23/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5454 - accuracy: 0.8393\n",
      "Epoch 24/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5443 - accuracy: 0.8391\n",
      "Epoch 25/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5437 - accuracy: 0.8393\n",
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_30 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_30 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 10)                7850      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 0s 950us/step - loss: 0.7313 - accuracy: 0.7815\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6095 - accuracy: 0.8198\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 0s 993us/step - loss: 0.5935 - accuracy: 0.8266\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5836 - accuracy: 0.8291\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5773 - accuracy: 0.8309\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5731 - accuracy: 0.8321\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 0s 942us/step - loss: 0.5697 - accuracy: 0.8332\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5662 - accuracy: 0.8335\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 0s 950us/step - loss: 0.5632 - accuracy: 0.8343\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 0s 946us/step - loss: 0.5612 - accuracy: 0.8355\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 0s 955us/step - loss: 0.5599 - accuracy: 0.8349\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 0s 955us/step - loss: 0.5573 - accuracy: 0.8367\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5555 - accuracy: 0.8373\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 0s 959us/step - loss: 0.5543 - accuracy: 0.8363\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 0s 967us/step - loss: 0.5531 - accuracy: 0.8371\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5516 - accuracy: 0.8380\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 0s 972us/step - loss: 0.5506 - accuracy: 0.8381\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5502 - accuracy: 0.8381\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 0s 929us/step - loss: 0.5489 - accuracy: 0.8391\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 0s 929us/step - loss: 0.5471 - accuracy: 0.8390\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 0s 976us/step - loss: 0.5467 - accuracy: 0.8389\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 0s 946us/step - loss: 0.5450 - accuracy: 0.8396\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 0s 963us/step - loss: 0.5455 - accuracy: 0.8395\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5439 - accuracy: 0.8400\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 0s 946us/step - loss: 0.5432 - accuracy: 0.8409\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 0s 933us/step - loss: 0.5430 - accuracy: 0.8400\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 0s 997us/step - loss: 0.5420 - accuracy: 0.8396\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 0s 963us/step - loss: 0.5417 - accuracy: 0.8408\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 0s 963us/step - loss: 0.5406 - accuracy: 0.8405\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5401 - accuracy: 0.8402\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 0s 967us/step - loss: 0.5395 - accuracy: 0.8409\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5393 - accuracy: 0.8409\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 0s 959us/step - loss: 0.5392 - accuracy: 0.8403\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 0s 938us/step - loss: 0.5382 - accuracy: 0.8406\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 0s 997us/step - loss: 0.5375 - accuracy: 0.8408\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 0s 929us/step - loss: 0.5376 - accuracy: 0.8412\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 0s 938us/step - loss: 0.5370 - accuracy: 0.8408\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 0s 904us/step - loss: 0.5365 - accuracy: 0.8412\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 0s 929us/step - loss: 0.5361 - accuracy: 0.8419\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5358 - accuracy: 0.8415\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 0s 823us/step - loss: 0.5347 - accuracy: 0.8417\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 0s 861us/step - loss: 0.5348 - accuracy: 0.8416\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 0s 925us/step - loss: 0.5348 - accuracy: 0.8413\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 0s 980us/step - loss: 0.5343 - accuracy: 0.8404\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 0s 929us/step - loss: 0.5337 - accuracy: 0.8416\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 0s 959us/step - loss: 0.5336 - accuracy: 0.8420\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 0s 916us/step - loss: 0.5332 - accuracy: 0.8419\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 0s 895us/step - loss: 0.5330 - accuracy: 0.8424\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 0s 959us/step - loss: 0.5323 - accuracy: 0.8423\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 0s 912us/step - loss: 0.5326 - accuracy: 0.8424\n",
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_31 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_31 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 10)                7850      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "235/235 [==============================] - 0s 827us/step - loss: 1.6656 - accuracy: 0.5171\n",
      "Epoch 2/25\n",
      "235/235 [==============================] - 0s 844us/step - loss: 1.1798 - accuracy: 0.6872\n",
      "Epoch 3/25\n",
      "235/235 [==============================] - 0s 827us/step - loss: 1.0195 - accuracy: 0.7209\n",
      "Epoch 4/25\n",
      "235/235 [==============================] - 0s 874us/step - loss: 0.9334 - accuracy: 0.7405\n",
      "Epoch 5/25\n",
      "235/235 [==============================] - 0s 814us/step - loss: 0.8784 - accuracy: 0.7535\n",
      "Epoch 6/25\n",
      "235/235 [==============================] - 0s 848us/step - loss: 0.8395 - accuracy: 0.7624\n",
      "Epoch 7/25\n",
      "235/235 [==============================] - 0s 904us/step - loss: 0.8106 - accuracy: 0.7694\n",
      "Epoch 8/25\n",
      "235/235 [==============================] - 0s 904us/step - loss: 0.7879 - accuracy: 0.7751\n",
      "Epoch 9/25\n",
      "235/235 [==============================] - 0s 861us/step - loss: 0.7697 - accuracy: 0.7791\n",
      "Epoch 10/25\n",
      "235/235 [==============================] - 0s 861us/step - loss: 0.7545 - accuracy: 0.7822\n",
      "Epoch 11/25\n",
      "235/235 [==============================] - 0s 857us/step - loss: 0.7417 - accuracy: 0.7850\n",
      "Epoch 12/25\n",
      "235/235 [==============================] - 0s 865us/step - loss: 0.7309 - accuracy: 0.7883\n",
      "Epoch 13/25\n",
      "235/235 [==============================] - 0s 959us/step - loss: 0.7213 - accuracy: 0.7907\n",
      "Epoch 14/25\n",
      "235/235 [==============================] - 0s 878us/step - loss: 0.7130 - accuracy: 0.7928\n",
      "Epoch 15/25\n",
      "235/235 [==============================] - 0s 865us/step - loss: 0.7056 - accuracy: 0.7947\n",
      "Epoch 16/25\n",
      "235/235 [==============================] - 0s 912us/step - loss: 0.6989 - accuracy: 0.7964\n",
      "Epoch 17/25\n",
      "235/235 [==============================] - 0s 929us/step - loss: 0.6929 - accuracy: 0.7985\n",
      "Epoch 18/25\n",
      "235/235 [==============================] - 0s 882us/step - loss: 0.6875 - accuracy: 0.7998\n",
      "Epoch 19/25\n",
      "235/235 [==============================] - 0s 895us/step - loss: 0.6825 - accuracy: 0.8012\n",
      "Epoch 20/25\n",
      "235/235 [==============================] - 0s 904us/step - loss: 0.6779 - accuracy: 0.8021\n",
      "Epoch 21/25\n",
      "235/235 [==============================] - 0s 857us/step - loss: 0.6738 - accuracy: 0.8034\n",
      "Epoch 22/25\n",
      "235/235 [==============================] - 0s 929us/step - loss: 0.6698 - accuracy: 0.8045\n",
      "Epoch 23/25\n",
      "235/235 [==============================] - 0s 827us/step - loss: 0.6662 - accuracy: 0.8051\n",
      "Epoch 24/25\n",
      "235/235 [==============================] - 0s 852us/step - loss: 0.6629 - accuracy: 0.8062\n",
      "Epoch 25/25\n",
      "235/235 [==============================] - 0s 942us/step - loss: 0.6597 - accuracy: 0.8067\n",
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_32 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_32 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 10)                7850      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 0s 959us/step - loss: 1.7053 - accuracy: 0.4874\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 0s 916us/step - loss: 1.1962 - accuracy: 0.6861\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 0s 955us/step - loss: 1.0286 - accuracy: 0.7181\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 0s 882us/step - loss: 0.9393 - accuracy: 0.7379\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 0s 921us/step - loss: 0.8824 - accuracy: 0.7518\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 0s 950us/step - loss: 0.8424 - accuracy: 0.7619\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 0s 908us/step - loss: 0.8126 - accuracy: 0.7689\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 0s 904us/step - loss: 0.7895 - accuracy: 0.7752\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 0s 955us/step - loss: 0.7708 - accuracy: 0.7799\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 0s 921us/step - loss: 0.7554 - accuracy: 0.7839\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 0s 916us/step - loss: 0.7425 - accuracy: 0.7876\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.7313 - accuracy: 0.7903\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 0s 891us/step - loss: 0.7216 - accuracy: 0.7927\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 0s 848us/step - loss: 0.7132 - accuracy: 0.7943\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 0s 972us/step - loss: 0.7056 - accuracy: 0.7962\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 0s 887us/step - loss: 0.6990 - accuracy: 0.7977\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 0s 946us/step - loss: 0.6929 - accuracy: 0.7991\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 0s 908us/step - loss: 0.6874 - accuracy: 0.8001\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 0s 929us/step - loss: 0.6823 - accuracy: 0.8017\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 0s 980us/step - loss: 0.6777 - accuracy: 0.8030\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 0s 933us/step - loss: 0.6735 - accuracy: 0.8034\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 0s 938us/step - loss: 0.6696 - accuracy: 0.8049\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 0s 895us/step - loss: 0.6660 - accuracy: 0.8058\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 0s 916us/step - loss: 0.6625 - accuracy: 0.8067\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 0s 955us/step - loss: 0.6594 - accuracy: 0.8076\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 0s 904us/step - loss: 0.6564 - accuracy: 0.8084\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 0s 942us/step - loss: 0.6536 - accuracy: 0.8090\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 0s 916us/step - loss: 0.6510 - accuracy: 0.8099\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 0s 955us/step - loss: 0.6484 - accuracy: 0.8104\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 0s 985us/step - loss: 0.6462 - accuracy: 0.8107\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 0s 929us/step - loss: 0.6439 - accuracy: 0.8113\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 0s 887us/step - loss: 0.6418 - accuracy: 0.8119\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 0s 933us/step - loss: 0.6398 - accuracy: 0.8123\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 0s 891us/step - loss: 0.6379 - accuracy: 0.8129\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 0s 942us/step - loss: 0.6361 - accuracy: 0.8132\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 0s 895us/step - loss: 0.6343 - accuracy: 0.8138\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 0s 904us/step - loss: 0.6326 - accuracy: 0.8142\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 0s 989us/step - loss: 0.6310 - accuracy: 0.8148\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 0s 921us/step - loss: 0.6294 - accuracy: 0.8154\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 0s 959us/step - loss: 0.6280 - accuracy: 0.8158\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 0s 878us/step - loss: 0.6266 - accuracy: 0.8162\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 0s 916us/step - loss: 0.6252 - accuracy: 0.8163\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 0s 968us/step - loss: 0.6239 - accuracy: 0.8164\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 0s 904us/step - loss: 0.6226 - accuracy: 0.8170\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 0s 904us/step - loss: 0.6214 - accuracy: 0.8173\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 0s 942us/step - loss: 0.6202 - accuracy: 0.8176\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 0s 933us/step - loss: 0.6191 - accuracy: 0.8177\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 0s 967us/step - loss: 0.6180 - accuracy: 0.8181\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 0s 929us/step - loss: 0.6168 - accuracy: 0.8186\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 0s 899us/step - loss: 0.6158 - accuracy: 0.8187\n",
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_33 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_33 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 10)                7850      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "235/235 [==============================] - 0s 972us/step - loss: 0.9507 - accuracy: 0.7277\n",
      "Epoch 2/25\n",
      "235/235 [==============================] - 0s 921us/step - loss: 0.6542 - accuracy: 0.8081\n",
      "Epoch 3/25\n",
      "235/235 [==============================] - 0s 942us/step - loss: 0.6176 - accuracy: 0.8182\n",
      "Epoch 4/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6016 - accuracy: 0.8223\n",
      "Epoch 5/25\n",
      "235/235 [==============================] - 0s 929us/step - loss: 0.5917 - accuracy: 0.8262\n",
      "Epoch 6/25\n",
      "235/235 [==============================] - 0s 921us/step - loss: 0.5853 - accuracy: 0.8285\n",
      "Epoch 7/25\n",
      "235/235 [==============================] - 0s 972us/step - loss: 0.5804 - accuracy: 0.8304\n",
      "Epoch 8/25\n",
      "235/235 [==============================] - 0s 938us/step - loss: 0.5758 - accuracy: 0.8311\n",
      "Epoch 9/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5725 - accuracy: 0.8327\n",
      "Epoch 10/25\n",
      "235/235 [==============================] - 0s 908us/step - loss: 0.5698 - accuracy: 0.8331\n",
      "Epoch 11/25\n",
      "235/235 [==============================] - 0s 967us/step - loss: 0.5674 - accuracy: 0.8343\n",
      "Epoch 12/25\n",
      "235/235 [==============================] - 0s 925us/step - loss: 0.5649 - accuracy: 0.8352\n",
      "Epoch 13/25\n",
      "235/235 [==============================] - 0s 908us/step - loss: 0.5629 - accuracy: 0.8348\n",
      "Epoch 14/25\n",
      "235/235 [==============================] - 0s 985us/step - loss: 0.5607 - accuracy: 0.8363\n",
      "Epoch 15/25\n",
      "235/235 [==============================] - 0s 946us/step - loss: 0.5595 - accuracy: 0.8360\n",
      "Epoch 16/25\n",
      "235/235 [==============================] - 0s 942us/step - loss: 0.5579 - accuracy: 0.8371\n",
      "Epoch 17/25\n",
      "235/235 [==============================] - 0s 908us/step - loss: 0.5564 - accuracy: 0.8369\n",
      "Epoch 18/25\n",
      "235/235 [==============================] - 0s 899us/step - loss: 0.5548 - accuracy: 0.8375\n",
      "Epoch 19/25\n",
      "235/235 [==============================] - 0s 972us/step - loss: 0.5538 - accuracy: 0.8369\n",
      "Epoch 20/25\n",
      "235/235 [==============================] - 0s 908us/step - loss: 0.5529 - accuracy: 0.8382\n",
      "Epoch 21/25\n",
      "235/235 [==============================] - 0s 861us/step - loss: 0.5517 - accuracy: 0.8381\n",
      "Epoch 22/25\n",
      "235/235 [==============================] - 0s 908us/step - loss: 0.5505 - accuracy: 0.8375\n",
      "Epoch 23/25\n",
      "235/235 [==============================] - 0s 865us/step - loss: 0.5495 - accuracy: 0.8379\n",
      "Epoch 24/25\n",
      "235/235 [==============================] - 0s 912us/step - loss: 0.5491 - accuracy: 0.8390\n",
      "Epoch 25/25\n",
      "235/235 [==============================] - 0s 904us/step - loss: 0.5480 - accuracy: 0.8388\n",
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_34 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_34 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 10)                7850      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 0s 946us/step - loss: 0.9428 - accuracy: 0.7319\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 0s 908us/step - loss: 0.6541 - accuracy: 0.8076\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 0s 904us/step - loss: 0.6182 - accuracy: 0.8177\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 0s 865us/step - loss: 0.6023 - accuracy: 0.8227\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 0s 848us/step - loss: 0.5928 - accuracy: 0.8256\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 0s 895us/step - loss: 0.5862 - accuracy: 0.8275\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 0s 955us/step - loss: 0.5807 - accuracy: 0.8300\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 0s 904us/step - loss: 0.5765 - accuracy: 0.8315\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 0s 887us/step - loss: 0.5733 - accuracy: 0.8324\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 0s 950us/step - loss: 0.5702 - accuracy: 0.8327\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 0s 912us/step - loss: 0.5672 - accuracy: 0.8343\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 0s 908us/step - loss: 0.5648 - accuracy: 0.8344\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 0s 942us/step - loss: 0.5626 - accuracy: 0.8354\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 0s 908us/step - loss: 0.5611 - accuracy: 0.8364\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 0s 959us/step - loss: 0.5592 - accuracy: 0.8358\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 0s 908us/step - loss: 0.5576 - accuracy: 0.8364\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 0s 818us/step - loss: 0.5565 - accuracy: 0.8369\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 0s 848us/step - loss: 0.5549 - accuracy: 0.8378\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 0s 806us/step - loss: 0.5540 - accuracy: 0.8375\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 0s 814us/step - loss: 0.5526 - accuracy: 0.8382\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 0s 861us/step - loss: 0.5513 - accuracy: 0.8380\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 0s 840us/step - loss: 0.5506 - accuracy: 0.8395\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 0s 806us/step - loss: 0.5496 - accuracy: 0.8395\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 0s 852us/step - loss: 0.5486 - accuracy: 0.8398\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 0s 818us/step - loss: 0.5480 - accuracy: 0.8398\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 0s 814us/step - loss: 0.5475 - accuracy: 0.8388\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 0s 831us/step - loss: 0.5461 - accuracy: 0.8398\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 0s 840us/step - loss: 0.5455 - accuracy: 0.8397\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 0s 806us/step - loss: 0.5451 - accuracy: 0.8400\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 0s 844us/step - loss: 0.5444 - accuracy: 0.8403\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 0s 835us/step - loss: 0.5437 - accuracy: 0.8399\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 0s 806us/step - loss: 0.5429 - accuracy: 0.8407\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 0s 848us/step - loss: 0.5427 - accuracy: 0.8402\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 0s 835us/step - loss: 0.5421 - accuracy: 0.8403\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 0s 823us/step - loss: 0.5414 - accuracy: 0.8415\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 0s 865us/step - loss: 0.5412 - accuracy: 0.8401\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 0s 818us/step - loss: 0.5405 - accuracy: 0.8413\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 0s 801us/step - loss: 0.5398 - accuracy: 0.8416\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 0s 852us/step - loss: 0.5393 - accuracy: 0.8413\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 0s 831us/step - loss: 0.5394 - accuracy: 0.8406\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 0s 865us/step - loss: 0.5388 - accuracy: 0.8414\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 0s 882us/step - loss: 0.5382 - accuracy: 0.8414\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 0s 823us/step - loss: 0.5382 - accuracy: 0.8417\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 0s 831us/step - loss: 0.5377 - accuracy: 0.8412\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 0s 865us/step - loss: 0.5374 - accuracy: 0.8414\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 0s 848us/step - loss: 0.5369 - accuracy: 0.8414\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 0s 857us/step - loss: 0.5366 - accuracy: 0.8417\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 0s 891us/step - loss: 0.5366 - accuracy: 0.8427\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 0s 835us/step - loss: 0.5356 - accuracy: 0.8426\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 0s 831us/step - loss: 0.5355 - accuracy: 0.8424\n",
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_35 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_35 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 10)                7850      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "235/235 [==============================] - 0s 810us/step - loss: 0.7330 - accuracy: 0.7807\n",
      "Epoch 2/25\n",
      "235/235 [==============================] - 0s 831us/step - loss: 0.6100 - accuracy: 0.8197\n",
      "Epoch 3/25\n",
      "235/235 [==============================] - 0s 818us/step - loss: 0.5938 - accuracy: 0.8259\n",
      "Epoch 4/25\n",
      "235/235 [==============================] - 0s 810us/step - loss: 0.5852 - accuracy: 0.8289\n",
      "Epoch 5/25\n",
      "235/235 [==============================] - 0s 810us/step - loss: 0.5785 - accuracy: 0.8306\n",
      "Epoch 6/25\n",
      "235/235 [==============================] - 0s 852us/step - loss: 0.5737 - accuracy: 0.8312\n",
      "Epoch 7/25\n",
      "235/235 [==============================] - 0s 835us/step - loss: 0.5695 - accuracy: 0.8337\n",
      "Epoch 8/25\n",
      "235/235 [==============================] - 0s 823us/step - loss: 0.5665 - accuracy: 0.8337\n",
      "Epoch 9/25\n",
      "235/235 [==============================] - 0s 878us/step - loss: 0.5647 - accuracy: 0.8342\n",
      "Epoch 10/25\n",
      "235/235 [==============================] - 0s 848us/step - loss: 0.5620 - accuracy: 0.8346\n",
      "Epoch 11/25\n",
      "235/235 [==============================] - 0s 857us/step - loss: 0.5599 - accuracy: 0.8355\n",
      "Epoch 12/25\n",
      "235/235 [==============================] - 0s 895us/step - loss: 0.5579 - accuracy: 0.8358\n",
      "Epoch 13/25\n",
      "235/235 [==============================] - 0s 844us/step - loss: 0.5557 - accuracy: 0.8373\n",
      "Epoch 14/25\n",
      "235/235 [==============================] - 0s 848us/step - loss: 0.5554 - accuracy: 0.8367\n",
      "Epoch 15/25\n",
      "235/235 [==============================] - 0s 869us/step - loss: 0.5534 - accuracy: 0.8367\n",
      "Epoch 16/25\n",
      "235/235 [==============================] - 0s 891us/step - loss: 0.5519 - accuracy: 0.8378\n",
      "Epoch 17/25\n",
      "235/235 [==============================] - 0s 848us/step - loss: 0.5505 - accuracy: 0.8383\n",
      "Epoch 18/25\n",
      "235/235 [==============================] - 0s 861us/step - loss: 0.5499 - accuracy: 0.8385\n",
      "Epoch 19/25\n",
      "235/235 [==============================] - 0s 852us/step - loss: 0.5491 - accuracy: 0.8382\n",
      "Epoch 20/25\n",
      "235/235 [==============================] - 0s 878us/step - loss: 0.5481 - accuracy: 0.8383\n",
      "Epoch 21/25\n",
      "235/235 [==============================] - 0s 904us/step - loss: 0.5471 - accuracy: 0.8389\n",
      "Epoch 22/25\n",
      "235/235 [==============================] - 0s 835us/step - loss: 0.5455 - accuracy: 0.8389\n",
      "Epoch 23/25\n",
      "235/235 [==============================] - 0s 852us/step - loss: 0.5451 - accuracy: 0.8395\n",
      "Epoch 24/25\n",
      "235/235 [==============================] - 0s 891us/step - loss: 0.5440 - accuracy: 0.8393\n",
      "Epoch 25/25\n",
      "235/235 [==============================] - 0s 857us/step - loss: 0.5438 - accuracy: 0.8396\n",
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_36 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_36 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 10)                7850      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 0s 882us/step - loss: 0.7338 - accuracy: 0.7800\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 0s 865us/step - loss: 0.6094 - accuracy: 0.8212\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 0s 895us/step - loss: 0.5936 - accuracy: 0.8262\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 0s 895us/step - loss: 0.5842 - accuracy: 0.8287\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 0s 882us/step - loss: 0.5777 - accuracy: 0.8303\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 0s 895us/step - loss: 0.5734 - accuracy: 0.8318\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 0s 865us/step - loss: 0.5702 - accuracy: 0.8332\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 0s 857us/step - loss: 0.5671 - accuracy: 0.8337\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 0s 946us/step - loss: 0.5638 - accuracy: 0.8336\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 0s 865us/step - loss: 0.5616 - accuracy: 0.8351\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 0s 852us/step - loss: 0.5593 - accuracy: 0.8350\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 0s 912us/step - loss: 0.5574 - accuracy: 0.8356\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 0s 852us/step - loss: 0.5556 - accuracy: 0.8365\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 0s 874us/step - loss: 0.5545 - accuracy: 0.8366\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 0s 916us/step - loss: 0.5533 - accuracy: 0.8377\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 0s 840us/step - loss: 0.5518 - accuracy: 0.8371\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 0s 904us/step - loss: 0.5505 - accuracy: 0.8381\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 0s 852us/step - loss: 0.5497 - accuracy: 0.8383\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 0s 857us/step - loss: 0.5483 - accuracy: 0.8385\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 0s 891us/step - loss: 0.5470 - accuracy: 0.8385\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 0s 861us/step - loss: 0.5469 - accuracy: 0.8381\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 0s 844us/step - loss: 0.5457 - accuracy: 0.8396\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 0s 874us/step - loss: 0.5448 - accuracy: 0.8397\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 0s 865us/step - loss: 0.5444 - accuracy: 0.8400\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 0s 840us/step - loss: 0.5434 - accuracy: 0.8391\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 0s 857us/step - loss: 0.5424 - accuracy: 0.8397\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 0s 823us/step - loss: 0.5423 - accuracy: 0.8402\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 0s 904us/step - loss: 0.5416 - accuracy: 0.8401\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 0s 844us/step - loss: 0.5410 - accuracy: 0.8406\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 0s 827us/step - loss: 0.5399 - accuracy: 0.8399\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 0s 933us/step - loss: 0.5398 - accuracy: 0.8404\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 0s 959us/step - loss: 0.5386 - accuracy: 0.8413\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 0s 921us/step - loss: 0.5390 - accuracy: 0.8403\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 0s 976us/step - loss: 0.5378 - accuracy: 0.8406\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 0s 925us/step - loss: 0.5375 - accuracy: 0.8414\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 0s 950us/step - loss: 0.5368 - accuracy: 0.8415\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 0s 916us/step - loss: 0.5365 - accuracy: 0.8418\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 0s 942us/step - loss: 0.5365 - accuracy: 0.8411\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 0s 925us/step - loss: 0.5365 - accuracy: 0.8408\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 0s 912us/step - loss: 0.5354 - accuracy: 0.8410\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 0s 950us/step - loss: 0.5354 - accuracy: 0.8409\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 0s 904us/step - loss: 0.5351 - accuracy: 0.8409\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 0s 946us/step - loss: 0.5341 - accuracy: 0.8416\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 0s 874us/step - loss: 0.5339 - accuracy: 0.8421\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 0s 827us/step - loss: 0.5337 - accuracy: 0.8416\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 0s 929us/step - loss: 0.5330 - accuracy: 0.8417\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 0s 844us/step - loss: 0.5331 - accuracy: 0.8420\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 0s 929us/step - loss: 0.5331 - accuracy: 0.8412\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 0s 942us/step - loss: 0.5331 - accuracy: 0.8416\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 0s 946us/step - loss: 0.5325 - accuracy: 0.8423\n",
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_37 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_37 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 32)                25120     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,450\n",
      "Trainable params: 25,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 1.8546 - accuracy: 0.4099\n",
      "Epoch 2/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 1.2713 - accuracy: 0.6311\n",
      "Epoch 3/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 1.0479 - accuracy: 0.6897\n",
      "Epoch 4/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.9366 - accuracy: 0.7220\n",
      "Epoch 5/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.8666 - accuracy: 0.7412\n",
      "Epoch 6/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.8140 - accuracy: 0.7568\n",
      "Epoch 7/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.7739 - accuracy: 0.7685\n",
      "Epoch 8/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.7447 - accuracy: 0.7774\n",
      "Epoch 9/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.7216 - accuracy: 0.7826\n",
      "Epoch 10/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6987 - accuracy: 0.7893\n",
      "Epoch 11/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6795 - accuracy: 0.7947\n",
      "Epoch 12/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6628 - accuracy: 0.7991\n",
      "Epoch 13/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6475 - accuracy: 0.8069\n",
      "Epoch 14/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6350 - accuracy: 0.8089\n",
      "Epoch 15/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6224 - accuracy: 0.8110\n",
      "Epoch 16/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6112 - accuracy: 0.8153\n",
      "Epoch 17/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6007 - accuracy: 0.8171\n",
      "Epoch 18/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5909 - accuracy: 0.8217\n",
      "Epoch 19/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5821 - accuracy: 0.8233\n",
      "Epoch 20/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5739 - accuracy: 0.8262\n",
      "Epoch 21/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5625 - accuracy: 0.8293\n",
      "Epoch 22/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5592 - accuracy: 0.8304\n",
      "Epoch 23/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5488 - accuracy: 0.8351\n",
      "Epoch 24/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5423 - accuracy: 0.8363\n",
      "Epoch 25/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5382 - accuracy: 0.8378\n",
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_38 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_38 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 32)                25120     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,450\n",
      "Trainable params: 25,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 1.8186 - accuracy: 0.4041\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 1.2815 - accuracy: 0.6313\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 1.0561 - accuracy: 0.6919\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.9381 - accuracy: 0.7252\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.8654 - accuracy: 0.7444\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.8157 - accuracy: 0.7586\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.7788 - accuracy: 0.7692\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.7523 - accuracy: 0.7751\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.7285 - accuracy: 0.7818\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.7043 - accuracy: 0.7887\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6863 - accuracy: 0.7935\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6715 - accuracy: 0.7968\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6563 - accuracy: 0.8018\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6448 - accuracy: 0.8050\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6334 - accuracy: 0.8084\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6232 - accuracy: 0.8101\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6136 - accuracy: 0.8138\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6036 - accuracy: 0.8156\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5955 - accuracy: 0.8195\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5854 - accuracy: 0.8227\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5788 - accuracy: 0.8238\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5714 - accuracy: 0.8265\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5650 - accuracy: 0.8286\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5572 - accuracy: 0.8311\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5513 - accuracy: 0.8323\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5446 - accuracy: 0.8339\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5383 - accuracy: 0.8362\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5323 - accuracy: 0.8394\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5281 - accuracy: 0.8400\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5224 - accuracy: 0.8407\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5148 - accuracy: 0.8434\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5119 - accuracy: 0.8451\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5072 - accuracy: 0.8469\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5025 - accuracy: 0.8483\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4986 - accuracy: 0.8485\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4943 - accuracy: 0.8492\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4933 - accuracy: 0.8504\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4887 - accuracy: 0.8511\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4845 - accuracy: 0.8529\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4774 - accuracy: 0.8552\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4793 - accuracy: 0.8549\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4715 - accuracy: 0.8568\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4710 - accuracy: 0.8573\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4671 - accuracy: 0.8584\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4663 - accuracy: 0.8576\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4616 - accuracy: 0.8597\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4577 - accuracy: 0.8602\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4559 - accuracy: 0.8608\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4543 - accuracy: 0.8621\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4516 - accuracy: 0.8617\n",
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_39 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_39 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 32)                25120     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,450\n",
      "Trainable params: 25,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.8297 - accuracy: 0.7513\n",
      "Epoch 2/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5122 - accuracy: 0.8429\n",
      "Epoch 3/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4478 - accuracy: 0.8632\n",
      "Epoch 4/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4113 - accuracy: 0.8755\n",
      "Epoch 5/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3857 - accuracy: 0.8822\n",
      "Epoch 6/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3670 - accuracy: 0.8869\n",
      "Epoch 7/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3548 - accuracy: 0.8909\n",
      "Epoch 8/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3407 - accuracy: 0.8954\n",
      "Epoch 9/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3318 - accuracy: 0.8968\n",
      "Epoch 10/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3235 - accuracy: 0.9000\n",
      "Epoch 11/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3148 - accuracy: 0.9027\n",
      "Epoch 12/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3081 - accuracy: 0.9040\n",
      "Epoch 13/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3045 - accuracy: 0.9052\n",
      "Epoch 14/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2986 - accuracy: 0.9074\n",
      "Epoch 15/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2914 - accuracy: 0.9093\n",
      "Epoch 16/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2893 - accuracy: 0.9108\n",
      "Epoch 17/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2826 - accuracy: 0.9115\n",
      "Epoch 18/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2782 - accuracy: 0.9119\n",
      "Epoch 19/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2768 - accuracy: 0.9135\n",
      "Epoch 20/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2746 - accuracy: 0.9138\n",
      "Epoch 21/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2704 - accuracy: 0.9153\n",
      "Epoch 22/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2688 - accuracy: 0.9154\n",
      "Epoch 23/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2673 - accuracy: 0.9160\n",
      "Epoch 24/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2606 - accuracy: 0.9173\n",
      "Epoch 25/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2597 - accuracy: 0.9178\n",
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_40 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_40 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 32)                25120     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,450\n",
      "Trainable params: 25,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 1s 1ms/step - loss: 0.8397 - accuracy: 0.7491\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5147 - accuracy: 0.8442\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4413 - accuracy: 0.8657\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4008 - accuracy: 0.8782\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3797 - accuracy: 0.8837\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3598 - accuracy: 0.8921\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3449 - accuracy: 0.8945\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3376 - accuracy: 0.8967\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3271 - accuracy: 0.8993\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3195 - accuracy: 0.9018\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3138 - accuracy: 0.9031\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3094 - accuracy: 0.9054\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3072 - accuracy: 0.9049\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3017 - accuracy: 0.9084\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2979 - accuracy: 0.9076\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2901 - accuracy: 0.9102\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2877 - accuracy: 0.9126\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2876 - accuracy: 0.9098\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2844 - accuracy: 0.9121\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2800 - accuracy: 0.9136\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2762 - accuracy: 0.9150\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2755 - accuracy: 0.9144\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2743 - accuracy: 0.9147\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2699 - accuracy: 0.9158\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2664 - accuracy: 0.9178\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2659 - accuracy: 0.9182\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2669 - accuracy: 0.9175\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2630 - accuracy: 0.9180\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2582 - accuracy: 0.9199\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2587 - accuracy: 0.9190\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2575 - accuracy: 0.9185\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2552 - accuracy: 0.9204\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2540 - accuracy: 0.9215\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2529 - accuracy: 0.9205\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2519 - accuracy: 0.9216\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2471 - accuracy: 0.9237\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2467 - accuracy: 0.9227\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2472 - accuracy: 0.9224\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2442 - accuracy: 0.9223\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2456 - accuracy: 0.9228\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2455 - accuracy: 0.9237\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2414 - accuracy: 0.9242\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2437 - accuracy: 0.9233\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2438 - accuracy: 0.9238\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2388 - accuracy: 0.9257\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2341 - accuracy: 0.9261\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2366 - accuracy: 0.9258\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2350 - accuracy: 0.9264\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2344 - accuracy: 0.9252\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2311 - accuracy: 0.9270\n",
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_41 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_41 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 32)                25120     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,450\n",
      "Trainable params: 25,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6548 - accuracy: 0.7963\n",
      "Epoch 2/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4484 - accuracy: 0.8617\n",
      "Epoch 3/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4032 - accuracy: 0.8757\n",
      "Epoch 4/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3766 - accuracy: 0.8852\n",
      "Epoch 5/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3632 - accuracy: 0.8872\n",
      "Epoch 6/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3499 - accuracy: 0.8910\n",
      "Epoch 7/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3428 - accuracy: 0.8943\n",
      "Epoch 8/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3311 - accuracy: 0.8960\n",
      "Epoch 9/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3237 - accuracy: 0.8991\n",
      "Epoch 10/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3196 - accuracy: 0.8995\n",
      "Epoch 11/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3148 - accuracy: 0.9016\n",
      "Epoch 12/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3072 - accuracy: 0.9039\n",
      "Epoch 13/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3000 - accuracy: 0.9058\n",
      "Epoch 14/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2988 - accuracy: 0.9062\n",
      "Epoch 15/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2918 - accuracy: 0.9078\n",
      "Epoch 16/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2927 - accuracy: 0.9071\n",
      "Epoch 17/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2889 - accuracy: 0.9094\n",
      "Epoch 18/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2840 - accuracy: 0.9108\n",
      "Epoch 19/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2812 - accuracy: 0.9106\n",
      "Epoch 20/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2780 - accuracy: 0.9128\n",
      "Epoch 21/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2792 - accuracy: 0.9124\n",
      "Epoch 22/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2737 - accuracy: 0.9137\n",
      "Epoch 23/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2732 - accuracy: 0.9122\n",
      "Epoch 24/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2693 - accuracy: 0.9146\n",
      "Epoch 25/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2678 - accuracy: 0.9161\n",
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_42 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_42 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 32)                25120     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,450\n",
      "Trainable params: 25,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6227 - accuracy: 0.8067\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.8670\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3872 - accuracy: 0.8802\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3651 - accuracy: 0.8871\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3431 - accuracy: 0.8932\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3315 - accuracy: 0.8972\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3190 - accuracy: 0.9008\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3124 - accuracy: 0.9031\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3036 - accuracy: 0.9053\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2994 - accuracy: 0.9058\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2941 - accuracy: 0.9074\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2886 - accuracy: 0.9095\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2853 - accuracy: 0.9101\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2784 - accuracy: 0.9127\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2747 - accuracy: 0.9141\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2723 - accuracy: 0.9152\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2714 - accuracy: 0.9142\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2665 - accuracy: 0.9153\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2616 - accuracy: 0.9181\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2621 - accuracy: 0.9174\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2580 - accuracy: 0.9184\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2559 - accuracy: 0.9189\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2575 - accuracy: 0.9176\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2528 - accuracy: 0.9200\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2490 - accuracy: 0.9204\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2472 - accuracy: 0.9219\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2444 - accuracy: 0.9215\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2469 - accuracy: 0.9219\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2434 - accuracy: 0.9217\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2423 - accuracy: 0.9234\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2401 - accuracy: 0.9229\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2360 - accuracy: 0.9243\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2371 - accuracy: 0.9242\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2326 - accuracy: 0.9259\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2309 - accuracy: 0.9268\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2311 - accuracy: 0.9263\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2302 - accuracy: 0.9264\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2318 - accuracy: 0.9255\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2278 - accuracy: 0.9275\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2267 - accuracy: 0.9276\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2251 - accuracy: 0.9275\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2238 - accuracy: 0.9288\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2206 - accuracy: 0.9296\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2209 - accuracy: 0.9297\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2217 - accuracy: 0.9295\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2175 - accuracy: 0.9297\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2195 - accuracy: 0.9301\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2183 - accuracy: 0.9296\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2161 - accuracy: 0.9308\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2168 - accuracy: 0.9303\n",
      "Model: \"sequential_43\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_43 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_43 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 32)                25120     \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,450\n",
      "Trainable params: 25,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 1.8886 - accuracy: 0.3715\n",
      "Epoch 2/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 1.3613 - accuracy: 0.5832\n",
      "Epoch 3/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 1.1454 - accuracy: 0.6489\n",
      "Epoch 4/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 1.0266 - accuracy: 0.6835\n",
      "Epoch 5/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.9497 - accuracy: 0.7072\n",
      "Epoch 6/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.8938 - accuracy: 0.7266\n",
      "Epoch 7/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.8523 - accuracy: 0.7398\n",
      "Epoch 8/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.8167 - accuracy: 0.7509\n",
      "Epoch 9/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.7896 - accuracy: 0.7581\n",
      "Epoch 10/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.7656 - accuracy: 0.7655\n",
      "Epoch 11/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.7457 - accuracy: 0.7725\n",
      "Epoch 12/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.7275 - accuracy: 0.7770\n",
      "Epoch 13/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.7097 - accuracy: 0.7830\n",
      "Epoch 14/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6959 - accuracy: 0.7867\n",
      "Epoch 15/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6805 - accuracy: 0.7926\n",
      "Epoch 16/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6718 - accuracy: 0.7930\n",
      "Epoch 17/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6607 - accuracy: 0.7975\n",
      "Epoch 18/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6496 - accuracy: 0.8009\n",
      "Epoch 19/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6409 - accuracy: 0.8018\n",
      "Epoch 20/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6323 - accuracy: 0.8053\n",
      "Epoch 21/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6258 - accuracy: 0.8065\n",
      "Epoch 22/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6157 - accuracy: 0.8132\n",
      "Epoch 23/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6077 - accuracy: 0.8120\n",
      "Epoch 24/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6048 - accuracy: 0.8151\n",
      "Epoch 25/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5970 - accuracy: 0.8151\n",
      "Model: \"sequential_44\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_44 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_44 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 32)                25120     \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_54 (Dense)            (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,450\n",
      "Trainable params: 25,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 1.9162 - accuracy: 0.3521\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 1.3588 - accuracy: 0.5899\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 1.1404 - accuracy: 0.6544\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 1.0246 - accuracy: 0.6925\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.9551 - accuracy: 0.7141\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.9029 - accuracy: 0.7283\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.8603 - accuracy: 0.7409\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.8268 - accuracy: 0.7495\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.8000 - accuracy: 0.7566\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.7777 - accuracy: 0.7659\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.7566 - accuracy: 0.7696\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.7415 - accuracy: 0.7767\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.7262 - accuracy: 0.7789\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.7121 - accuracy: 0.7839\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6964 - accuracy: 0.7873\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6882 - accuracy: 0.7911\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6768 - accuracy: 0.7933\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6665 - accuracy: 0.7962\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6595 - accuracy: 0.7984\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6468 - accuracy: 0.8014\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6406 - accuracy: 0.8072\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6366 - accuracy: 0.8069\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6264 - accuracy: 0.8108\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6203 - accuracy: 0.8122\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6156 - accuracy: 0.8141\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6078 - accuracy: 0.8151\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6028 - accuracy: 0.8169\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5988 - accuracy: 0.8175\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5955 - accuracy: 0.8183\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5901 - accuracy: 0.8202\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5819 - accuracy: 0.8238\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5825 - accuracy: 0.8231\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5736 - accuracy: 0.8267\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5692 - accuracy: 0.8270\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5697 - accuracy: 0.8268\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5645 - accuracy: 0.8284\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5609 - accuracy: 0.8303\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5566 - accuracy: 0.8286\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5516 - accuracy: 0.8318\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5520 - accuracy: 0.8313\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5452 - accuracy: 0.8328\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5436 - accuracy: 0.8334\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5405 - accuracy: 0.8356\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5372 - accuracy: 0.8356\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5354 - accuracy: 0.8362\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5288 - accuracy: 0.8391\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5311 - accuracy: 0.8366\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5231 - accuracy: 0.8414\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5245 - accuracy: 0.8379\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5208 - accuracy: 0.8413\n",
      "Model: \"sequential_45\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_45 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_45 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 32)                25120     \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,450\n",
      "Trainable params: 25,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.9423 - accuracy: 0.7097\n",
      "Epoch 2/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6091 - accuracy: 0.8125\n",
      "Epoch 3/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5366 - accuracy: 0.8346\n",
      "Epoch 4/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4929 - accuracy: 0.8480\n",
      "Epoch 5/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4665 - accuracy: 0.8570\n",
      "Epoch 6/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4465 - accuracy: 0.8632\n",
      "Epoch 7/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4347 - accuracy: 0.8656\n",
      "Epoch 8/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4218 - accuracy: 0.8680\n",
      "Epoch 9/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4131 - accuracy: 0.8704\n",
      "Epoch 10/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4036 - accuracy: 0.8724\n",
      "Epoch 11/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3958 - accuracy: 0.8760\n",
      "Epoch 12/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3887 - accuracy: 0.8780\n",
      "Epoch 13/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3858 - accuracy: 0.8774\n",
      "Epoch 14/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3811 - accuracy: 0.8798\n",
      "Epoch 15/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3791 - accuracy: 0.8798\n",
      "Epoch 16/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3756 - accuracy: 0.8811\n",
      "Epoch 17/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3725 - accuracy: 0.8813\n",
      "Epoch 18/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3669 - accuracy: 0.8853\n",
      "Epoch 19/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3649 - accuracy: 0.8835\n",
      "Epoch 20/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3594 - accuracy: 0.8847\n",
      "Epoch 21/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3566 - accuracy: 0.8864\n",
      "Epoch 22/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3590 - accuracy: 0.8851\n",
      "Epoch 23/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3533 - accuracy: 0.8870\n",
      "Epoch 24/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3509 - accuracy: 0.8873\n",
      "Epoch 25/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3469 - accuracy: 0.8889\n",
      "Model: \"sequential_46\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_46 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_46 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 32)                25120     \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_58 (Dense)            (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,450\n",
      "Trainable params: 25,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.9230 - accuracy: 0.7157\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5799 - accuracy: 0.8221\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5074 - accuracy: 0.8431\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4708 - accuracy: 0.8535\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4474 - accuracy: 0.8592\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4326 - accuracy: 0.8655\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4187 - accuracy: 0.8683\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4080 - accuracy: 0.8710\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3991 - accuracy: 0.8747\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3936 - accuracy: 0.8768\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3843 - accuracy: 0.8788\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3821 - accuracy: 0.8795\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3778 - accuracy: 0.8802\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3701 - accuracy: 0.8823\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3684 - accuracy: 0.8831\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3614 - accuracy: 0.8841\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3607 - accuracy: 0.8862\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3605 - accuracy: 0.8860\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3513 - accuracy: 0.8887\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3521 - accuracy: 0.8888\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3500 - accuracy: 0.8888\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3430 - accuracy: 0.8908\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3450 - accuracy: 0.8896\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3439 - accuracy: 0.8891\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3393 - accuracy: 0.8922\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3393 - accuracy: 0.8911\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3367 - accuracy: 0.8927\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.8921\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.8939\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3315 - accuracy: 0.8939\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3308 - accuracy: 0.8939\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3264 - accuracy: 0.8938\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3248 - accuracy: 0.8956\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8941\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3240 - accuracy: 0.8956\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3204 - accuracy: 0.8962\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3216 - accuracy: 0.8973\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3186 - accuracy: 0.8977\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3198 - accuracy: 0.8973\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3195 - accuracy: 0.8967\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3166 - accuracy: 0.8976\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3158 - accuracy: 0.8984\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3144 - accuracy: 0.8975\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3135 - accuracy: 0.8988\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3128 - accuracy: 0.8984\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3107 - accuracy: 0.9003\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3138 - accuracy: 0.8979\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3134 - accuracy: 0.8988\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3095 - accuracy: 0.8990\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3100 - accuracy: 0.8983\n",
      "Model: \"sequential_47\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_47 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_47 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 32)                25120     \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_60 (Dense)            (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,450\n",
      "Trainable params: 25,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.7331 - accuracy: 0.7637\n",
      "Epoch 2/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5277 - accuracy: 0.8343\n",
      "Epoch 3/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4930 - accuracy: 0.8417\n",
      "Epoch 4/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4744 - accuracy: 0.8507\n",
      "Epoch 5/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4611 - accuracy: 0.8546\n",
      "Epoch 6/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4500 - accuracy: 0.8557\n",
      "Epoch 7/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4435 - accuracy: 0.8587\n",
      "Epoch 8/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4360 - accuracy: 0.8608\n",
      "Epoch 9/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4306 - accuracy: 0.8611\n",
      "Epoch 10/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4251 - accuracy: 0.8627\n",
      "Epoch 11/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4193 - accuracy: 0.8665\n",
      "Epoch 12/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4153 - accuracy: 0.8654\n",
      "Epoch 13/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4164 - accuracy: 0.8649\n",
      "Epoch 14/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4106 - accuracy: 0.8684\n",
      "Epoch 15/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4096 - accuracy: 0.8675\n",
      "Epoch 16/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4072 - accuracy: 0.8676\n",
      "Epoch 17/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3973 - accuracy: 0.8719\n",
      "Epoch 18/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3996 - accuracy: 0.8702\n",
      "Epoch 19/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3985 - accuracy: 0.8729\n",
      "Epoch 20/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3944 - accuracy: 0.8720\n",
      "Epoch 21/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3884 - accuracy: 0.8745\n",
      "Epoch 22/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3901 - accuracy: 0.8741\n",
      "Epoch 23/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3868 - accuracy: 0.8746\n",
      "Epoch 24/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3857 - accuracy: 0.8752\n",
      "Epoch 25/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3838 - accuracy: 0.8756\n",
      "Model: \"sequential_48\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_48 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_48 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 32)                25120     \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,450\n",
      "Trainable params: 25,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.7345 - accuracy: 0.7667\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5292 - accuracy: 0.8329\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4869 - accuracy: 0.8454\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4655 - accuracy: 0.8540\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4528 - accuracy: 0.8559\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4403 - accuracy: 0.8601\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4312 - accuracy: 0.8637\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4254 - accuracy: 0.8643\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4149 - accuracy: 0.8662\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4046 - accuracy: 0.8704\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4006 - accuracy: 0.8722\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3951 - accuracy: 0.8741\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3875 - accuracy: 0.8752\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3837 - accuracy: 0.8760\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3789 - accuracy: 0.8787\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3792 - accuracy: 0.8763\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3759 - accuracy: 0.8804\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3725 - accuracy: 0.8811\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3656 - accuracy: 0.8834\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3628 - accuracy: 0.8824\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3641 - accuracy: 0.8827\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3616 - accuracy: 0.8842\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3592 - accuracy: 0.8838\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3542 - accuracy: 0.8842\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3525 - accuracy: 0.8856\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3549 - accuracy: 0.8864\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3513 - accuracy: 0.8846\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3455 - accuracy: 0.8887\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3448 - accuracy: 0.8874\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3462 - accuracy: 0.8870\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3429 - accuracy: 0.8885\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3375 - accuracy: 0.8909\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3406 - accuracy: 0.8882\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3399 - accuracy: 0.8894\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3388 - accuracy: 0.8879\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3361 - accuracy: 0.8902\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3350 - accuracy: 0.8900\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3335 - accuracy: 0.8908\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3312 - accuracy: 0.8918\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3306 - accuracy: 0.8902\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3305 - accuracy: 0.8930\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8924\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8925\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3241 - accuracy: 0.8929\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3277 - accuracy: 0.8932\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3225 - accuracy: 0.8933\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3249 - accuracy: 0.8932\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3265 - accuracy: 0.8924\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3247 - accuracy: 0.8932\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3214 - accuracy: 0.8935\n",
      "Model: \"sequential_49\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_49 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_49 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 128)               100480    \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_64 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 1.7305 - accuracy: 0.4723\n",
      "Epoch 2/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 1.1185 - accuracy: 0.6917\n",
      "Epoch 3/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.9137 - accuracy: 0.7386\n",
      "Epoch 4/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.8125 - accuracy: 0.7641\n",
      "Epoch 5/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.7460 - accuracy: 0.7837\n",
      "Epoch 6/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6991 - accuracy: 0.7953\n",
      "Epoch 7/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6640 - accuracy: 0.8044\n",
      "Epoch 8/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6324 - accuracy: 0.8144\n",
      "Epoch 9/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6082 - accuracy: 0.8202\n",
      "Epoch 10/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5859 - accuracy: 0.8284\n",
      "Epoch 11/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5684 - accuracy: 0.8322\n",
      "Epoch 12/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5517 - accuracy: 0.8366\n",
      "Epoch 13/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5355 - accuracy: 0.8413\n",
      "Epoch 14/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5226 - accuracy: 0.8458\n",
      "Epoch 15/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5097 - accuracy: 0.8487\n",
      "Epoch 16/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4997 - accuracy: 0.8521\n",
      "Epoch 17/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4895 - accuracy: 0.8555\n",
      "Epoch 18/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4789 - accuracy: 0.8581\n",
      "Epoch 19/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4695 - accuracy: 0.8597\n",
      "Epoch 20/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4618 - accuracy: 0.8627\n",
      "Epoch 21/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4545 - accuracy: 0.8658\n",
      "Epoch 22/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4461 - accuracy: 0.8678\n",
      "Epoch 23/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4384 - accuracy: 0.8696\n",
      "Epoch 24/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4330 - accuracy: 0.8706\n",
      "Epoch 25/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4265 - accuracy: 0.8738\n",
      "Model: \"sequential_50\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_50 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_50 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_65 (Dense)            (None, 128)               100480    \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_66 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 1.7133 - accuracy: 0.4945\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 1.1080 - accuracy: 0.6944\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.9120 - accuracy: 0.7376\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.8116 - accuracy: 0.7634\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.7509 - accuracy: 0.7811\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.7046 - accuracy: 0.7936\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6729 - accuracy: 0.8004\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6407 - accuracy: 0.8110\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6175 - accuracy: 0.8174\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5952 - accuracy: 0.8254\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5754 - accuracy: 0.8300\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5588 - accuracy: 0.8354\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5429 - accuracy: 0.8411\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5280 - accuracy: 0.8438\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5151 - accuracy: 0.8496\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5018 - accuracy: 0.8524\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4919 - accuracy: 0.8544\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4810 - accuracy: 0.8587\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4732 - accuracy: 0.8605\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4620 - accuracy: 0.8638\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.4548 - accuracy: 0.8647\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.4469 - accuracy: 0.8674\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.8709\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.8739\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.8760\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.4198 - accuracy: 0.8764\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.4124 - accuracy: 0.8794\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.4066 - accuracy: 0.8803\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3999 - accuracy: 0.8814\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3949 - accuracy: 0.8840\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3901 - accuracy: 0.8860\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3865 - accuracy: 0.8866\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3804 - accuracy: 0.8888\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3752 - accuracy: 0.8898\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3724 - accuracy: 0.8906\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3673 - accuracy: 0.8910\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3635 - accuracy: 0.8935\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3591 - accuracy: 0.8952\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3572 - accuracy: 0.8950\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3513 - accuracy: 0.8965\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3484 - accuracy: 0.8992\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3440 - accuracy: 0.9001\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3409 - accuracy: 0.8999\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3384 - accuracy: 0.9007\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3339 - accuracy: 0.9026\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3308 - accuracy: 0.9042\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.9041\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3259 - accuracy: 0.9048\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3220 - accuracy: 0.9069\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3188 - accuracy: 0.9072\n",
      "Model: \"sequential_51\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_51 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_51 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_67 (Dense)            (None, 128)               100480    \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_68 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.6066 - accuracy: 0.8193\n",
      "Epoch 2/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3255 - accuracy: 0.9031\n",
      "Epoch 3/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.2518 - accuracy: 0.9250\n",
      "Epoch 4/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.2085 - accuracy: 0.9391\n",
      "Epoch 5/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.1764 - accuracy: 0.9483\n",
      "Epoch 6/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.1553 - accuracy: 0.9545\n",
      "Epoch 7/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.1377 - accuracy: 0.9602\n",
      "Epoch 8/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.1250 - accuracy: 0.9630\n",
      "Epoch 9/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.1127 - accuracy: 0.9672\n",
      "Epoch 10/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.1032 - accuracy: 0.9694\n",
      "Epoch 11/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0951 - accuracy: 0.9720\n",
      "Epoch 12/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0889 - accuracy: 0.9736\n",
      "Epoch 13/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0817 - accuracy: 0.9756\n",
      "Epoch 14/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0757 - accuracy: 0.9777\n",
      "Epoch 15/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0697 - accuracy: 0.9789\n",
      "Epoch 16/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0667 - accuracy: 0.9797\n",
      "Epoch 17/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0623 - accuracy: 0.9810\n",
      "Epoch 18/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0580 - accuracy: 0.9824\n",
      "Epoch 19/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0558 - accuracy: 0.9834\n",
      "Epoch 20/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0532 - accuracy: 0.9837\n",
      "Epoch 21/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0502 - accuracy: 0.9849\n",
      "Epoch 22/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0471 - accuracy: 0.9852\n",
      "Epoch 23/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0432 - accuracy: 0.9873\n",
      "Epoch 24/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0414 - accuracy: 0.9870\n",
      "Epoch 25/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0417 - accuracy: 0.9868\n",
      "Model: \"sequential_52\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_52 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_52 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_69 (Dense)            (None, 128)               100480    \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_70 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 1s 1ms/step - loss: 0.5966 - accuracy: 0.8243\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3263 - accuracy: 0.9033\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.2489 - accuracy: 0.9273\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.2061 - accuracy: 0.9392\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.1764 - accuracy: 0.9484\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.1565 - accuracy: 0.9545\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.1410 - accuracy: 0.9591\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.1265 - accuracy: 0.9634\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.1160 - accuracy: 0.9661\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.1069 - accuracy: 0.9691\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0966 - accuracy: 0.9712\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0903 - accuracy: 0.9737\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0835 - accuracy: 0.9752\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0780 - accuracy: 0.9766\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0734 - accuracy: 0.9784\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0686 - accuracy: 0.9793\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0639 - accuracy: 0.9810\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0613 - accuracy: 0.9817\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0568 - accuracy: 0.9826\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0542 - accuracy: 0.9831\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0506 - accuracy: 0.9848\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0481 - accuracy: 0.9855\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0468 - accuracy: 0.9852\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0443 - accuracy: 0.9862\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0432 - accuracy: 0.9867\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0390 - accuracy: 0.9882\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0379 - accuracy: 0.9884\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0387 - accuracy: 0.9883\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0353 - accuracy: 0.9884\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0342 - accuracy: 0.9897\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0330 - accuracy: 0.9895\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0311 - accuracy: 0.9907\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0305 - accuracy: 0.9901\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0295 - accuracy: 0.9907\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0293 - accuracy: 0.9910\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0280 - accuracy: 0.9915\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0277 - accuracy: 0.9912\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0262 - accuracy: 0.9919\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0251 - accuracy: 0.9926\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0243 - accuracy: 0.9923\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0244 - accuracy: 0.9924\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0234 - accuracy: 0.9928\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0246 - accuracy: 0.9921\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0222 - accuracy: 0.9926\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0227 - accuracy: 0.9924\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0208 - accuracy: 0.9934\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0215 - accuracy: 0.9931\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0202 - accuracy: 0.9932\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0213 - accuracy: 0.9937\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0208 - accuracy: 0.9930\n",
      "Model: \"sequential_53\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_53 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_53 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_71 (Dense)            (None, 128)               100480    \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_72 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "235/235 [==============================] - 1s 1ms/step - loss: 0.4436 - accuracy: 0.8642\n",
      "Epoch 2/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2397 - accuracy: 0.9287\n",
      "Epoch 3/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.1897 - accuracy: 0.9439\n",
      "Epoch 4/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.1613 - accuracy: 0.9523\n",
      "Epoch 5/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.1414 - accuracy: 0.9588\n",
      "Epoch 6/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.1251 - accuracy: 0.9634\n",
      "Epoch 7/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.1141 - accuracy: 0.9668\n",
      "Epoch 8/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.1039 - accuracy: 0.9691\n",
      "Epoch 9/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0955 - accuracy: 0.9711\n",
      "Epoch 10/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0886 - accuracy: 0.9726\n",
      "Epoch 11/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0810 - accuracy: 0.9758\n",
      "Epoch 12/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0757 - accuracy: 0.9777\n",
      "Epoch 13/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0715 - accuracy: 0.9788\n",
      "Epoch 14/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0653 - accuracy: 0.9809\n",
      "Epoch 15/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0625 - accuracy: 0.9816\n",
      "Epoch 16/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0606 - accuracy: 0.9819\n",
      "Epoch 17/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0561 - accuracy: 0.9835\n",
      "Epoch 18/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0527 - accuracy: 0.9839\n",
      "Epoch 19/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0512 - accuracy: 0.9843\n",
      "Epoch 20/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0474 - accuracy: 0.9859\n",
      "Epoch 21/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0469 - accuracy: 0.9861\n",
      "Epoch 22/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0440 - accuracy: 0.9872\n",
      "Epoch 23/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0416 - accuracy: 0.9870\n",
      "Epoch 24/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0394 - accuracy: 0.9884\n",
      "Epoch 25/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0391 - accuracy: 0.9880\n",
      "Model: \"sequential_54\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_54 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_54 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 128)               100480    \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 1s 1ms/step - loss: 0.4315 - accuracy: 0.8675\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2367 - accuracy: 0.9290\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.1881 - accuracy: 0.9441\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.1597 - accuracy: 0.9535\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.1390 - accuracy: 0.9586\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.1255 - accuracy: 0.9629\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.1134 - accuracy: 0.9663\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.1041 - accuracy: 0.9694\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0963 - accuracy: 0.9713\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0896 - accuracy: 0.9737\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0814 - accuracy: 0.9757\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0786 - accuracy: 0.9764\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0732 - accuracy: 0.9781\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0692 - accuracy: 0.9793\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0634 - accuracy: 0.9812\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0599 - accuracy: 0.9818\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0589 - accuracy: 0.9822\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0564 - accuracy: 0.9831\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0526 - accuracy: 0.9837\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0504 - accuracy: 0.9845\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0481 - accuracy: 0.9859\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0441 - accuracy: 0.9869\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0433 - accuracy: 0.9869\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0418 - accuracy: 0.9880\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0403 - accuracy: 0.9882\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0397 - accuracy: 0.9881\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0391 - accuracy: 0.9884\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0366 - accuracy: 0.9889\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0355 - accuracy: 0.9890\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0331 - accuracy: 0.9899\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0328 - accuracy: 0.9899\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0319 - accuracy: 0.9904\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0304 - accuracy: 0.9902\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0303 - accuracy: 0.9910\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0312 - accuracy: 0.9905\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0289 - accuracy: 0.9911\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0283 - accuracy: 0.9912\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0260 - accuracy: 0.9921\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0267 - accuracy: 0.9919\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0261 - accuracy: 0.9921\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0252 - accuracy: 0.9921\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0270 - accuracy: 0.9918\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0249 - accuracy: 0.9924\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0241 - accuracy: 0.9927\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0243 - accuracy: 0.9925\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0231 - accuracy: 0.9932\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0227 - accuracy: 0.9924\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0218 - accuracy: 0.9930\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0227 - accuracy: 0.9926\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0204 - accuracy: 0.9936\n",
      "Model: \"sequential_55\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_55 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_55 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_75 (Dense)            (None, 128)               100480    \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_76 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 1.8034 - accuracy: 0.4406\n",
      "Epoch 2/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 1.2085 - accuracy: 0.6586\n",
      "Epoch 3/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.9884 - accuracy: 0.7111\n",
      "Epoch 4/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.8724 - accuracy: 0.7439\n",
      "Epoch 5/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.8014 - accuracy: 0.7637\n",
      "Epoch 6/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.7477 - accuracy: 0.7784\n",
      "Epoch 7/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.7093 - accuracy: 0.7912\n",
      "Epoch 8/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6759 - accuracy: 0.7996\n",
      "Epoch 9/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6499 - accuracy: 0.8072\n",
      "Epoch 10/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6297 - accuracy: 0.8130\n",
      "Epoch 11/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6064 - accuracy: 0.8199\n",
      "Epoch 12/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5904 - accuracy: 0.8251\n",
      "Epoch 13/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5740 - accuracy: 0.8284\n",
      "Epoch 14/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5575 - accuracy: 0.8335\n",
      "Epoch 15/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5446 - accuracy: 0.8375\n",
      "Epoch 16/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5331 - accuracy: 0.8405\n",
      "Epoch 17/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5225 - accuracy: 0.8438\n",
      "Epoch 18/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5118 - accuracy: 0.8478\n",
      "Epoch 19/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5014 - accuracy: 0.8518\n",
      "Epoch 20/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4908 - accuracy: 0.8537\n",
      "Epoch 21/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4851 - accuracy: 0.8561\n",
      "Epoch 22/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4752 - accuracy: 0.8575\n",
      "Epoch 23/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4677 - accuracy: 0.8590\n",
      "Epoch 24/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4605 - accuracy: 0.8629\n",
      "Epoch 25/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4532 - accuracy: 0.8654\n",
      "Model: \"sequential_56\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_56 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_56 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_77 (Dense)            (None, 128)               100480    \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_78 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 1.7556 - accuracy: 0.4538\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 1.1919 - accuracy: 0.6572\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.9820 - accuracy: 0.7142\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.8735 - accuracy: 0.7447\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.8041 - accuracy: 0.7626\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.7556 - accuracy: 0.7767\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.7156 - accuracy: 0.7883\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6835 - accuracy: 0.7992\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6545 - accuracy: 0.8061\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6354 - accuracy: 0.8104\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6144 - accuracy: 0.8171\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5950 - accuracy: 0.8226\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5815 - accuracy: 0.8277\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5670 - accuracy: 0.8316\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5522 - accuracy: 0.8354\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5416 - accuracy: 0.8391\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5298 - accuracy: 0.8410\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5202 - accuracy: 0.8445\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5084 - accuracy: 0.8487\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4962 - accuracy: 0.8531\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4904 - accuracy: 0.8541\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4795 - accuracy: 0.8565\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4736 - accuracy: 0.8588\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4657 - accuracy: 0.8608\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4599 - accuracy: 0.8625\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4533 - accuracy: 0.8650\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4444 - accuracy: 0.8682\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4391 - accuracy: 0.8697\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4331 - accuracy: 0.8706\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.8726\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4222 - accuracy: 0.8742\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4166 - accuracy: 0.8756\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4134 - accuracy: 0.8770\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4072 - accuracy: 0.8786\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4034 - accuracy: 0.8800\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3968 - accuracy: 0.8813\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3937 - accuracy: 0.8834\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3901 - accuracy: 0.8848\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3847 - accuracy: 0.8868\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3797 - accuracy: 0.8875\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3785 - accuracy: 0.8882\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3719 - accuracy: 0.8899\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3699 - accuracy: 0.8908\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3668 - accuracy: 0.8915\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3632 - accuracy: 0.8925\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3605 - accuracy: 0.8929\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3559 - accuracy: 0.8948\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3531 - accuracy: 0.8963\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3512 - accuracy: 0.8963\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3490 - accuracy: 0.8972\n",
      "Model: \"sequential_57\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_57 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_57 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_79 (Dense)            (None, 128)               100480    \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_80 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "235/235 [==============================] - 1s 1ms/step - loss: 0.6221 - accuracy: 0.8153\n",
      "Epoch 2/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3473 - accuracy: 0.8969\n",
      "Epoch 3/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2751 - accuracy: 0.9187\n",
      "Epoch 4/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2324 - accuracy: 0.9304\n",
      "Epoch 5/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2067 - accuracy: 0.9385\n",
      "Epoch 6/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.1863 - accuracy: 0.9453\n",
      "Epoch 7/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.1700 - accuracy: 0.9492\n",
      "Epoch 8/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.1548 - accuracy: 0.9530\n",
      "Epoch 9/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.1467 - accuracy: 0.9556\n",
      "Epoch 10/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.1364 - accuracy: 0.9584\n",
      "Epoch 11/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.1296 - accuracy: 0.9610\n",
      "Epoch 12/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.1230 - accuracy: 0.9630\n",
      "Epoch 13/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.1163 - accuracy: 0.9641\n",
      "Epoch 14/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.1105 - accuracy: 0.9663\n",
      "Epoch 15/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.1045 - accuracy: 0.9676\n",
      "Epoch 16/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0997 - accuracy: 0.9686\n",
      "Epoch 17/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0967 - accuracy: 0.9690\n",
      "Epoch 18/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0937 - accuracy: 0.9707\n",
      "Epoch 19/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0892 - accuracy: 0.9724\n",
      "Epoch 20/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0862 - accuracy: 0.9732\n",
      "Epoch 21/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0832 - accuracy: 0.9745\n",
      "Epoch 22/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0800 - accuracy: 0.9750\n",
      "Epoch 23/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0777 - accuracy: 0.9757\n",
      "Epoch 24/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0736 - accuracy: 0.9768\n",
      "Epoch 25/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0729 - accuracy: 0.9768\n",
      "Model: \"sequential_58\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_58 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_58 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_81 (Dense)            (None, 128)               100480    \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_82 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 1s 1ms/step - loss: 0.6396 - accuracy: 0.8079\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3513 - accuracy: 0.8945\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2756 - accuracy: 0.9178\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.2319 - accuracy: 0.9315\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2036 - accuracy: 0.9389\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.1844 - accuracy: 0.9447\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.1674 - accuracy: 0.9495\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.1529 - accuracy: 0.9535\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.1438 - accuracy: 0.9568\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.1349 - accuracy: 0.9596\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.1277 - accuracy: 0.9619\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.1179 - accuracy: 0.9636\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.1131 - accuracy: 0.9644\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.1079 - accuracy: 0.9677\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.1014 - accuracy: 0.9687\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0986 - accuracy: 0.9697\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0944 - accuracy: 0.9701\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0910 - accuracy: 0.9716\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0881 - accuracy: 0.9722\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0858 - accuracy: 0.9732\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0796 - accuracy: 0.9743\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0785 - accuracy: 0.9755\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0755 - accuracy: 0.9762\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0711 - accuracy: 0.9769\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0711 - accuracy: 0.9769\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0697 - accuracy: 0.9779\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0663 - accuracy: 0.9794\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0660 - accuracy: 0.9783\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0635 - accuracy: 0.9799\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0604 - accuracy: 0.9808\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0598 - accuracy: 0.9807\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0580 - accuracy: 0.9810\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0573 - accuracy: 0.9814\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0554 - accuracy: 0.9816\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0562 - accuracy: 0.9817\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0530 - accuracy: 0.9829\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0518 - accuracy: 0.9831\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0507 - accuracy: 0.9835\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0521 - accuracy: 0.9829\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0514 - accuracy: 0.9837\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0472 - accuracy: 0.9849\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0486 - accuracy: 0.9838\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0472 - accuracy: 0.9848\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0445 - accuracy: 0.9855\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0446 - accuracy: 0.9853\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0451 - accuracy: 0.9852\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0437 - accuracy: 0.9853\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0428 - accuracy: 0.9858\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0424 - accuracy: 0.9858\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0426 - accuracy: 0.9864\n",
      "Model: \"sequential_59\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_59 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_59 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_83 (Dense)            (None, 128)               100480    \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_84 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4528 - accuracy: 0.8606\n",
      "Epoch 2/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2607 - accuracy: 0.9219\n",
      "Epoch 3/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2150 - accuracy: 0.9356\n",
      "Epoch 4/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.1890 - accuracy: 0.9427\n",
      "Epoch 5/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.1687 - accuracy: 0.9496\n",
      "Epoch 6/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.1536 - accuracy: 0.9534\n",
      "Epoch 7/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.1420 - accuracy: 0.9579\n",
      "Epoch 8/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.1335 - accuracy: 0.9583\n",
      "Epoch 9/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.1261 - accuracy: 0.9615\n",
      "Epoch 10/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.1202 - accuracy: 0.9625\n",
      "Epoch 11/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.1112 - accuracy: 0.9663\n",
      "Epoch 12/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.1085 - accuracy: 0.9673\n",
      "Epoch 13/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.1019 - accuracy: 0.9689\n",
      "Epoch 14/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0990 - accuracy: 0.9689\n",
      "Epoch 15/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0934 - accuracy: 0.9703\n",
      "Epoch 16/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0897 - accuracy: 0.9715\n",
      "Epoch 17/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0845 - accuracy: 0.9739\n",
      "Epoch 18/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0822 - accuracy: 0.9743\n",
      "Epoch 19/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0801 - accuracy: 0.9752\n",
      "Epoch 20/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0769 - accuracy: 0.9756\n",
      "Epoch 21/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0748 - accuracy: 0.9765\n",
      "Epoch 22/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0718 - accuracy: 0.9771\n",
      "Epoch 23/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0719 - accuracy: 0.9766\n",
      "Epoch 24/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0689 - accuracy: 0.9780\n",
      "Epoch 25/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0651 - accuracy: 0.9793\n",
      "Model: \"sequential_60\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_60 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_60 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_85 (Dense)            (None, 128)               100480    \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_86 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4750 - accuracy: 0.8539\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2823 - accuracy: 0.9152\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2306 - accuracy: 0.9320\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2016 - accuracy: 0.9387\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.1836 - accuracy: 0.9449\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.1669 - accuracy: 0.9495\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.1562 - accuracy: 0.9528\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.1472 - accuracy: 0.9560\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.1394 - accuracy: 0.9572\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.1319 - accuracy: 0.9590\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.1284 - accuracy: 0.9599\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.1203 - accuracy: 0.9621\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.1146 - accuracy: 0.9646\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.1068 - accuracy: 0.9669\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.1005 - accuracy: 0.9690\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.1006 - accuracy: 0.9687\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0977 - accuracy: 0.9693\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0941 - accuracy: 0.9704\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0927 - accuracy: 0.9709\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0870 - accuracy: 0.9725\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0851 - accuracy: 0.9731\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0822 - accuracy: 0.9739\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0799 - accuracy: 0.9737\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0776 - accuracy: 0.9754\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0726 - accuracy: 0.9768\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0721 - accuracy: 0.9769\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0725 - accuracy: 0.9767\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0685 - accuracy: 0.9778\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0678 - accuracy: 0.9783\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0661 - accuracy: 0.9783\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0647 - accuracy: 0.9789\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0629 - accuracy: 0.9798\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0625 - accuracy: 0.9795\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0622 - accuracy: 0.9798\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0615 - accuracy: 0.9802\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0570 - accuracy: 0.9815\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0588 - accuracy: 0.9807\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0564 - accuracy: 0.9812\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0552 - accuracy: 0.9819\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0551 - accuracy: 0.9815\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0536 - accuracy: 0.9820\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0516 - accuracy: 0.9836\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0512 - accuracy: 0.9828\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0506 - accuracy: 0.9833\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0517 - accuracy: 0.9832\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0485 - accuracy: 0.9837\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0473 - accuracy: 0.9849\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0473 - accuracy: 0.9843\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0468 - accuracy: 0.9848\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0463 - accuracy: 0.9847\n",
      "Model: \"sequential_61\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_61 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_61 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_87 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_88 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 1.6177 - accuracy: 0.5382\n",
      "Epoch 2/25\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 1.0357 - accuracy: 0.7189\n",
      "Epoch 3/25\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.8507 - accuracy: 0.7619\n",
      "Epoch 4/25\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.7533 - accuracy: 0.7877\n",
      "Epoch 5/25\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.6920 - accuracy: 0.8019\n",
      "Epoch 6/25\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.6521 - accuracy: 0.8131\n",
      "Epoch 7/25\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.6176 - accuracy: 0.8214\n",
      "Epoch 8/25\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.5921 - accuracy: 0.8291\n",
      "Epoch 9/25\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.5686 - accuracy: 0.8358\n",
      "Epoch 10/25\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.5485 - accuracy: 0.8408\n",
      "Epoch 11/25\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.5304 - accuracy: 0.8456\n",
      "Epoch 12/25\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.5153 - accuracy: 0.8502\n",
      "Epoch 13/25\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.5003 - accuracy: 0.8540\n",
      "Epoch 14/25\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.4878 - accuracy: 0.8575\n",
      "Epoch 15/25\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.4766 - accuracy: 0.8606\n",
      "Epoch 16/25\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.4649 - accuracy: 0.8645\n",
      "Epoch 17/25\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.4538 - accuracy: 0.8679\n",
      "Epoch 18/25\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.4451 - accuracy: 0.8693\n",
      "Epoch 19/25\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.4348 - accuracy: 0.8746\n",
      "Epoch 20/25\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.4269 - accuracy: 0.8760\n",
      "Epoch 21/25\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.4181 - accuracy: 0.8781\n",
      "Epoch 22/25\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.4102 - accuracy: 0.8806\n",
      "Epoch 23/25\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.4022 - accuracy: 0.8828\n",
      "Epoch 24/25\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.3952 - accuracy: 0.8851\n",
      "Epoch 25/25\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.3884 - accuracy: 0.8888\n",
      "Model: \"sequential_62\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_62 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_62 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_89 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_90 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 1.6298 - accuracy: 0.5538\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 1.0376 - accuracy: 0.7240\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.8473 - accuracy: 0.7646\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.7496 - accuracy: 0.7886\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.6912 - accuracy: 0.8012\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.6484 - accuracy: 0.8120\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.6150 - accuracy: 0.8225\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.5882 - accuracy: 0.8287\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.5675 - accuracy: 0.8352\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.5475 - accuracy: 0.8406\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.5295 - accuracy: 0.8436\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.5149 - accuracy: 0.8486\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.5005 - accuracy: 0.8551\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.4878 - accuracy: 0.8568\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.4760 - accuracy: 0.8616\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.4649 - accuracy: 0.8640\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.4547 - accuracy: 0.8674\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.4438 - accuracy: 0.8711\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.4345 - accuracy: 0.8739\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.4261 - accuracy: 0.8766\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.4180 - accuracy: 0.8783\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.4106 - accuracy: 0.8805\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.4021 - accuracy: 0.8834\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.3957 - accuracy: 0.8846\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.3885 - accuracy: 0.8878\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.3812 - accuracy: 0.8897\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.3755 - accuracy: 0.8918\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.3702 - accuracy: 0.8924\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.3639 - accuracy: 0.8957\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.3586 - accuracy: 0.8972\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.3535 - accuracy: 0.8982\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.3482 - accuracy: 0.8997\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.3428 - accuracy: 0.9010\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.3390 - accuracy: 0.9025\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.3339 - accuracy: 0.9041\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.3306 - accuracy: 0.9049\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.3269 - accuracy: 0.9068\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.3212 - accuracy: 0.9079\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.3174 - accuracy: 0.9088\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.3141 - accuracy: 0.9106\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.3105 - accuracy: 0.9109\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.3065 - accuracy: 0.9129\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.3029 - accuracy: 0.9135\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.3001 - accuracy: 0.9141\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2964 - accuracy: 0.9156\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2918 - accuracy: 0.9171\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2888 - accuracy: 0.9174\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2852 - accuracy: 0.9184\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2835 - accuracy: 0.9195\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2794 - accuracy: 0.9201\n",
      "Model: \"sequential_63\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_63 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_63 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_91 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_92 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.4730 - accuracy: 0.8565\n",
      "Epoch 2/25\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.2158 - accuracy: 0.9373\n",
      "Epoch 3/25\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1453 - accuracy: 0.9587\n",
      "Epoch 4/25\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1054 - accuracy: 0.9694\n",
      "Epoch 5/25\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0789 - accuracy: 0.9779\n",
      "Epoch 6/25\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0620 - accuracy: 0.9827\n",
      "Epoch 7/25\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0476 - accuracy: 0.9871\n",
      "Epoch 8/25\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0371 - accuracy: 0.9900\n",
      "Epoch 9/25\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0286 - accuracy: 0.9924\n",
      "Epoch 10/25\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0230 - accuracy: 0.9939\n",
      "Epoch 11/25\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0180 - accuracy: 0.9955\n",
      "Epoch 12/25\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0145 - accuracy: 0.9967\n",
      "Epoch 13/25\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0119 - accuracy: 0.9972\n",
      "Epoch 14/25\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0098 - accuracy: 0.9978\n",
      "Epoch 15/25\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0088 - accuracy: 0.9977\n",
      "Epoch 16/25\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0067 - accuracy: 0.9984\n",
      "Epoch 17/25\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0062 - accuracy: 0.9987\n",
      "Epoch 18/25\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0052 - accuracy: 0.9987\n",
      "Epoch 19/25\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0047 - accuracy: 0.9989\n",
      "Epoch 20/25\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0043 - accuracy: 0.9989\n",
      "Epoch 21/25\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0043 - accuracy: 0.9990\n",
      "Epoch 22/25\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0040 - accuracy: 0.9990\n",
      "Epoch 23/25\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0033 - accuracy: 0.9992\n",
      "Epoch 24/25\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0032 - accuracy: 0.9993\n",
      "Epoch 25/25\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0030 - accuracy: 0.9991\n",
      "Model: \"sequential_64\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_64 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_64 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_93 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_94 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.4784 - accuracy: 0.8567\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.2166 - accuracy: 0.9365\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1455 - accuracy: 0.9590\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1061 - accuracy: 0.9702\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0800 - accuracy: 0.9776\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0625 - accuracy: 0.9824\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0475 - accuracy: 0.9869\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0368 - accuracy: 0.9904\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0292 - accuracy: 0.9919\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0230 - accuracy: 0.9934\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0183 - accuracy: 0.9951\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0147 - accuracy: 0.9965\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0123 - accuracy: 0.9969\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0103 - accuracy: 0.9973\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0082 - accuracy: 0.9979\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0072 - accuracy: 0.9982\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0064 - accuracy: 0.9985\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0056 - accuracy: 0.9985\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0050 - accuracy: 0.9989\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0042 - accuracy: 0.9990\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0036 - accuracy: 0.9991\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0039 - accuracy: 0.9991\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0033 - accuracy: 0.9991\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0029 - accuracy: 0.9992\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0028 - accuracy: 0.9993\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0030 - accuracy: 0.9992\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0028 - accuracy: 0.9992\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0025 - accuracy: 0.9993\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0021 - accuracy: 0.9995\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0023 - accuracy: 0.9994\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0018 - accuracy: 0.9994\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0021 - accuracy: 0.9993\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0016 - accuracy: 0.9996\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0017 - accuracy: 0.9995\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0017 - accuracy: 0.9995\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0018 - accuracy: 0.9994\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0016 - accuracy: 0.9995\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0014 - accuracy: 0.9995\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0013 - accuracy: 0.9996\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0012 - accuracy: 0.9996\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0014 - accuracy: 0.9995\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 9.6710e-04 - accuracy: 0.9998\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0011 - accuracy: 0.9996\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 8.6639e-04 - accuracy: 0.9998\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 8.5875e-04 - accuracy: 0.9997\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0011 - accuracy: 0.9996\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0010 - accuracy: 0.9997\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 8.9649e-04 - accuracy: 0.9998\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0013 - accuracy: 0.9997\n",
      "Model: \"sequential_65\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_65 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_65 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_95 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_96 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.3401 - accuracy: 0.8960\n",
      "Epoch 2/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1442 - accuracy: 0.9581\n",
      "Epoch 3/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0978 - accuracy: 0.9719\n",
      "Epoch 4/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0716 - accuracy: 0.9799\n",
      "Epoch 5/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0531 - accuracy: 0.9859\n",
      "Epoch 6/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0404 - accuracy: 0.9900\n",
      "Epoch 7/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0321 - accuracy: 0.9921\n",
      "Epoch 8/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0252 - accuracy: 0.9942\n",
      "Epoch 9/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0196 - accuracy: 0.9959\n",
      "Epoch 10/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0178 - accuracy: 0.9961\n",
      "Epoch 11/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0139 - accuracy: 0.9974\n",
      "Epoch 12/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0122 - accuracy: 0.9976\n",
      "Epoch 13/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0103 - accuracy: 0.9980\n",
      "Epoch 14/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0086 - accuracy: 0.9984\n",
      "Epoch 15/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0082 - accuracy: 0.9985\n",
      "Epoch 16/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0071 - accuracy: 0.9989\n",
      "Epoch 17/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0071 - accuracy: 0.9986\n",
      "Epoch 18/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0068 - accuracy: 0.9986\n",
      "Epoch 19/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0063 - accuracy: 0.9987\n",
      "Epoch 20/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0077 - accuracy: 0.9982\n",
      "Epoch 21/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0058 - accuracy: 0.9987\n",
      "Epoch 22/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0059 - accuracy: 0.9985\n",
      "Epoch 23/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0055 - accuracy: 0.9987\n",
      "Epoch 24/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0053 - accuracy: 0.9989\n",
      "Epoch 25/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0049 - accuracy: 0.9989\n",
      "Model: \"sequential_66\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_66 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_66 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_97 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_98 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.3461 - accuracy: 0.8927\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1483 - accuracy: 0.9566\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0987 - accuracy: 0.9719\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0710 - accuracy: 0.9801\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0524 - accuracy: 0.9862\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0401 - accuracy: 0.9902\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0308 - accuracy: 0.9931\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0247 - accuracy: 0.9945\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0195 - accuracy: 0.9961\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0153 - accuracy: 0.9971\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0132 - accuracy: 0.9978\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0113 - accuracy: 0.9980\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0103 - accuracy: 0.9981\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0090 - accuracy: 0.9984\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0069 - accuracy: 0.9988\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0075 - accuracy: 0.9984\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0062 - accuracy: 0.9988\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0064 - accuracy: 0.9987\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0054 - accuracy: 0.9991\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0062 - accuracy: 0.9986\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0073 - accuracy: 0.9981\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0061 - accuracy: 0.9985\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0046 - accuracy: 0.9989\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0054 - accuracy: 0.9988\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0051 - accuracy: 0.9988\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0044 - accuracy: 0.9990\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0044 - accuracy: 0.9990\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0047 - accuracy: 0.9989\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0042 - accuracy: 0.9991\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0049 - accuracy: 0.9986\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0042 - accuracy: 0.9990\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0040 - accuracy: 0.9990\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0037 - accuracy: 0.9989\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0032 - accuracy: 0.9993\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0036 - accuracy: 0.9990\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0035 - accuracy: 0.9990\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0046 - accuracy: 0.9986\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0040 - accuracy: 0.9988\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0031 - accuracy: 0.9991\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0038 - accuracy: 0.9989\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0045 - accuracy: 0.9987\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0036 - accuracy: 0.9988\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0039 - accuracy: 0.9989\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0021 - accuracy: 0.9995\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0022 - accuracy: 0.9994\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0034 - accuracy: 0.9988\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0038 - accuracy: 0.9987\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0022 - accuracy: 0.9995\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0022 - accuracy: 0.9994\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0026 - accuracy: 0.9994\n",
      "Model: \"sequential_67\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_67 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_67 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_99 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_30 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_100 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 1.6034 - accuracy: 0.5422\n",
      "Epoch 2/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 1.0453 - accuracy: 0.7122\n",
      "Epoch 3/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.8681 - accuracy: 0.7539\n",
      "Epoch 4/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.7771 - accuracy: 0.7767\n",
      "Epoch 5/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.7195 - accuracy: 0.7920\n",
      "Epoch 6/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.6773 - accuracy: 0.8040\n",
      "Epoch 7/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.6428 - accuracy: 0.8129\n",
      "Epoch 8/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.6156 - accuracy: 0.8198\n",
      "Epoch 9/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.5930 - accuracy: 0.8265\n",
      "Epoch 10/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.5715 - accuracy: 0.8326\n",
      "Epoch 11/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.5510 - accuracy: 0.8383\n",
      "Epoch 12/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.5345 - accuracy: 0.8444\n",
      "Epoch 13/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.5217 - accuracy: 0.8465\n",
      "Epoch 14/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.5061 - accuracy: 0.8511\n",
      "Epoch 15/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.4920 - accuracy: 0.8549\n",
      "Epoch 16/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.4803 - accuracy: 0.8591\n",
      "Epoch 17/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.4691 - accuracy: 0.8618\n",
      "Epoch 18/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.4584 - accuracy: 0.8660\n",
      "Epoch 19/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.4498 - accuracy: 0.8667\n",
      "Epoch 20/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.4401 - accuracy: 0.8709\n",
      "Epoch 21/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.4323 - accuracy: 0.8724\n",
      "Epoch 22/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.4220 - accuracy: 0.8770\n",
      "Epoch 23/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.4138 - accuracy: 0.8801\n",
      "Epoch 24/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.4084 - accuracy: 0.8801\n",
      "Epoch 25/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.4002 - accuracy: 0.8830\n",
      "Model: \"sequential_68\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_68 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_68 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_101 (Dense)           (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_31 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_102 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 1.6359 - accuracy: 0.5377\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 1.0528 - accuracy: 0.7094\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.8661 - accuracy: 0.7537\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.7700 - accuracy: 0.7791\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.7111 - accuracy: 0.7948\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.6657 - accuracy: 0.8079\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.6322 - accuracy: 0.8173\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.6056 - accuracy: 0.8229\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.5816 - accuracy: 0.8309\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.5615 - accuracy: 0.8357\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.5430 - accuracy: 0.8406\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.5253 - accuracy: 0.8462\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.5126 - accuracy: 0.8491\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.4986 - accuracy: 0.8537\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.4869 - accuracy: 0.8572\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.4762 - accuracy: 0.8616\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.4639 - accuracy: 0.8637\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.4537 - accuracy: 0.8676\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.4446 - accuracy: 0.8695\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.4362 - accuracy: 0.8734\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.4271 - accuracy: 0.8759\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.4198 - accuracy: 0.8776\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.4107 - accuracy: 0.8795\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.4047 - accuracy: 0.8826\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.3982 - accuracy: 0.8843\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.3910 - accuracy: 0.8864\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.3849 - accuracy: 0.8879\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.3789 - accuracy: 0.8894\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.3730 - accuracy: 0.8917\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.3686 - accuracy: 0.8928\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.3611 - accuracy: 0.8951\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.3576 - accuracy: 0.8959\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.3525 - accuracy: 0.8976\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.3481 - accuracy: 0.8998\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.3425 - accuracy: 0.9002\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.3379 - accuracy: 0.9027\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.3361 - accuracy: 0.9035\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.3299 - accuracy: 0.9046\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.3264 - accuracy: 0.9053\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.3228 - accuracy: 0.9061\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.3192 - accuracy: 0.9079\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.3152 - accuracy: 0.9092\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.3098 - accuracy: 0.9103\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.3086 - accuracy: 0.9104\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.3049 - accuracy: 0.9133\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.3008 - accuracy: 0.9134\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.2987 - accuracy: 0.9138\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.2962 - accuracy: 0.9139\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.2932 - accuracy: 0.9162\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.2892 - accuracy: 0.9180\n",
      "Model: \"sequential_69\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_69 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_69 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_103 (Dense)           (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_32 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_104 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.4917 - accuracy: 0.8507\n",
      "Epoch 2/25\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.2275 - accuracy: 0.9325\n",
      "Epoch 3/25\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1571 - accuracy: 0.9540\n",
      "Epoch 4/25\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1192 - accuracy: 0.9659\n",
      "Epoch 5/25\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0922 - accuracy: 0.9728\n",
      "Epoch 6/25\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0765 - accuracy: 0.9780\n",
      "Epoch 7/25\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0618 - accuracy: 0.9824\n",
      "Epoch 8/25\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0514 - accuracy: 0.9853\n",
      "Epoch 9/25\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0420 - accuracy: 0.9884\n",
      "Epoch 10/25\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0347 - accuracy: 0.9904\n",
      "Epoch 11/25\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0301 - accuracy: 0.9913\n",
      "Epoch 12/25\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0258 - accuracy: 0.9923\n",
      "Epoch 13/25\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0220 - accuracy: 0.9935\n",
      "Epoch 14/25\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0190 - accuracy: 0.9945\n",
      "Epoch 15/25\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0178 - accuracy: 0.9947\n",
      "Epoch 16/25\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0152 - accuracy: 0.9956\n",
      "Epoch 17/25\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0132 - accuracy: 0.9962\n",
      "Epoch 18/25\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0127 - accuracy: 0.9962\n",
      "Epoch 19/25\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0105 - accuracy: 0.9969\n",
      "Epoch 20/25\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0101 - accuracy: 0.9971\n",
      "Epoch 21/25\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0098 - accuracy: 0.9969\n",
      "Epoch 22/25\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0093 - accuracy: 0.9973\n",
      "Epoch 23/25\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0081 - accuracy: 0.9977\n",
      "Epoch 24/25\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0076 - accuracy: 0.9976\n",
      "Epoch 25/25\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0082 - accuracy: 0.9973\n",
      "Model: \"sequential_70\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_70 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_70 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_105 (Dense)           (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_33 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_106 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.4818 - accuracy: 0.8550\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.2236 - accuracy: 0.9345\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1546 - accuracy: 0.9554\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1163 - accuracy: 0.9664\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0921 - accuracy: 0.9732\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0747 - accuracy: 0.9784\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0598 - accuracy: 0.9830\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0496 - accuracy: 0.9853\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0418 - accuracy: 0.9878\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0355 - accuracy: 0.9898\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0306 - accuracy: 0.9908\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0256 - accuracy: 0.9924\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0220 - accuracy: 0.9939\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0187 - accuracy: 0.9948\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0164 - accuracy: 0.9953\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0157 - accuracy: 0.9955\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0134 - accuracy: 0.9962\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0108 - accuracy: 0.9969\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0115 - accuracy: 0.9967\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0102 - accuracy: 0.9971\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0099 - accuracy: 0.9970\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0083 - accuracy: 0.9973\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0075 - accuracy: 0.9980\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0071 - accuracy: 0.9979\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0070 - accuracy: 0.9979\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0065 - accuracy: 0.9980\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0066 - accuracy: 0.9980\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0064 - accuracy: 0.9981\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0068 - accuracy: 0.9978\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0054 - accuracy: 0.9983\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0053 - accuracy: 0.9983\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0052 - accuracy: 0.9983\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0053 - accuracy: 0.9986\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0053 - accuracy: 0.9983\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0047 - accuracy: 0.9985\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0052 - accuracy: 0.9984\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0047 - accuracy: 0.9987\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0041 - accuracy: 0.9987\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0046 - accuracy: 0.9986\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0044 - accuracy: 0.9987\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0034 - accuracy: 0.9991\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0039 - accuracy: 0.9990\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0037 - accuracy: 0.9988\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0032 - accuracy: 0.9990\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0042 - accuracy: 0.9988\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0033 - accuracy: 0.9990\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0028 - accuracy: 0.9991\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0031 - accuracy: 0.9989\n",
      "Model: \"sequential_71\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_71 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_71 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_107 (Dense)           (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_34 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_108 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.3587 - accuracy: 0.8892\n",
      "Epoch 2/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1623 - accuracy: 0.9528\n",
      "Epoch 3/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1152 - accuracy: 0.9663\n",
      "Epoch 4/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0894 - accuracy: 0.9741\n",
      "Epoch 5/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0687 - accuracy: 0.9803\n",
      "Epoch 6/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0563 - accuracy: 0.9843\n",
      "Epoch 7/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0461 - accuracy: 0.9878\n",
      "Epoch 8/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0395 - accuracy: 0.9894\n",
      "Epoch 9/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0337 - accuracy: 0.9911\n",
      "Epoch 10/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0287 - accuracy: 0.9923\n",
      "Epoch 11/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0239 - accuracy: 0.9940\n",
      "Epoch 12/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0221 - accuracy: 0.9941\n",
      "Epoch 13/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0188 - accuracy: 0.9952\n",
      "Epoch 14/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0175 - accuracy: 0.9957\n",
      "Epoch 15/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0151 - accuracy: 0.9962\n",
      "Epoch 16/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0154 - accuracy: 0.9959\n",
      "Epoch 17/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0130 - accuracy: 0.9966\n",
      "Epoch 18/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0130 - accuracy: 0.9966\n",
      "Epoch 19/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0112 - accuracy: 0.9973\n",
      "Epoch 20/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0109 - accuracy: 0.9971\n",
      "Epoch 21/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0115 - accuracy: 0.9969\n",
      "Epoch 22/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0101 - accuracy: 0.9973\n",
      "Epoch 23/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0103 - accuracy: 0.9971\n",
      "Epoch 24/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0096 - accuracy: 0.9973\n",
      "Epoch 25/25\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0096 - accuracy: 0.9971\n",
      "Model: \"sequential_72\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_72 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_72 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_109 (Dense)           (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_110 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.3649 - accuracy: 0.8866\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1648 - accuracy: 0.9515\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1190 - accuracy: 0.9652\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0919 - accuracy: 0.9736\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0721 - accuracy: 0.9799\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0600 - accuracy: 0.9830\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0482 - accuracy: 0.9868\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0407 - accuracy: 0.9889\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0349 - accuracy: 0.9907\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0294 - accuracy: 0.9922\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0244 - accuracy: 0.9938\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0214 - accuracy: 0.9948\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0193 - accuracy: 0.9949\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0190 - accuracy: 0.9950\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0164 - accuracy: 0.9957\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0148 - accuracy: 0.9963\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0139 - accuracy: 0.9966\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0124 - accuracy: 0.9968\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0123 - accuracy: 0.9967\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0105 - accuracy: 0.9974\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0107 - accuracy: 0.9971\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0108 - accuracy: 0.9973\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0096 - accuracy: 0.9973\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0098 - accuracy: 0.9973\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0082 - accuracy: 0.9978\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0100 - accuracy: 0.9970\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0090 - accuracy: 0.9976\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0079 - accuracy: 0.9978\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0083 - accuracy: 0.9977\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0081 - accuracy: 0.9976\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0084 - accuracy: 0.9976\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0062 - accuracy: 0.9985\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0076 - accuracy: 0.9978\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0076 - accuracy: 0.9976\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0066 - accuracy: 0.9981\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0056 - accuracy: 0.9984\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0059 - accuracy: 0.9983\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0056 - accuracy: 0.9983\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0062 - accuracy: 0.9980\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0061 - accuracy: 0.9984\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0057 - accuracy: 0.9983\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0051 - accuracy: 0.9987\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0063 - accuracy: 0.9981\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0058 - accuracy: 0.9982\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0065 - accuracy: 0.9982\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0062 - accuracy: 0.9980\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0062 - accuracy: 0.9980\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0065 - accuracy: 0.9979\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0063 - accuracy: 0.9980\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0065 - accuracy: 0.9981\n",
      "Model: \"sequential_73\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_73 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_73 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_111 (Dense)           (None, 32)                25120     \n",
      "                                                                 \n",
      " dropout_36 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_112 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_113 (Dense)           (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26,506\n",
      "Trainable params: 26,506\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 2.0615 - accuracy: 0.2889\n",
      "Epoch 2/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 1.5677 - accuracy: 0.5031\n",
      "Epoch 3/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 1.2841 - accuracy: 0.5959\n",
      "Epoch 4/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 1.1144 - accuracy: 0.6505\n",
      "Epoch 5/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.9939 - accuracy: 0.6915\n",
      "Epoch 6/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.9159 - accuracy: 0.7188\n",
      "Epoch 7/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.8582 - accuracy: 0.7353\n",
      "Epoch 8/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.8138 - accuracy: 0.7494\n",
      "Epoch 9/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.7734 - accuracy: 0.7615\n",
      "Epoch 10/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.7498 - accuracy: 0.7686\n",
      "Epoch 11/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.7186 - accuracy: 0.7766\n",
      "Epoch 12/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6983 - accuracy: 0.7832\n",
      "Epoch 13/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6799 - accuracy: 0.7901\n",
      "Epoch 14/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6591 - accuracy: 0.7977\n",
      "Epoch 15/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6447 - accuracy: 0.7989\n",
      "Epoch 16/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6337 - accuracy: 0.8023\n",
      "Epoch 17/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6201 - accuracy: 0.8084\n",
      "Epoch 18/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6112 - accuracy: 0.8102\n",
      "Epoch 19/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5971 - accuracy: 0.8144\n",
      "Epoch 20/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5903 - accuracy: 0.8177\n",
      "Epoch 21/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5762 - accuracy: 0.8215\n",
      "Epoch 22/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5689 - accuracy: 0.8237\n",
      "Epoch 23/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5592 - accuracy: 0.8267\n",
      "Epoch 24/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5527 - accuracy: 0.8288\n",
      "Epoch 25/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5411 - accuracy: 0.8316\n",
      "Model: \"sequential_74\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_74 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_74 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_114 (Dense)           (None, 32)                25120     \n",
      "                                                                 \n",
      " dropout_38 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_115 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dropout_39 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_116 (Dense)           (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26,506\n",
      "Trainable params: 26,506\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 2.0035 - accuracy: 0.3246\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 1.4622 - accuracy: 0.5469\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 1.1989 - accuracy: 0.6194\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 1.0570 - accuracy: 0.6691\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.9663 - accuracy: 0.6998\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.9003 - accuracy: 0.7206\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.8496 - accuracy: 0.7366\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.8129 - accuracy: 0.7469\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.7836 - accuracy: 0.7566\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.7541 - accuracy: 0.7671\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.7298 - accuracy: 0.7745\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.7088 - accuracy: 0.7808\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.7858\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6736 - accuracy: 0.7917\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6638 - accuracy: 0.7924\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6473 - accuracy: 0.7999\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6340 - accuracy: 0.8039\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6255 - accuracy: 0.8059\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6101 - accuracy: 0.8095\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6012 - accuracy: 0.8141\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.5910 - accuracy: 0.8169\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.5823 - accuracy: 0.8191\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.5748 - accuracy: 0.8231\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.5651 - accuracy: 0.8255\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.5573 - accuracy: 0.8275\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.5496 - accuracy: 0.8308\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.5438 - accuracy: 0.8308\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.5383 - accuracy: 0.8342\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.5318 - accuracy: 0.8363\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.5237 - accuracy: 0.8384\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.8414\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.5115 - accuracy: 0.8413\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.8423\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.8436\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.4980 - accuracy: 0.8448\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.4941 - accuracy: 0.8455\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.4879 - accuracy: 0.8488\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.4834 - accuracy: 0.8502\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.4784 - accuracy: 0.8518\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.4720 - accuracy: 0.8543\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.4715 - accuracy: 0.8544\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.8560\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.8569\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.8568\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4589 - accuracy: 0.8582\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4529 - accuracy: 0.8603\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4504 - accuracy: 0.8597\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4511 - accuracy: 0.8597\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4443 - accuracy: 0.8620\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4387 - accuracy: 0.8633\n",
      "Model: \"sequential_75\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_75 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_75 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_117 (Dense)           (None, 32)                25120     \n",
      "                                                                 \n",
      " dropout_40 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_118 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dropout_41 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_119 (Dense)           (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26,506\n",
      "Trainable params: 26,506\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "235/235 [==============================] - 1s 1ms/step - loss: 1.0053 - accuracy: 0.6894\n",
      "Epoch 2/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5838 - accuracy: 0.8204\n",
      "Epoch 3/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4936 - accuracy: 0.8487\n",
      "Epoch 4/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4450 - accuracy: 0.8621\n",
      "Epoch 5/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4136 - accuracy: 0.8729\n",
      "Epoch 6/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3931 - accuracy: 0.8775\n",
      "Epoch 7/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3763 - accuracy: 0.8820\n",
      "Epoch 8/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3593 - accuracy: 0.8886\n",
      "Epoch 9/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3520 - accuracy: 0.8910\n",
      "Epoch 10/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3425 - accuracy: 0.8945\n",
      "Epoch 11/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8976\n",
      "Epoch 12/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3269 - accuracy: 0.8998\n",
      "Epoch 13/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3169 - accuracy: 0.9012\n",
      "Epoch 14/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3112 - accuracy: 0.9039\n",
      "Epoch 15/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3079 - accuracy: 0.9054\n",
      "Epoch 16/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3039 - accuracy: 0.9068\n",
      "Epoch 17/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2968 - accuracy: 0.9076\n",
      "Epoch 18/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2941 - accuracy: 0.9086\n",
      "Epoch 19/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2908 - accuracy: 0.9103\n",
      "Epoch 20/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2873 - accuracy: 0.9105\n",
      "Epoch 21/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2816 - accuracy: 0.9118\n",
      "Epoch 22/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2826 - accuracy: 0.9114\n",
      "Epoch 23/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2770 - accuracy: 0.9129\n",
      "Epoch 24/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2768 - accuracy: 0.9136\n",
      "Epoch 25/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2728 - accuracy: 0.9161\n",
      "Model: \"sequential_76\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_76 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_76 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_120 (Dense)           (None, 32)                25120     \n",
      "                                                                 \n",
      " dropout_42 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_121 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dropout_43 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_122 (Dense)           (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26,506\n",
      "Trainable params: 26,506\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 1s 1ms/step - loss: 0.9675 - accuracy: 0.6961\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5729 - accuracy: 0.8235\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4846 - accuracy: 0.8490\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4403 - accuracy: 0.8628\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4112 - accuracy: 0.8727\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3858 - accuracy: 0.8798\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3702 - accuracy: 0.8838\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3580 - accuracy: 0.8881\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3482 - accuracy: 0.8919\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3444 - accuracy: 0.8935\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3347 - accuracy: 0.8958\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8988\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3183 - accuracy: 0.9002\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3161 - accuracy: 0.9017\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3098 - accuracy: 0.9027\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3066 - accuracy: 0.9041\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3004 - accuracy: 0.9064\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2958 - accuracy: 0.9069\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2914 - accuracy: 0.9084\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2905 - accuracy: 0.9091\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2887 - accuracy: 0.9094\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2838 - accuracy: 0.9118\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2834 - accuracy: 0.9105\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2779 - accuracy: 0.9123\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2790 - accuracy: 0.9112\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2738 - accuracy: 0.9144\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2700 - accuracy: 0.9153\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2717 - accuracy: 0.9145\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2725 - accuracy: 0.9130\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2648 - accuracy: 0.9162\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2658 - accuracy: 0.9157\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2613 - accuracy: 0.9179\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2588 - accuracy: 0.9185\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2605 - accuracy: 0.9176\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2592 - accuracy: 0.9182\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2550 - accuracy: 0.9182\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2549 - accuracy: 0.9191\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2541 - accuracy: 0.9203\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2559 - accuracy: 0.9196\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2533 - accuracy: 0.9205\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2462 - accuracy: 0.9221\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2460 - accuracy: 0.9223\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2508 - accuracy: 0.9206\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2471 - accuracy: 0.9216\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2465 - accuracy: 0.9231\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2458 - accuracy: 0.9229\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2439 - accuracy: 0.9236\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2411 - accuracy: 0.9243\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2409 - accuracy: 0.9236\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2402 - accuracy: 0.9236\n",
      "Model: \"sequential_77\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_77 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_77 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_123 (Dense)           (None, 32)                25120     \n",
      "                                                                 \n",
      " dropout_44 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_124 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dropout_45 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_125 (Dense)           (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26,506\n",
      "Trainable params: 26,506\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "235/235 [==============================] - 1s 1ms/step - loss: 0.7082 - accuracy: 0.7752\n",
      "Epoch 2/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4588 - accuracy: 0.8552\n",
      "Epoch 3/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4117 - accuracy: 0.8723\n",
      "Epoch 4/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3846 - accuracy: 0.8807\n",
      "Epoch 5/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3666 - accuracy: 0.8851\n",
      "Epoch 6/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3526 - accuracy: 0.8897\n",
      "Epoch 7/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3417 - accuracy: 0.8924\n",
      "Epoch 8/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3335 - accuracy: 0.8947\n",
      "Epoch 9/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8959\n",
      "Epoch 10/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3172 - accuracy: 0.9003\n",
      "Epoch 11/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3152 - accuracy: 0.8999\n",
      "Epoch 12/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3078 - accuracy: 0.9030\n",
      "Epoch 13/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3021 - accuracy: 0.9052\n",
      "Epoch 14/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2980 - accuracy: 0.9056\n",
      "Epoch 15/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2976 - accuracy: 0.9050\n",
      "Epoch 16/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2921 - accuracy: 0.9082\n",
      "Epoch 17/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2855 - accuracy: 0.9089\n",
      "Epoch 18/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2842 - accuracy: 0.9092\n",
      "Epoch 19/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2796 - accuracy: 0.9119\n",
      "Epoch 20/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2785 - accuracy: 0.9115\n",
      "Epoch 21/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2761 - accuracy: 0.9126\n",
      "Epoch 22/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2733 - accuracy: 0.9135\n",
      "Epoch 23/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2688 - accuracy: 0.9150\n",
      "Epoch 24/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2721 - accuracy: 0.9132\n",
      "Epoch 25/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2662 - accuracy: 0.9146\n",
      "Model: \"sequential_78\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_78 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_78 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_126 (Dense)           (None, 32)                25120     \n",
      "                                                                 \n",
      " dropout_46 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_127 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dropout_47 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_128 (Dense)           (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26,506\n",
      "Trainable params: 26,506\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 1s 1ms/step - loss: 0.7369 - accuracy: 0.7654\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4927 - accuracy: 0.8473\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4446 - accuracy: 0.8611\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4168 - accuracy: 0.8693\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3964 - accuracy: 0.8755\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3857 - accuracy: 0.8782\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3693 - accuracy: 0.8836\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3625 - accuracy: 0.8861\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3554 - accuracy: 0.8878\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3498 - accuracy: 0.8888\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3410 - accuracy: 0.8917\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3347 - accuracy: 0.8929\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3322 - accuracy: 0.8940\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8950\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3252 - accuracy: 0.8973\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3176 - accuracy: 0.8994\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3160 - accuracy: 0.8996\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3085 - accuracy: 0.9028\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3077 - accuracy: 0.9019\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3050 - accuracy: 0.9035\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3002 - accuracy: 0.9053\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2962 - accuracy: 0.9057\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2918 - accuracy: 0.9070\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2910 - accuracy: 0.9076\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2895 - accuracy: 0.9074\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2906 - accuracy: 0.9083\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2871 - accuracy: 0.9091\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2834 - accuracy: 0.9094\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2838 - accuracy: 0.9090\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2823 - accuracy: 0.9109\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2767 - accuracy: 0.9129\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2782 - accuracy: 0.9115\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2769 - accuracy: 0.9115\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2773 - accuracy: 0.9110\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2739 - accuracy: 0.9115\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2732 - accuracy: 0.9134\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2736 - accuracy: 0.9119\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2725 - accuracy: 0.9126\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2706 - accuracy: 0.9138\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2713 - accuracy: 0.9136\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2649 - accuracy: 0.9160\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2671 - accuracy: 0.9148\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2658 - accuracy: 0.9149\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2598 - accuracy: 0.9163\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2631 - accuracy: 0.9156\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2644 - accuracy: 0.9156\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2558 - accuracy: 0.9185\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2624 - accuracy: 0.9158\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2604 - accuracy: 0.9165\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2588 - accuracy: 0.9175\n",
      "Model: \"sequential_79\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_79 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_79 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_129 (Dense)           (None, 32)                25120     \n",
      "                                                                 \n",
      " dropout_48 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_130 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dropout_49 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_131 (Dense)           (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26,506\n",
      "Trainable params: 26,506\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 2.1176 - accuracy: 0.2493\n",
      "Epoch 2/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 1.7200 - accuracy: 0.4394\n",
      "Epoch 3/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 1.4497 - accuracy: 0.5338\n",
      "Epoch 4/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 1.2906 - accuracy: 0.5826\n",
      "Epoch 5/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 1.1802 - accuracy: 0.6204\n",
      "Epoch 6/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 1.0985 - accuracy: 0.6467\n",
      "Epoch 7/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 1.0422 - accuracy: 0.6650\n",
      "Epoch 8/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.9823 - accuracy: 0.6863\n",
      "Epoch 9/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.9494 - accuracy: 0.6965\n",
      "Epoch 10/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.9139 - accuracy: 0.7074\n",
      "Epoch 11/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.8854 - accuracy: 0.7158\n",
      "Epoch 12/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.8611 - accuracy: 0.7230\n",
      "Epoch 13/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.8395 - accuracy: 0.7320\n",
      "Epoch 14/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.8168 - accuracy: 0.7383\n",
      "Epoch 15/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.7999 - accuracy: 0.7424\n",
      "Epoch 16/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.7858 - accuracy: 0.7477\n",
      "Epoch 17/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.7760 - accuracy: 0.7510\n",
      "Epoch 18/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.7564 - accuracy: 0.7561\n",
      "Epoch 19/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.7468 - accuracy: 0.7615\n",
      "Epoch 20/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.7358 - accuracy: 0.7642\n",
      "Epoch 21/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.7247 - accuracy: 0.7689\n",
      "Epoch 22/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.7147 - accuracy: 0.7707\n",
      "Epoch 23/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.7030 - accuracy: 0.7754\n",
      "Epoch 24/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.7012 - accuracy: 0.7771\n",
      "Epoch 25/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6862 - accuracy: 0.7824\n",
      "Model: \"sequential_80\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_80 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_80 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_132 (Dense)           (None, 32)                25120     \n",
      "                                                                 \n",
      " dropout_50 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_133 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dropout_51 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_134 (Dense)           (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26,506\n",
      "Trainable params: 26,506\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 2.1089 - accuracy: 0.2305\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 1.7458 - accuracy: 0.3965\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 1.4908 - accuracy: 0.5044\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 1.3108 - accuracy: 0.5704\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 1.1974 - accuracy: 0.6117\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 1.1058 - accuracy: 0.6442\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 1.0402 - accuracy: 0.6664\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.9851 - accuracy: 0.6840\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.9439 - accuracy: 0.6978\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.9128 - accuracy: 0.7068\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.8844 - accuracy: 0.7167\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.8576 - accuracy: 0.7272\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.8345 - accuracy: 0.7331\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.8153 - accuracy: 0.7397\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.7989 - accuracy: 0.7453\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.7822 - accuracy: 0.7512\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.7682 - accuracy: 0.7556\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.7525 - accuracy: 0.7608\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.7430 - accuracy: 0.7648\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.7278 - accuracy: 0.7681\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.7149 - accuracy: 0.7742\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.7086 - accuracy: 0.7759\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.7017 - accuracy: 0.7788\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6909 - accuracy: 0.7817\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6774 - accuracy: 0.7865\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6707 - accuracy: 0.7880\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6637 - accuracy: 0.7920\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6574 - accuracy: 0.7933\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6496 - accuracy: 0.7987\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6480 - accuracy: 0.7969\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6392 - accuracy: 0.7987\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6321 - accuracy: 0.8024\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6296 - accuracy: 0.8011\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6214 - accuracy: 0.8051\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6133 - accuracy: 0.8063\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6128 - accuracy: 0.8077\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6073 - accuracy: 0.8094\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6058 - accuracy: 0.8092\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5963 - accuracy: 0.8143\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5965 - accuracy: 0.8119\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5914 - accuracy: 0.8159\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5900 - accuracy: 0.8153\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5877 - accuracy: 0.8159\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5815 - accuracy: 0.8186\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5765 - accuracy: 0.8195\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5742 - accuracy: 0.8205\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5713 - accuracy: 0.8186\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5665 - accuracy: 0.8232\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5659 - accuracy: 0.8222\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5592 - accuracy: 0.8254\n",
      "Model: \"sequential_81\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_81 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_81 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_135 (Dense)           (None, 32)                25120     \n",
      "                                                                 \n",
      " dropout_52 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_136 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dropout_53 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_137 (Dense)           (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26,506\n",
      "Trainable params: 26,506\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "235/235 [==============================] - 1s 1ms/step - loss: 1.1365 - accuracy: 0.6334\n",
      "Epoch 2/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.7088 - accuracy: 0.7799\n",
      "Epoch 3/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6055 - accuracy: 0.8130\n",
      "Epoch 4/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5591 - accuracy: 0.8267\n",
      "Epoch 5/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5244 - accuracy: 0.8367\n",
      "Epoch 6/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5046 - accuracy: 0.8440\n",
      "Epoch 7/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4869 - accuracy: 0.8482\n",
      "Epoch 8/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4717 - accuracy: 0.8533\n",
      "Epoch 9/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4630 - accuracy: 0.8571\n",
      "Epoch 10/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4509 - accuracy: 0.8620\n",
      "Epoch 11/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4401 - accuracy: 0.8633\n",
      "Epoch 12/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4378 - accuracy: 0.8651\n",
      "Epoch 13/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4339 - accuracy: 0.8662\n",
      "Epoch 14/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4210 - accuracy: 0.8698\n",
      "Epoch 15/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4196 - accuracy: 0.8707\n",
      "Epoch 16/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4158 - accuracy: 0.8722\n",
      "Epoch 17/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4076 - accuracy: 0.8745\n",
      "Epoch 18/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4063 - accuracy: 0.8757\n",
      "Epoch 19/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4017 - accuracy: 0.8767\n",
      "Epoch 20/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4015 - accuracy: 0.8755\n",
      "Epoch 21/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3899 - accuracy: 0.8788\n",
      "Epoch 22/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3930 - accuracy: 0.8776\n",
      "Epoch 23/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3858 - accuracy: 0.8803\n",
      "Epoch 24/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3871 - accuracy: 0.8819\n",
      "Epoch 25/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3844 - accuracy: 0.8802\n",
      "Model: \"sequential_82\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_82 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_82 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_138 (Dense)           (None, 32)                25120     \n",
      "                                                                 \n",
      " dropout_54 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_139 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dropout_55 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_140 (Dense)           (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26,506\n",
      "Trainable params: 26,506\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 1s 1ms/step - loss: 1.1217 - accuracy: 0.6375\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.7053 - accuracy: 0.7802\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6127 - accuracy: 0.8088\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5655 - accuracy: 0.8242\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5275 - accuracy: 0.8355\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5049 - accuracy: 0.8424\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4845 - accuracy: 0.8506\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4667 - accuracy: 0.8555\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4580 - accuracy: 0.8572\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4513 - accuracy: 0.8598\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4386 - accuracy: 0.8646\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4297 - accuracy: 0.8667\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4262 - accuracy: 0.8666\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4150 - accuracy: 0.8716\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4111 - accuracy: 0.8723\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4114 - accuracy: 0.8721\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4030 - accuracy: 0.8739\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4013 - accuracy: 0.8757\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3988 - accuracy: 0.8759\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3947 - accuracy: 0.8766\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3919 - accuracy: 0.8784\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3893 - accuracy: 0.8788\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3838 - accuracy: 0.8815\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3820 - accuracy: 0.8798\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3793 - accuracy: 0.8812\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3804 - accuracy: 0.8804\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3793 - accuracy: 0.8815\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3753 - accuracy: 0.8832\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3753 - accuracy: 0.8820\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3747 - accuracy: 0.8842\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3710 - accuracy: 0.8842\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3665 - accuracy: 0.8853\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3689 - accuracy: 0.8830\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3646 - accuracy: 0.8863\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3636 - accuracy: 0.8867\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3603 - accuracy: 0.8862\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3613 - accuracy: 0.8880\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3594 - accuracy: 0.8867\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3569 - accuracy: 0.8874\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3601 - accuracy: 0.8867\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3595 - accuracy: 0.8872\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3562 - accuracy: 0.8878\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3554 - accuracy: 0.8886\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3555 - accuracy: 0.8895\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3515 - accuracy: 0.8887\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3472 - accuracy: 0.8910\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3453 - accuracy: 0.8907\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3526 - accuracy: 0.8883\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3440 - accuracy: 0.8921\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3494 - accuracy: 0.8894\n",
      "Model: \"sequential_83\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_83 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_83 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_141 (Dense)           (None, 32)                25120     \n",
      "                                                                 \n",
      " dropout_56 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_142 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dropout_57 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_143 (Dense)           (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26,506\n",
      "Trainable params: 26,506\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "235/235 [==============================] - 1s 1ms/step - loss: 0.8559 - accuracy: 0.7231\n",
      "Epoch 2/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6062 - accuracy: 0.8075\n",
      "Epoch 3/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5553 - accuracy: 0.8244\n",
      "Epoch 4/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5347 - accuracy: 0.8323\n",
      "Epoch 5/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5153 - accuracy: 0.8384\n",
      "Epoch 6/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5025 - accuracy: 0.8417\n",
      "Epoch 7/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4953 - accuracy: 0.8429\n",
      "Epoch 8/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4823 - accuracy: 0.8492\n",
      "Epoch 9/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4727 - accuracy: 0.8527\n",
      "Epoch 10/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4698 - accuracy: 0.8525\n",
      "Epoch 11/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4665 - accuracy: 0.8548\n",
      "Epoch 12/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4656 - accuracy: 0.8554\n",
      "Epoch 13/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4530 - accuracy: 0.8585\n",
      "Epoch 14/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4511 - accuracy: 0.8595\n",
      "Epoch 15/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4521 - accuracy: 0.8599\n",
      "Epoch 16/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4509 - accuracy: 0.8602\n",
      "Epoch 17/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4421 - accuracy: 0.8613\n",
      "Epoch 18/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4409 - accuracy: 0.8616\n",
      "Epoch 19/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4384 - accuracy: 0.8624\n",
      "Epoch 20/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4331 - accuracy: 0.8640\n",
      "Epoch 21/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4343 - accuracy: 0.8655\n",
      "Epoch 22/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4327 - accuracy: 0.8648\n",
      "Epoch 23/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4273 - accuracy: 0.8655\n",
      "Epoch 24/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4262 - accuracy: 0.8669\n",
      "Epoch 25/25\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4205 - accuracy: 0.8686\n",
      "Model: \"sequential_84\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_84 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_84 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_144 (Dense)           (None, 32)                25120     \n",
      "                                                                 \n",
      " dropout_58 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_145 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " dropout_59 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_146 (Dense)           (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26,506\n",
      "Trainable params: 26,506\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 1s 1ms/step - loss: 0.8546 - accuracy: 0.7243\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.5941 - accuracy: 0.8138\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5512 - accuracy: 0.8283\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5212 - accuracy: 0.8376\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.8437\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4846 - accuracy: 0.8507\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.8507\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.4715 - accuracy: 0.8528\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4613 - accuracy: 0.8558\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4567 - accuracy: 0.8570\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.4488 - accuracy: 0.8608\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4443 - accuracy: 0.8608\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4420 - accuracy: 0.8617\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.8630\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4366 - accuracy: 0.8620\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.8656\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4222 - accuracy: 0.8680\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.4212 - accuracy: 0.8669\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.4192 - accuracy: 0.8668\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.4183 - accuracy: 0.8687\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4144 - accuracy: 0.8699\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.4097 - accuracy: 0.8720\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.4102 - accuracy: 0.8706\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4106 - accuracy: 0.8700\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4049 - accuracy: 0.8730\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4051 - accuracy: 0.8720\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.4028 - accuracy: 0.8722\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.4020 - accuracy: 0.8720\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4007 - accuracy: 0.8739\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4002 - accuracy: 0.8754\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3977 - accuracy: 0.8748\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3957 - accuracy: 0.8751\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3932 - accuracy: 0.8752\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3916 - accuracy: 0.8747\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3880 - accuracy: 0.8778\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3919 - accuracy: 0.8755\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3870 - accuracy: 0.8774\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8782\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3832 - accuracy: 0.8773\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3836 - accuracy: 0.8786\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3829 - accuracy: 0.8792\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3801 - accuracy: 0.8801\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3823 - accuracy: 0.8808\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3798 - accuracy: 0.8802\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3786 - accuracy: 0.8800\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3773 - accuracy: 0.8814\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3811 - accuracy: 0.8785\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3738 - accuracy: 0.8812\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3770 - accuracy: 0.8804\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3750 - accuracy: 0.8795\n",
      "Model: \"sequential_85\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_85 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_85 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_147 (Dense)           (None, 128)               100480    \n",
      "                                                                 \n",
      " dropout_60 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_148 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_61 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_149 (Dense)           (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 1.9703 - accuracy: 0.3580\n",
      "Epoch 2/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 1.2997 - accuracy: 0.6319\n",
      "Epoch 3/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.9964 - accuracy: 0.7062\n",
      "Epoch 4/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.8522 - accuracy: 0.7455\n",
      "Epoch 5/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.7671 - accuracy: 0.7678\n",
      "Epoch 6/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.7065 - accuracy: 0.7863\n",
      "Epoch 7/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.6616 - accuracy: 0.7997\n",
      "Epoch 8/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.6251 - accuracy: 0.8099\n",
      "Epoch 9/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.5979 - accuracy: 0.8182\n",
      "Epoch 10/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.5743 - accuracy: 0.8263\n",
      "Epoch 11/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.5545 - accuracy: 0.8310\n",
      "Epoch 12/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.5354 - accuracy: 0.8374\n",
      "Epoch 13/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.5142 - accuracy: 0.8446\n",
      "Epoch 14/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.5000 - accuracy: 0.8478\n",
      "Epoch 15/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.4869 - accuracy: 0.8522\n",
      "Epoch 16/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.4781 - accuracy: 0.8528\n",
      "Epoch 17/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.4640 - accuracy: 0.8588\n",
      "Epoch 18/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.4545 - accuracy: 0.8617\n",
      "Epoch 19/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.4435 - accuracy: 0.8652\n",
      "Epoch 20/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.4315 - accuracy: 0.8688\n",
      "Epoch 21/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.4267 - accuracy: 0.8706\n",
      "Epoch 22/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.4185 - accuracy: 0.8715\n",
      "Epoch 23/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.4092 - accuracy: 0.8752\n",
      "Epoch 24/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.4021 - accuracy: 0.8781\n",
      "Epoch 25/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.3947 - accuracy: 0.8799\n",
      "Model: \"sequential_86\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_86 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_86 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_150 (Dense)           (None, 128)               100480    \n",
      "                                                                 \n",
      " dropout_62 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_151 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_63 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_152 (Dense)           (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 1.8970 - accuracy: 0.3981\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 1.2420 - accuracy: 0.6376\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.9724 - accuracy: 0.7118\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.8420 - accuracy: 0.7477\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.7625 - accuracy: 0.7714\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.7062 - accuracy: 0.7864\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6652 - accuracy: 0.7987\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.6323 - accuracy: 0.8083\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.6036 - accuracy: 0.8168\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.5800 - accuracy: 0.8245\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.5598 - accuracy: 0.8294\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.5408 - accuracy: 0.8361\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.5203 - accuracy: 0.8424\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.8446\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.4924 - accuracy: 0.8490\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.4798 - accuracy: 0.8534\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.4659 - accuracy: 0.8580\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.4568 - accuracy: 0.8602\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.8653\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.4349 - accuracy: 0.8672\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.8704\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.8733\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.4091 - accuracy: 0.8738\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.4022 - accuracy: 0.8774\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.3962 - accuracy: 0.8787\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3884 - accuracy: 0.8820\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3812 - accuracy: 0.8840\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.3751 - accuracy: 0.8864\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.3685 - accuracy: 0.8888\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3632 - accuracy: 0.8906\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3557 - accuracy: 0.8932\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.3507 - accuracy: 0.8945\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.3468 - accuracy: 0.8925\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.3431 - accuracy: 0.8957\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3340 - accuracy: 0.8977\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.3325 - accuracy: 0.8985\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3290 - accuracy: 0.8990\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.3206 - accuracy: 0.9013\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.3215 - accuracy: 0.9027\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3155 - accuracy: 0.9048\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3107 - accuracy: 0.9061\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.3061 - accuracy: 0.9069\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3048 - accuracy: 0.9072\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.2980 - accuracy: 0.9102\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.2960 - accuracy: 0.9100\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.2936 - accuracy: 0.9115\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.2859 - accuracy: 0.9129\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.2867 - accuracy: 0.9135\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.2835 - accuracy: 0.9140\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.2802 - accuracy: 0.9153\n",
      "Model: \"sequential_87\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_87 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_87 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_153 (Dense)           (None, 128)               100480    \n",
      "                                                                 \n",
      " dropout_64 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_154 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_65 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_155 (Dense)           (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.5879 - accuracy: 0.8194\n",
      "Epoch 2/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.3007 - accuracy: 0.9077\n",
      "Epoch 3/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.2269 - accuracy: 0.9308\n",
      "Epoch 4/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.1829 - accuracy: 0.9443\n",
      "Epoch 5/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.1571 - accuracy: 0.9524\n",
      "Epoch 6/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.1352 - accuracy: 0.9586\n",
      "Epoch 7/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.1178 - accuracy: 0.9635\n",
      "Epoch 8/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.1044 - accuracy: 0.9674\n",
      "Epoch 9/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0968 - accuracy: 0.9692\n",
      "Epoch 10/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0852 - accuracy: 0.9736\n",
      "Epoch 11/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0768 - accuracy: 0.9750\n",
      "Epoch 12/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0723 - accuracy: 0.9766\n",
      "Epoch 13/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0660 - accuracy: 0.9785\n",
      "Epoch 14/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0637 - accuracy: 0.9793\n",
      "Epoch 15/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0565 - accuracy: 0.9822\n",
      "Epoch 16/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0525 - accuracy: 0.9835\n",
      "Epoch 17/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0528 - accuracy: 0.9830\n",
      "Epoch 18/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0477 - accuracy: 0.9844\n",
      "Epoch 19/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0470 - accuracy: 0.9846\n",
      "Epoch 20/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0437 - accuracy: 0.9858\n",
      "Epoch 21/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0411 - accuracy: 0.9870\n",
      "Epoch 22/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0394 - accuracy: 0.9868\n",
      "Epoch 23/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0388 - accuracy: 0.9869\n",
      "Epoch 24/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0374 - accuracy: 0.9877\n",
      "Epoch 25/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0339 - accuracy: 0.9890\n",
      "Model: \"sequential_88\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_88 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_88 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_156 (Dense)           (None, 128)               100480    \n",
      "                                                                 \n",
      " dropout_66 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_157 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_67 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_158 (Dense)           (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.5894 - accuracy: 0.8211\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.2998 - accuracy: 0.9097\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.2228 - accuracy: 0.9328\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.1817 - accuracy: 0.9439\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.1542 - accuracy: 0.9536\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.1362 - accuracy: 0.9577\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.1195 - accuracy: 0.9632\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.1070 - accuracy: 0.9676\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0957 - accuracy: 0.9707\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0878 - accuracy: 0.9727\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0807 - accuracy: 0.9745\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0729 - accuracy: 0.9779\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0678 - accuracy: 0.9781\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0618 - accuracy: 0.9798\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0578 - accuracy: 0.9808\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0546 - accuracy: 0.9819\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0498 - accuracy: 0.9836\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0482 - accuracy: 0.9841\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0458 - accuracy: 0.9848\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0452 - accuracy: 0.9857\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0421 - accuracy: 0.9863\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0390 - accuracy: 0.9871\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0372 - accuracy: 0.9878\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0355 - accuracy: 0.9882\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0357 - accuracy: 0.9884\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0368 - accuracy: 0.9880\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0331 - accuracy: 0.9892\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0307 - accuracy: 0.9898\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0303 - accuracy: 0.9902\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0303 - accuracy: 0.9901\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0300 - accuracy: 0.9905\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0296 - accuracy: 0.9899\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0287 - accuracy: 0.9905\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0290 - accuracy: 0.9909\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0268 - accuracy: 0.9909\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0266 - accuracy: 0.9914\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0274 - accuracy: 0.9911\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0255 - accuracy: 0.9914\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0249 - accuracy: 0.9919\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0236 - accuracy: 0.9925\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0234 - accuracy: 0.9922\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0239 - accuracy: 0.9922\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0231 - accuracy: 0.9925\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0213 - accuracy: 0.9931\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0221 - accuracy: 0.9927\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0207 - accuracy: 0.9931\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0227 - accuracy: 0.9930\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0226 - accuracy: 0.9925\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0229 - accuracy: 0.9923\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0223 - accuracy: 0.9929\n",
      "Model: \"sequential_89\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_89 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_89 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_159 (Dense)           (None, 128)               100480    \n",
      "                                                                 \n",
      " dropout_68 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_160 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_69 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_161 (Dense)           (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.4277 - accuracy: 0.8661\n",
      "Epoch 2/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.2143 - accuracy: 0.9355\n",
      "Epoch 3/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.1624 - accuracy: 0.9502\n",
      "Epoch 4/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.1362 - accuracy: 0.9592\n",
      "Epoch 5/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.1171 - accuracy: 0.9635\n",
      "Epoch 6/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.1018 - accuracy: 0.9683\n",
      "Epoch 7/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0888 - accuracy: 0.9718\n",
      "Epoch 8/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0804 - accuracy: 0.9749\n",
      "Epoch 9/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0744 - accuracy: 0.9761\n",
      "Epoch 10/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0672 - accuracy: 0.9789\n",
      "Epoch 11/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0650 - accuracy: 0.9794\n",
      "Epoch 12/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0577 - accuracy: 0.9817\n",
      "Epoch 13/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0542 - accuracy: 0.9827\n",
      "Epoch 14/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0520 - accuracy: 0.9830\n",
      "Epoch 15/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0491 - accuracy: 0.9844\n",
      "Epoch 16/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0442 - accuracy: 0.9857\n",
      "Epoch 17/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0432 - accuracy: 0.9858\n",
      "Epoch 18/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0406 - accuracy: 0.9868\n",
      "Epoch 19/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0399 - accuracy: 0.9873\n",
      "Epoch 20/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0386 - accuracy: 0.9873\n",
      "Epoch 21/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0366 - accuracy: 0.9877\n",
      "Epoch 22/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0352 - accuracy: 0.9879\n",
      "Epoch 23/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0342 - accuracy: 0.9883\n",
      "Epoch 24/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0323 - accuracy: 0.9894\n",
      "Epoch 25/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0315 - accuracy: 0.9896\n",
      "Model: \"sequential_90\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_90 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_90 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_162 (Dense)           (None, 128)               100480    \n",
      "                                                                 \n",
      " dropout_70 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_163 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_71 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_164 (Dense)           (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.4197 - accuracy: 0.8707\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.2092 - accuracy: 0.9357\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.1637 - accuracy: 0.9502\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.1369 - accuracy: 0.9577\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.1151 - accuracy: 0.9644\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.1006 - accuracy: 0.9686\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0913 - accuracy: 0.9716\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0829 - accuracy: 0.9737\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0767 - accuracy: 0.9756\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0684 - accuracy: 0.9778\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0628 - accuracy: 0.9797\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0598 - accuracy: 0.9810\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0559 - accuracy: 0.9820\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0518 - accuracy: 0.9835\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0489 - accuracy: 0.9842\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0460 - accuracy: 0.9854\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0440 - accuracy: 0.9859\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0425 - accuracy: 0.9865\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0404 - accuracy: 0.9866\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0390 - accuracy: 0.9873\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0366 - accuracy: 0.9880\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0374 - accuracy: 0.9879\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0343 - accuracy: 0.9887\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0339 - accuracy: 0.9891\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0319 - accuracy: 0.9895\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0308 - accuracy: 0.9898\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0328 - accuracy: 0.9894\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0316 - accuracy: 0.9897\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0305 - accuracy: 0.9902\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0312 - accuracy: 0.9901\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0278 - accuracy: 0.9910\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0271 - accuracy: 0.9914\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0279 - accuracy: 0.9908\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0258 - accuracy: 0.9915\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0251 - accuracy: 0.9919\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0266 - accuracy: 0.9910\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0241 - accuracy: 0.9919\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0233 - accuracy: 0.9927\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0237 - accuracy: 0.9921\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0247 - accuracy: 0.9920\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0235 - accuracy: 0.9922\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0241 - accuracy: 0.9919\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0240 - accuracy: 0.9923\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0233 - accuracy: 0.9922\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0217 - accuracy: 0.9929\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0249 - accuracy: 0.9919\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0220 - accuracy: 0.9925\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0225 - accuracy: 0.9926\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0209 - accuracy: 0.9934\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0198 - accuracy: 0.9938\n",
      "Model: \"sequential_91\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_91 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_91 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_165 (Dense)           (None, 128)               100480    \n",
      "                                                                 \n",
      " dropout_72 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_166 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_73 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_167 (Dense)           (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 1.9956 - accuracy: 0.3301\n",
      "Epoch 2/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 1.3853 - accuracy: 0.5815\n",
      "Epoch 3/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 1.1139 - accuracy: 0.6610\n",
      "Epoch 4/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.9679 - accuracy: 0.7076\n",
      "Epoch 5/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.8802 - accuracy: 0.7312\n",
      "Epoch 6/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.8129 - accuracy: 0.7536\n",
      "Epoch 7/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.7665 - accuracy: 0.7688\n",
      "Epoch 8/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.7235 - accuracy: 0.7800\n",
      "Epoch 9/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6956 - accuracy: 0.7882\n",
      "Epoch 10/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6690 - accuracy: 0.7953\n",
      "Epoch 11/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6453 - accuracy: 0.8039\n",
      "Epoch 12/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6217 - accuracy: 0.8109\n",
      "Epoch 13/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6026 - accuracy: 0.8153\n",
      "Epoch 14/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.5856 - accuracy: 0.8198\n",
      "Epoch 15/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.5706 - accuracy: 0.8254\n",
      "Epoch 16/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.5543 - accuracy: 0.8307\n",
      "Epoch 17/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.5403 - accuracy: 0.8340\n",
      "Epoch 18/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.5275 - accuracy: 0.8387\n",
      "Epoch 19/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.5181 - accuracy: 0.8402\n",
      "Epoch 20/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.8443\n",
      "Epoch 21/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.4967 - accuracy: 0.8481\n",
      "Epoch 22/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.4874 - accuracy: 0.8497\n",
      "Epoch 23/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.4781 - accuracy: 0.8536\n",
      "Epoch 24/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.8559\n",
      "Epoch 25/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.8586\n",
      "Model: \"sequential_92\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_92 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_92 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_168 (Dense)           (None, 128)               100480    \n",
      "                                                                 \n",
      " dropout_74 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_169 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_75 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_170 (Dense)           (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 1.9967 - accuracy: 0.3315\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 1.3685 - accuracy: 0.5895\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 1.0849 - accuracy: 0.6664\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.9396 - accuracy: 0.7124\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.8450 - accuracy: 0.7408\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.7870 - accuracy: 0.7579\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.7348 - accuracy: 0.7740\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.7873\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6621 - accuracy: 0.7952\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6335 - accuracy: 0.8041\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6108 - accuracy: 0.8115\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.5902 - accuracy: 0.8182\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.5711 - accuracy: 0.8235\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.5521 - accuracy: 0.8310\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.5373 - accuracy: 0.8336\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.5274 - accuracy: 0.8364\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.5121 - accuracy: 0.8434\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.4999 - accuracy: 0.8452\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.4879 - accuracy: 0.8485\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.4805 - accuracy: 0.8522\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.4707 - accuracy: 0.8565\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.8587\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.4558 - accuracy: 0.8613\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.4483 - accuracy: 0.8613\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.8648\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.8679\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.4223 - accuracy: 0.8711\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.4175 - accuracy: 0.8721\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.4124 - accuracy: 0.8730\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.4052 - accuracy: 0.8764\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.4026 - accuracy: 0.8760\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3978 - accuracy: 0.8786\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3922 - accuracy: 0.8799\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3875 - accuracy: 0.8813\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3821 - accuracy: 0.8833\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3766 - accuracy: 0.8845\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3712 - accuracy: 0.8866\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3676 - accuracy: 0.8878\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3612 - accuracy: 0.8895\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3620 - accuracy: 0.8892\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3549 - accuracy: 0.8912\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3522 - accuracy: 0.8930\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3449 - accuracy: 0.8946\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3426 - accuracy: 0.8947\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3411 - accuracy: 0.8954\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3370 - accuracy: 0.8973\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3342 - accuracy: 0.8985\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3292 - accuracy: 0.8993\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3264 - accuracy: 0.9003\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.3250 - accuracy: 0.9011\n",
      "Model: \"sequential_93\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_93 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_93 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_171 (Dense)           (None, 128)               100480    \n",
      "                                                                 \n",
      " dropout_76 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_172 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_77 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_173 (Dense)           (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.6458 - accuracy: 0.8015\n",
      "Epoch 2/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.3373 - accuracy: 0.8967\n",
      "Epoch 3/25\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2661 - accuracy: 0.9183\n",
      "Epoch 4/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.2204 - accuracy: 0.9323\n",
      "Epoch 5/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.1943 - accuracy: 0.9404\n",
      "Epoch 6/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.1706 - accuracy: 0.9472\n",
      "Epoch 7/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.1584 - accuracy: 0.9511\n",
      "Epoch 8/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.1464 - accuracy: 0.9542\n",
      "Epoch 9/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.1355 - accuracy: 0.9571\n",
      "Epoch 10/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.1299 - accuracy: 0.9597\n",
      "Epoch 11/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.1217 - accuracy: 0.9620\n",
      "Epoch 12/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.1153 - accuracy: 0.9630\n",
      "Epoch 13/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.1098 - accuracy: 0.9649\n",
      "Epoch 14/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.1042 - accuracy: 0.9665\n",
      "Epoch 15/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0974 - accuracy: 0.9690\n",
      "Epoch 16/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0954 - accuracy: 0.9698\n",
      "Epoch 17/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0916 - accuracy: 0.9704\n",
      "Epoch 18/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0907 - accuracy: 0.9715\n",
      "Epoch 19/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0854 - accuracy: 0.9718\n",
      "Epoch 20/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0821 - accuracy: 0.9741\n",
      "Epoch 21/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0830 - accuracy: 0.9733\n",
      "Epoch 22/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0786 - accuracy: 0.9746\n",
      "Epoch 23/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0743 - accuracy: 0.9758\n",
      "Epoch 24/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0730 - accuracy: 0.9757\n",
      "Epoch 25/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0733 - accuracy: 0.9760\n",
      "Model: \"sequential_94\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_94 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_94 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_174 (Dense)           (None, 128)               100480    \n",
      "                                                                 \n",
      " dropout_78 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_175 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_79 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_176 (Dense)           (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.6564 - accuracy: 0.7976\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.3477 - accuracy: 0.8943\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.2727 - accuracy: 0.9168\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2307 - accuracy: 0.9299\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2024 - accuracy: 0.9389\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1788 - accuracy: 0.9451\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1648 - accuracy: 0.9488\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.1542 - accuracy: 0.9520\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1394 - accuracy: 0.9568\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1323 - accuracy: 0.9592\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1215 - accuracy: 0.9624\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1185 - accuracy: 0.9622\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1116 - accuracy: 0.9646\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1031 - accuracy: 0.9677\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0993 - accuracy: 0.9684\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0959 - accuracy: 0.9694\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0905 - accuracy: 0.9708\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0894 - accuracy: 0.9710\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0827 - accuracy: 0.9735\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0816 - accuracy: 0.9733\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0803 - accuracy: 0.9737\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0803 - accuracy: 0.9736\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0767 - accuracy: 0.9747\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0747 - accuracy: 0.9755\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0740 - accuracy: 0.9765\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0686 - accuracy: 0.9780\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0671 - accuracy: 0.9782\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0651 - accuracy: 0.9791\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0695 - accuracy: 0.9776\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0659 - accuracy: 0.9786\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0623 - accuracy: 0.9800\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0653 - accuracy: 0.9789\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0624 - accuracy: 0.9792\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0586 - accuracy: 0.9809\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0592 - accuracy: 0.9807\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0587 - accuracy: 0.9810\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0588 - accuracy: 0.9816\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0577 - accuracy: 0.9816\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0550 - accuracy: 0.9821\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0570 - accuracy: 0.9819\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0537 - accuracy: 0.9825\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0519 - accuracy: 0.9832\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0553 - accuracy: 0.9822\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0536 - accuracy: 0.9830\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0512 - accuracy: 0.9837\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0521 - accuracy: 0.9836\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0511 - accuracy: 0.9838\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0510 - accuracy: 0.9837\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0514 - accuracy: 0.9833\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0498 - accuracy: 0.9840\n",
      "Model: \"sequential_95\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_95 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_95 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_177 (Dense)           (None, 128)               100480    \n",
      "                                                                 \n",
      " dropout_80 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_178 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_81 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_179 (Dense)           (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.4820 - accuracy: 0.8483\n",
      "Epoch 2/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.2600 - accuracy: 0.9205\n",
      "Epoch 3/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.2141 - accuracy: 0.9349\n",
      "Epoch 4/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.1826 - accuracy: 0.9434\n",
      "Epoch 5/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.1661 - accuracy: 0.9487\n",
      "Epoch 6/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.1485 - accuracy: 0.9543\n",
      "Epoch 7/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.1380 - accuracy: 0.9566\n",
      "Epoch 8/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.1298 - accuracy: 0.9592\n",
      "Epoch 9/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.1211 - accuracy: 0.9614\n",
      "Epoch 10/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.1126 - accuracy: 0.9642\n",
      "Epoch 11/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.1081 - accuracy: 0.9653\n",
      "Epoch 12/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.1002 - accuracy: 0.9673\n",
      "Epoch 13/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0958 - accuracy: 0.9694\n",
      "Epoch 14/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0959 - accuracy: 0.9693\n",
      "Epoch 15/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0889 - accuracy: 0.9718\n",
      "Epoch 16/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0862 - accuracy: 0.9722\n",
      "Epoch 17/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0824 - accuracy: 0.9728\n",
      "Epoch 18/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0816 - accuracy: 0.9731\n",
      "Epoch 19/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0774 - accuracy: 0.9748\n",
      "Epoch 20/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0769 - accuracy: 0.9753\n",
      "Epoch 21/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0754 - accuracy: 0.9749\n",
      "Epoch 22/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0727 - accuracy: 0.9760\n",
      "Epoch 23/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0734 - accuracy: 0.9756\n",
      "Epoch 24/25\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0670 - accuracy: 0.9784\n",
      "Epoch 25/25\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0667 - accuracy: 0.9780\n",
      "Model: \"sequential_96\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_96 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_96 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_180 (Dense)           (None, 128)               100480    \n",
      "                                                                 \n",
      " dropout_82 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_181 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_83 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_182 (Dense)           (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.4852 - accuracy: 0.8477\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.2629 - accuracy: 0.9191\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.2164 - accuracy: 0.9329\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.1869 - accuracy: 0.9422\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.1682 - accuracy: 0.9479\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.1531 - accuracy: 0.9525\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.1406 - accuracy: 0.9554\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.1282 - accuracy: 0.9604\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.1235 - accuracy: 0.9609\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.1161 - accuracy: 0.9630\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.1109 - accuracy: 0.9640\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.1065 - accuracy: 0.9657\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.1002 - accuracy: 0.9674\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0967 - accuracy: 0.9689\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0930 - accuracy: 0.9694\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0885 - accuracy: 0.9711\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0839 - accuracy: 0.9726\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0846 - accuracy: 0.9725\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0816 - accuracy: 0.9729\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0779 - accuracy: 0.9746\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0767 - accuracy: 0.9753\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0734 - accuracy: 0.9754\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0731 - accuracy: 0.9761\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0693 - accuracy: 0.9773\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0673 - accuracy: 0.9781\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0661 - accuracy: 0.9784\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0649 - accuracy: 0.9787\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0622 - accuracy: 0.9797\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0627 - accuracy: 0.9791\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0632 - accuracy: 0.9785\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0582 - accuracy: 0.9800\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0584 - accuracy: 0.9805\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0596 - accuracy: 0.9808\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0583 - accuracy: 0.9809\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0542 - accuracy: 0.9823\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0548 - accuracy: 0.9820\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0579 - accuracy: 0.9811\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0545 - accuracy: 0.9822\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0533 - accuracy: 0.9823\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0527 - accuracy: 0.9821\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0507 - accuracy: 0.9834\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0508 - accuracy: 0.9830\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0507 - accuracy: 0.9832\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0503 - accuracy: 0.9841\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0489 - accuracy: 0.9840\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0495 - accuracy: 0.9837\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0460 - accuracy: 0.9852\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0478 - accuracy: 0.9842\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0469 - accuracy: 0.9843\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.0469 - accuracy: 0.9846\n",
      "Model: \"sequential_97\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_97 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_97 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_183 (Dense)           (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_84 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_184 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_85 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_185 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 1.7166 - accuracy: 0.5194\n",
      "Epoch 2/25\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 1.0477 - accuracy: 0.7132\n",
      "Epoch 3/25\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.8214 - accuracy: 0.7628\n",
      "Epoch 4/25\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.7169 - accuracy: 0.7899\n",
      "Epoch 5/25\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.6527 - accuracy: 0.8068\n",
      "Epoch 6/25\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.6091 - accuracy: 0.8196\n",
      "Epoch 7/25\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.5739 - accuracy: 0.8293\n",
      "Epoch 8/25\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.5454 - accuracy: 0.8371\n",
      "Epoch 9/25\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.5233 - accuracy: 0.8443\n",
      "Epoch 10/25\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.5015 - accuracy: 0.8518\n",
      "Epoch 11/25\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.4819 - accuracy: 0.8567\n",
      "Epoch 12/25\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.4644 - accuracy: 0.8623\n",
      "Epoch 13/25\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.4501 - accuracy: 0.8660\n",
      "Epoch 14/25\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.4349 - accuracy: 0.8694\n",
      "Epoch 15/25\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.4221 - accuracy: 0.8746\n",
      "Epoch 16/25\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.4090 - accuracy: 0.8786\n",
      "Epoch 17/25\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.3975 - accuracy: 0.8827\n",
      "Epoch 18/25\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.3870 - accuracy: 0.8852\n",
      "Epoch 19/25\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.3761 - accuracy: 0.8883\n",
      "Epoch 20/25\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.3692 - accuracy: 0.8902\n",
      "Epoch 21/25\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.3594 - accuracy: 0.8929\n",
      "Epoch 22/25\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.3507 - accuracy: 0.8967\n",
      "Epoch 23/25\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.3422 - accuracy: 0.8991\n",
      "Epoch 24/25\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.3350 - accuracy: 0.9015\n",
      "Epoch 25/25\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.3290 - accuracy: 0.9026\n",
      "Model: \"sequential_98\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_98 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_98 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_186 (Dense)           (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_86 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_187 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_87 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_188 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 1.7244 - accuracy: 0.5161\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 1.0408 - accuracy: 0.7148\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.8136 - accuracy: 0.7670\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.7100 - accuracy: 0.7932\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.6454 - accuracy: 0.8096\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.5996 - accuracy: 0.8228\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.5670 - accuracy: 0.8315\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.5368 - accuracy: 0.8392\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.5126 - accuracy: 0.8482\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.4918 - accuracy: 0.8528\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.4730 - accuracy: 0.8597\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.4563 - accuracy: 0.8643\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.4385 - accuracy: 0.8698\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.4246 - accuracy: 0.8746\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.4125 - accuracy: 0.8778\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.3998 - accuracy: 0.8812\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.3883 - accuracy: 0.8859\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.3764 - accuracy: 0.8885\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.3682 - accuracy: 0.8906\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.3586 - accuracy: 0.8939\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.3501 - accuracy: 0.8963\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.3412 - accuracy: 0.8988\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.3326 - accuracy: 0.9022\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.3275 - accuracy: 0.9029\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.3203 - accuracy: 0.9061\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.3113 - accuracy: 0.9081\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.3050 - accuracy: 0.9099\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.3022 - accuracy: 0.9103\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.2944 - accuracy: 0.9140\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.2896 - accuracy: 0.9147\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.2838 - accuracy: 0.9166\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.2778 - accuracy: 0.9179\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.2736 - accuracy: 0.9191\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.2678 - accuracy: 0.9216\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.2632 - accuracy: 0.9225\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.2603 - accuracy: 0.9240\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.2534 - accuracy: 0.9261\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.2514 - accuracy: 0.9266\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.2461 - accuracy: 0.9277\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.2412 - accuracy: 0.9292\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.2376 - accuracy: 0.9305\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.2341 - accuracy: 0.9315\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.2302 - accuracy: 0.9325\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.2280 - accuracy: 0.9336\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.2241 - accuracy: 0.9354\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.2183 - accuracy: 0.9366\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.2181 - accuracy: 0.9362\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.2135 - accuracy: 0.9375\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.2096 - accuracy: 0.9391\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.2072 - accuracy: 0.9396\n",
      "Model: \"sequential_99\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_99 (Rescaling)    (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_99 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_189 (Dense)           (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_88 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_190 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_89 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_191 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.4296 - accuracy: 0.8669\n",
      "Epoch 2/25\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.1688 - accuracy: 0.9486\n",
      "Epoch 3/25\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.1067 - accuracy: 0.9681\n",
      "Epoch 4/25\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0704 - accuracy: 0.9783\n",
      "Epoch 5/25\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0509 - accuracy: 0.9842\n",
      "Epoch 6/25\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0374 - accuracy: 0.9877\n",
      "Epoch 7/25\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0305 - accuracy: 0.9904\n",
      "Epoch 8/25\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0238 - accuracy: 0.9921\n",
      "Epoch 9/25\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0207 - accuracy: 0.9934\n",
      "Epoch 10/25\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0161 - accuracy: 0.9950\n",
      "Epoch 11/25\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0154 - accuracy: 0.9949\n",
      "Epoch 12/25\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0132 - accuracy: 0.9955\n",
      "Epoch 13/25\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0129 - accuracy: 0.9958\n",
      "Epoch 14/25\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0122 - accuracy: 0.9959\n",
      "Epoch 15/25\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0113 - accuracy: 0.9964\n",
      "Epoch 16/25\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0101 - accuracy: 0.9969\n",
      "Epoch 17/25\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0102 - accuracy: 0.9968\n",
      "Epoch 18/25\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0090 - accuracy: 0.9971\n",
      "Epoch 19/25\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0096 - accuracy: 0.9969\n",
      "Epoch 20/25\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0087 - accuracy: 0.9974\n",
      "Epoch 21/25\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0086 - accuracy: 0.9972\n",
      "Epoch 22/25\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0083 - accuracy: 0.9976\n",
      "Epoch 23/25\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0084 - accuracy: 0.9975\n",
      "Epoch 24/25\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0074 - accuracy: 0.9977\n",
      "Epoch 25/25\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0073 - accuracy: 0.9974\n",
      "Model: \"sequential_100\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_100 (Rescaling)   (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_100 (Flatten)       (None, 784)               0         \n",
      "                                                                 \n",
      " dense_192 (Dense)           (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_90 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_193 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_91 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_194 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.4258 - accuracy: 0.8666\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.1642 - accuracy: 0.9501\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.1026 - accuracy: 0.9679\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0713 - accuracy: 0.9771\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0512 - accuracy: 0.9837\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0381 - accuracy: 0.9879\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0297 - accuracy: 0.9906\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0256 - accuracy: 0.9919\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0198 - accuracy: 0.9933\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0176 - accuracy: 0.9939\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0146 - accuracy: 0.9952\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0141 - accuracy: 0.9954\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0130 - accuracy: 0.9957\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0123 - accuracy: 0.9959\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0112 - accuracy: 0.9963\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0091 - accuracy: 0.9969\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0092 - accuracy: 0.9970\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0106 - accuracy: 0.9970\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0086 - accuracy: 0.9973\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0088 - accuracy: 0.9972\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0098 - accuracy: 0.9970\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0080 - accuracy: 0.9975\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0080 - accuracy: 0.9976\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0080 - accuracy: 0.9973\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0072 - accuracy: 0.9979\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0076 - accuracy: 0.9978\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0070 - accuracy: 0.9979\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0074 - accuracy: 0.9980\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0072 - accuracy: 0.9981\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0066 - accuracy: 0.9980\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0070 - accuracy: 0.9980\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0065 - accuracy: 0.9982\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0054 - accuracy: 0.9984\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0068 - accuracy: 0.9981\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0072 - accuracy: 0.9981\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0061 - accuracy: 0.9984\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0053 - accuracy: 0.9986\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0048 - accuracy: 0.9986\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0050 - accuracy: 0.9986\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0046 - accuracy: 0.9988\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0063 - accuracy: 0.9985\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0064 - accuracy: 0.9984\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0049 - accuracy: 0.9986\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0049 - accuracy: 0.9987\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0046 - accuracy: 0.9987\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0047 - accuracy: 0.9989\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0044 - accuracy: 0.9986\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0031 - accuracy: 0.9991\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0040 - accuracy: 0.9989\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0052 - accuracy: 0.9987\n",
      "Model: \"sequential_101\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_101 (Rescaling)   (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_101 (Flatten)       (None, 784)               0         \n",
      "                                                                 \n",
      " dense_195 (Dense)           (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_92 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_196 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_93 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_197 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.3364 - accuracy: 0.8944\n",
      "Epoch 2/25\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.1289 - accuracy: 0.9603\n",
      "Epoch 3/25\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0803 - accuracy: 0.9752\n",
      "Epoch 4/25\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0551 - accuracy: 0.9829\n",
      "Epoch 5/25\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0402 - accuracy: 0.9874\n",
      "Epoch 6/25\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0310 - accuracy: 0.9903\n",
      "Epoch 7/25\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0230 - accuracy: 0.9927\n",
      "Epoch 8/25\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0184 - accuracy: 0.9946\n",
      "Epoch 9/25\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0173 - accuracy: 0.9945\n",
      "Epoch 10/25\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0175 - accuracy: 0.9946\n",
      "Epoch 11/25\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0161 - accuracy: 0.9951\n",
      "Epoch 12/25\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0132 - accuracy: 0.9957\n",
      "Epoch 13/25\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0136 - accuracy: 0.9958\n",
      "Epoch 14/25\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0117 - accuracy: 0.9962\n",
      "Epoch 15/25\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0112 - accuracy: 0.9965\n",
      "Epoch 16/25\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0101 - accuracy: 0.9969\n",
      "Epoch 17/25\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0107 - accuracy: 0.9966\n",
      "Epoch 18/25\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0117 - accuracy: 0.9962\n",
      "Epoch 19/25\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0104 - accuracy: 0.9967\n",
      "Epoch 20/25\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0086 - accuracy: 0.9973\n",
      "Epoch 21/25\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0115 - accuracy: 0.9965\n",
      "Epoch 22/25\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0098 - accuracy: 0.9968\n",
      "Epoch 23/25\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0096 - accuracy: 0.9968\n",
      "Epoch 24/25\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0111 - accuracy: 0.9964\n",
      "Epoch 25/25\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0083 - accuracy: 0.9974\n",
      "Model: \"sequential_102\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_102 (Rescaling)   (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_102 (Flatten)       (None, 784)               0         \n",
      "                                                                 \n",
      " dense_198 (Dense)           (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_94 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_199 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_95 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_200 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.3448 - accuracy: 0.8927\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.1349 - accuracy: 0.9587\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0866 - accuracy: 0.9724\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0601 - accuracy: 0.9812\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0423 - accuracy: 0.9867\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0343 - accuracy: 0.9894\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0263 - accuracy: 0.9920\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0216 - accuracy: 0.9930\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0191 - accuracy: 0.9934\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0163 - accuracy: 0.9950\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0168 - accuracy: 0.9945\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0124 - accuracy: 0.9961\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0161 - accuracy: 0.9947\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0138 - accuracy: 0.9954\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0131 - accuracy: 0.9959\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0117 - accuracy: 0.9963\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0102 - accuracy: 0.9966\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0113 - accuracy: 0.9965\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0107 - accuracy: 0.9965\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0109 - accuracy: 0.9964\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0112 - accuracy: 0.9965\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0091 - accuracy: 0.9967\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0130 - accuracy: 0.9958\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0097 - accuracy: 0.9967\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0085 - accuracy: 0.9971\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0084 - accuracy: 0.9975\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0085 - accuracy: 0.9973\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0079 - accuracy: 0.9977\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0083 - accuracy: 0.9972\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0102 - accuracy: 0.9971\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0075 - accuracy: 0.9975\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0096 - accuracy: 0.9969\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0067 - accuracy: 0.9980\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0076 - accuracy: 0.9973\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0093 - accuracy: 0.9969\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0085 - accuracy: 0.9974\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0056 - accuracy: 0.9983\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0073 - accuracy: 0.9976\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0088 - accuracy: 0.9970\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0095 - accuracy: 0.9972\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0077 - accuracy: 0.9976\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0066 - accuracy: 0.9981\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0067 - accuracy: 0.9977\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0050 - accuracy: 0.9987\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0047 - accuracy: 0.9985\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0052 - accuracy: 0.9983\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0090 - accuracy: 0.9972\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0093 - accuracy: 0.9970\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0086 - accuracy: 0.9973\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0076 - accuracy: 0.9980\n",
      "Model: \"sequential_103\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_103 (Rescaling)   (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_103 (Flatten)       (None, 784)               0         \n",
      "                                                                 \n",
      " dense_201 (Dense)           (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_96 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_202 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_97 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_203 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 1.7406 - accuracy: 0.4867\n",
      "Epoch 2/25\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 1.0911 - accuracy: 0.6927\n",
      "Epoch 3/25\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.8662 - accuracy: 0.7447\n",
      "Epoch 4/25\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.7593 - accuracy: 0.7737\n",
      "Epoch 5/25\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.6934 - accuracy: 0.7917\n",
      "Epoch 6/25\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.6466 - accuracy: 0.8060\n",
      "Epoch 7/25\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.6063 - accuracy: 0.8183\n",
      "Epoch 8/25\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.5743 - accuracy: 0.8272\n",
      "Epoch 9/25\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.5497 - accuracy: 0.8340\n",
      "Epoch 10/25\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.5295 - accuracy: 0.8415\n",
      "Epoch 11/25\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.5083 - accuracy: 0.8462\n",
      "Epoch 12/25\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.4894 - accuracy: 0.8522\n",
      "Epoch 13/25\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.4736 - accuracy: 0.8587\n",
      "Epoch 14/25\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.4586 - accuracy: 0.8622\n",
      "Epoch 15/25\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.4476 - accuracy: 0.8656\n",
      "Epoch 16/25\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.4336 - accuracy: 0.8706\n",
      "Epoch 17/25\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.4207 - accuracy: 0.8732\n",
      "Epoch 18/25\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.4115 - accuracy: 0.8766\n",
      "Epoch 19/25\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.4007 - accuracy: 0.8791\n",
      "Epoch 20/25\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.3906 - accuracy: 0.8820\n",
      "Epoch 21/25\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.3827 - accuracy: 0.8854\n",
      "Epoch 22/25\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.3742 - accuracy: 0.8881\n",
      "Epoch 23/25\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.3670 - accuracy: 0.8882\n",
      "Epoch 24/25\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.3596 - accuracy: 0.8921\n",
      "Epoch 25/25\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.3537 - accuracy: 0.8937\n",
      "Model: \"sequential_104\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_104 (Rescaling)   (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_104 (Flatten)       (None, 784)               0         \n",
      "                                                                 \n",
      " dense_204 (Dense)           (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_98 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_205 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_99 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_206 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 1.7894 - accuracy: 0.4580\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 1.1170 - accuracy: 0.6836\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.8822 - accuracy: 0.7395\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.7703 - accuracy: 0.7720\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.7034 - accuracy: 0.7896\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.6557 - accuracy: 0.8027\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.6146 - accuracy: 0.8154\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.5864 - accuracy: 0.8238\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.5577 - accuracy: 0.8325\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.5348 - accuracy: 0.8389\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.5162 - accuracy: 0.8458\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.4993 - accuracy: 0.8500\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.4827 - accuracy: 0.8548\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.4686 - accuracy: 0.8584\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.4532 - accuracy: 0.8637\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.4384 - accuracy: 0.8670\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.4303 - accuracy: 0.8685\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.4156 - accuracy: 0.8750\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.4066 - accuracy: 0.8779\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.3972 - accuracy: 0.8808\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.3873 - accuracy: 0.8825\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.3788 - accuracy: 0.8865\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.3729 - accuracy: 0.8876\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.3633 - accuracy: 0.8906\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.3554 - accuracy: 0.8930\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.3468 - accuracy: 0.8964\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.3407 - accuracy: 0.8972\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.3352 - accuracy: 0.8988\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.3282 - accuracy: 0.9010\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.3237 - accuracy: 0.9029\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.3167 - accuracy: 0.9046\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.3107 - accuracy: 0.9069\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.3047 - accuracy: 0.9093\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.2997 - accuracy: 0.9103\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.2957 - accuracy: 0.9123\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.2916 - accuracy: 0.9125\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.2865 - accuracy: 0.9140\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.2830 - accuracy: 0.9156\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.2755 - accuracy: 0.9177\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.2734 - accuracy: 0.9186\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.2695 - accuracy: 0.9197\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.2655 - accuracy: 0.9208\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.2621 - accuracy: 0.9219\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.2579 - accuracy: 0.9222\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.2544 - accuracy: 0.9241\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.2512 - accuracy: 0.9246\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.2469 - accuracy: 0.9260\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.2437 - accuracy: 0.9287\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.2395 - accuracy: 0.9292\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.2366 - accuracy: 0.9294\n",
      "Model: \"sequential_105\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_105 (Rescaling)   (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_105 (Flatten)       (None, 784)               0         \n",
      "                                                                 \n",
      " dense_207 (Dense)           (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_100 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_208 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_101 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_209 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.4499 - accuracy: 0.8604\n",
      "Epoch 2/25\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.1868 - accuracy: 0.9426\n",
      "Epoch 3/25\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.1243 - accuracy: 0.9625\n",
      "Epoch 4/25\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0915 - accuracy: 0.9722\n",
      "Epoch 5/25\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0710 - accuracy: 0.9776\n",
      "Epoch 6/25\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0554 - accuracy: 0.9824\n",
      "Epoch 7/25\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0464 - accuracy: 0.9851\n",
      "Epoch 8/25\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0388 - accuracy: 0.9874\n",
      "Epoch 9/25\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0330 - accuracy: 0.9891\n",
      "Epoch 10/25\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0309 - accuracy: 0.9903\n",
      "Epoch 11/25\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0264 - accuracy: 0.9914\n",
      "Epoch 12/25\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0253 - accuracy: 0.9919\n",
      "Epoch 13/25\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0221 - accuracy: 0.9927\n",
      "Epoch 14/25\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0229 - accuracy: 0.9929\n",
      "Epoch 15/25\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0204 - accuracy: 0.9940\n",
      "Epoch 16/25\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0186 - accuracy: 0.9941\n",
      "Epoch 17/25\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0177 - accuracy: 0.9945\n",
      "Epoch 18/25\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0167 - accuracy: 0.9947\n",
      "Epoch 19/25\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0172 - accuracy: 0.9948\n",
      "Epoch 20/25\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0143 - accuracy: 0.9953\n",
      "Epoch 21/25\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0163 - accuracy: 0.9954\n",
      "Epoch 22/25\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0149 - accuracy: 0.9955\n",
      "Epoch 23/25\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0148 - accuracy: 0.9957\n",
      "Epoch 24/25\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0130 - accuracy: 0.9963\n",
      "Epoch 25/25\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0130 - accuracy: 0.9962\n",
      "Model: \"sequential_106\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_106 (Rescaling)   (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_106 (Flatten)       (None, 784)               0         \n",
      "                                                                 \n",
      " dense_210 (Dense)           (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_102 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_211 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_103 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_212 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.4522 - accuracy: 0.8594\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.1885 - accuracy: 0.9420\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.1247 - accuracy: 0.9617\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0914 - accuracy: 0.9718\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0724 - accuracy: 0.9774\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0579 - accuracy: 0.9818\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0461 - accuracy: 0.9851\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0404 - accuracy: 0.9869\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0348 - accuracy: 0.9886\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0287 - accuracy: 0.9909\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0275 - accuracy: 0.9911\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0231 - accuracy: 0.9922\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0244 - accuracy: 0.9922\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0207 - accuracy: 0.9932\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0204 - accuracy: 0.9933\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0201 - accuracy: 0.9939\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0189 - accuracy: 0.9940\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0178 - accuracy: 0.9942\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0147 - accuracy: 0.9952\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0170 - accuracy: 0.9949\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0153 - accuracy: 0.9953\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0152 - accuracy: 0.9954\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0144 - accuracy: 0.9957\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0124 - accuracy: 0.9962\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0141 - accuracy: 0.9957\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0117 - accuracy: 0.9964\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0141 - accuracy: 0.9959\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0131 - accuracy: 0.9959\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0118 - accuracy: 0.9964\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0124 - accuracy: 0.9963\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0116 - accuracy: 0.9964\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0109 - accuracy: 0.9972\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0118 - accuracy: 0.9964\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0114 - accuracy: 0.9966\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0106 - accuracy: 0.9971\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0112 - accuracy: 0.9969\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0119 - accuracy: 0.9968\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0098 - accuracy: 0.9973\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0119 - accuracy: 0.9968\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0099 - accuracy: 0.9970\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0096 - accuracy: 0.9972\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0101 - accuracy: 0.9971\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0106 - accuracy: 0.9970\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0094 - accuracy: 0.9976\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0094 - accuracy: 0.9976\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0089 - accuracy: 0.9977\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0087 - accuracy: 0.9977\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0095 - accuracy: 0.9976\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0097 - accuracy: 0.9972\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0099 - accuracy: 0.9975\n",
      "Model: \"sequential_107\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_107 (Rescaling)   (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_107 (Flatten)       (None, 784)               0         \n",
      "                                                                 \n",
      " dense_213 (Dense)           (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_104 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_214 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_105 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_215 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.3636 - accuracy: 0.8863\n",
      "Epoch 2/25\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.1542 - accuracy: 0.9526\n",
      "Epoch 3/25\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.1036 - accuracy: 0.9675\n",
      "Epoch 4/25\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0776 - accuracy: 0.9760\n",
      "Epoch 5/25\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0625 - accuracy: 0.9805\n",
      "Epoch 6/25\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0501 - accuracy: 0.9838\n",
      "Epoch 7/25\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0392 - accuracy: 0.9869\n",
      "Epoch 8/25\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0361 - accuracy: 0.9876\n",
      "Epoch 9/25\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0306 - accuracy: 0.9897\n",
      "Epoch 10/25\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0273 - accuracy: 0.9909\n",
      "Epoch 11/25\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0267 - accuracy: 0.9912\n",
      "Epoch 12/25\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0226 - accuracy: 0.9930\n",
      "Epoch 13/25\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0226 - accuracy: 0.9926\n",
      "Epoch 14/25\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0207 - accuracy: 0.9933\n",
      "Epoch 15/25\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0191 - accuracy: 0.9937\n",
      "Epoch 16/25\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0197 - accuracy: 0.9932\n",
      "Epoch 17/25\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0181 - accuracy: 0.9938\n",
      "Epoch 18/25\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0187 - accuracy: 0.9936\n",
      "Epoch 19/25\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0178 - accuracy: 0.9941\n",
      "Epoch 20/25\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0159 - accuracy: 0.9947\n",
      "Epoch 21/25\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0184 - accuracy: 0.9939\n",
      "Epoch 22/25\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0154 - accuracy: 0.9951\n",
      "Epoch 23/25\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0152 - accuracy: 0.9951\n",
      "Epoch 24/25\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0168 - accuracy: 0.9942\n",
      "Epoch 25/25\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0146 - accuracy: 0.9953\n",
      "Model: \"sequential_108\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_108 (Rescaling)   (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_108 (Flatten)       (None, 784)               0         \n",
      "                                                                 \n",
      " dense_216 (Dense)           (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_106 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_217 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_107 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_218 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.3702 - accuracy: 0.8842\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.1541 - accuracy: 0.9517\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.1097 - accuracy: 0.9662\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0812 - accuracy: 0.9743\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0619 - accuracy: 0.9799\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0528 - accuracy: 0.9829\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0431 - accuracy: 0.9863\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0374 - accuracy: 0.9881\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0331 - accuracy: 0.9890\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0272 - accuracy: 0.9907\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0278 - accuracy: 0.9910\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0251 - accuracy: 0.9919\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0217 - accuracy: 0.9927\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0242 - accuracy: 0.9919\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0214 - accuracy: 0.9930\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0175 - accuracy: 0.9944\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0200 - accuracy: 0.9932\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0182 - accuracy: 0.9942\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0178 - accuracy: 0.9944\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0178 - accuracy: 0.9944\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0168 - accuracy: 0.9947\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0178 - accuracy: 0.9941\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0159 - accuracy: 0.9949\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0161 - accuracy: 0.9948\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0136 - accuracy: 0.9954\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0141 - accuracy: 0.9955\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0143 - accuracy: 0.9950\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0162 - accuracy: 0.9948\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0142 - accuracy: 0.9957\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0137 - accuracy: 0.9956\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0118 - accuracy: 0.9965\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0134 - accuracy: 0.9957\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0147 - accuracy: 0.9953\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0114 - accuracy: 0.9959\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0129 - accuracy: 0.9957\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0135 - accuracy: 0.9956\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0124 - accuracy: 0.9960\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0115 - accuracy: 0.9962\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0126 - accuracy: 0.9959\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0114 - accuracy: 0.9963\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0088 - accuracy: 0.9973\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0106 - accuracy: 0.9966\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0107 - accuracy: 0.9967\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0101 - accuracy: 0.9966\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0109 - accuracy: 0.9964\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0116 - accuracy: 0.9965\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0118 - accuracy: 0.9962\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0109 - accuracy: 0.9963\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0101 - accuracy: 0.9968\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0115 - accuracy: 0.9966\n"
     ]
    }
   ],
   "source": [
    "build_model_params = {\n",
    "    'n_hidden': [0, 1, 2],\n",
    "    'n_neurons': [32, 128, 512],\n",
    "    'dropout': [.1, .2],\n",
    "    'optimizer': [SGD(), RMSprop(), Adam()]\n",
    "}\n",
    "fit_and_predict_params = {\n",
    "    'epochs': [25, 50]\n",
    "}\n",
    "\n",
    "keys, values = zip(*build_model_params.items())\n",
    "build_model_kwargses = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "keys, values = zip(*fit_and_predict_params.items())\n",
    "fit_and_predict_kwargses = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "\n",
    "results = []\n",
    "for build_model_kwargs in build_model_kwargses:\n",
    "    for fit_and_predict_kwargs in fit_and_predict_kwargses:\n",
    "        model = build_model(**build_model_kwargs)\n",
    "        acc, cm = fit_and_predict(model, **fit_and_predict_kwargs)\n",
    "        results.append((build_model_kwargs, fit_and_predict_kwargs, acc, cm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "|accuracy|n_hidden|n_neurons|dropout|optimizer|epochs|\n",
       "|--------|--------|---------|-------|---------|------|\n",
       "|66.96%|0|32|0.1|<class 'keras.optimizer_v2.gradient_descent.SGD'>|25|\n",
       "|68.59%|0|32|0.1|<class 'keras.optimizer_v2.gradient_descent.SGD'>|50|\n",
       "|70.34%|0|32|0.1|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|25|\n",
       "|70.19%|0|32|0.1|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|50|\n",
       "|70.24%|0|32|0.1|<class 'keras.optimizer_v2.adam.Adam'>|25|\n",
       "|70.02%|0|32|0.1|<class 'keras.optimizer_v2.adam.Adam'>|50|\n",
       "|66.69%|0|32|0.2|<class 'keras.optimizer_v2.gradient_descent.SGD'>|25|\n",
       "|68.66%|0|32|0.2|<class 'keras.optimizer_v2.gradient_descent.SGD'>|50|\n",
       "|70.28%|0|32|0.2|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|25|\n",
       "|70.24%|0|32|0.2|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|50|\n",
       "|69.98%|0|32|0.2|<class 'keras.optimizer_v2.adam.Adam'>|25|\n",
       "|69.86%|0|32|0.2|<class 'keras.optimizer_v2.adam.Adam'>|50|\n",
       "|66.72%|0|128|0.1|<class 'keras.optimizer_v2.gradient_descent.SGD'>|25|\n",
       "|68.63%|0|128|0.1|<class 'keras.optimizer_v2.gradient_descent.SGD'>|50|\n",
       "|70.37%|0|128|0.1|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|25|\n",
       "|69.97%|0|128|0.1|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|50|\n",
       "|70.24%|0|128|0.1|<class 'keras.optimizer_v2.adam.Adam'>|25|\n",
       "|69.88%|0|128|0.1|<class 'keras.optimizer_v2.adam.Adam'>|50|\n",
       "|67.27%|0|128|0.2|<class 'keras.optimizer_v2.gradient_descent.SGD'>|25|\n",
       "|68.38%|0|128|0.2|<class 'keras.optimizer_v2.gradient_descent.SGD'>|50|\n",
       "|70.60%|0|128|0.2|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|25|\n",
       "|69.95%|0|128|0.2|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|50|\n",
       "|70.10%|0|128|0.2|<class 'keras.optimizer_v2.adam.Adam'>|25|\n",
       "|70.04%|0|128|0.2|<class 'keras.optimizer_v2.adam.Adam'>|50|\n",
       "|66.71%|0|512|0.1|<class 'keras.optimizer_v2.gradient_descent.SGD'>|25|\n",
       "|68.56%|0|512|0.1|<class 'keras.optimizer_v2.gradient_descent.SGD'>|50|\n",
       "|70.28%|0|512|0.1|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|25|\n",
       "|69.93%|0|512|0.1|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|50|\n",
       "|70.04%|0|512|0.1|<class 'keras.optimizer_v2.adam.Adam'>|25|\n",
       "|70.30%|0|512|0.1|<class 'keras.optimizer_v2.adam.Adam'>|50|\n",
       "|66.69%|0|512|0.2|<class 'keras.optimizer_v2.gradient_descent.SGD'>|25|\n",
       "|68.38%|0|512|0.2|<class 'keras.optimizer_v2.gradient_descent.SGD'>|50|\n",
       "|69.75%|0|512|0.2|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|25|\n",
       "|69.92%|0|512|0.2|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|50|\n",
       "|69.95%|0|512|0.2|<class 'keras.optimizer_v2.adam.Adam'>|25|\n",
       "|70.19%|0|512|0.2|<class 'keras.optimizer_v2.adam.Adam'>|50|\n",
       "|73.31%|1|32|0.1|<class 'keras.optimizer_v2.gradient_descent.SGD'>|25|\n",
       "|76.27%|1|32|0.1|<class 'keras.optimizer_v2.gradient_descent.SGD'>|50|\n",
       "|82.59%|1|32|0.1|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|25|\n",
       "|83.50%|1|32|0.1|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|50|\n",
       "|82.25%|1|32|0.1|<class 'keras.optimizer_v2.adam.Adam'>|25|\n",
       "|82.98%|1|32|0.1|<class 'keras.optimizer_v2.adam.Adam'>|50|\n",
       "|72.61%|1|32|0.2|<class 'keras.optimizer_v2.gradient_descent.SGD'>|25|\n",
       "|75.90%|1|32|0.2|<class 'keras.optimizer_v2.gradient_descent.SGD'>|50|\n",
       "|80.67%|1|32|0.2|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|25|\n",
       "|81.06%|1|32|0.2|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|50|\n",
       "|79.68%|1|32|0.2|<class 'keras.optimizer_v2.adam.Adam'>|25|\n",
       "|80.96%|1|32|0.2|<class 'keras.optimizer_v2.adam.Adam'>|50|\n",
       "|76.77%|1|128|0.1|<class 'keras.optimizer_v2.gradient_descent.SGD'>|25|\n",
       "|80.97%|1|128|0.1|<class 'keras.optimizer_v2.gradient_descent.SGD'>|50|\n",
       "|89.65%|1|128|0.1|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|25|\n",
       "|89.63%|1|128|0.1|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|50|\n",
       "|89.34%|1|128|0.1|<class 'keras.optimizer_v2.adam.Adam'>|25|\n",
       "|89.25%|1|128|0.1|<class 'keras.optimizer_v2.adam.Adam'>|50|\n",
       "|76.38%|1|128|0.2|<class 'keras.optimizer_v2.gradient_descent.SGD'>|25|\n",
       "|79.96%|1|128|0.2|<class 'keras.optimizer_v2.gradient_descent.SGD'>|50|\n",
       "|89.04%|1|128|0.2|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|25|\n",
       "|89.59%|1|128|0.2|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|50|\n",
       "|89.50%|1|128|0.2|<class 'keras.optimizer_v2.adam.Adam'>|25|\n",
       "|88.84%|1|128|0.2|<class 'keras.optimizer_v2.adam.Adam'>|50|\n",
       "|76.90%|1|512|0.1|<class 'keras.optimizer_v2.gradient_descent.SGD'>|25|\n",
       "|81.96%|1|512|0.1|<class 'keras.optimizer_v2.gradient_descent.SGD'>|50|\n",
       "|91.45%|1|512|0.1|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|25|\n",
       "|92.39%|1|512|0.1|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|50|\n",
       "|92.10%|1|512|0.1|<class 'keras.optimizer_v2.adam.Adam'>|25|\n",
       "|92.33%|1|512|0.1|<class 'keras.optimizer_v2.adam.Adam'>|50|\n",
       "|77.37%|1|512|0.2|<class 'keras.optimizer_v2.gradient_descent.SGD'>|25|\n",
       "|81.61%|1|512|0.2|<class 'keras.optimizer_v2.gradient_descent.SGD'>|50|\n",
       "|92.10%|1|512|0.2|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|25|\n",
       "|91.68%|1|512|0.2|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|50|\n",
       "|91.42%|1|512|0.2|<class 'keras.optimizer_v2.adam.Adam'>|25|\n",
       "|92.03%|1|512|0.2|<class 'keras.optimizer_v2.adam.Adam'>|50|\n",
       "|74.63%|2|32|0.1|<class 'keras.optimizer_v2.gradient_descent.SGD'>|25|\n",
       "|78.34%|2|32|0.1|<class 'keras.optimizer_v2.gradient_descent.SGD'>|50|\n",
       "|82.82%|2|32|0.1|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|25|\n",
       "|83.22%|2|32|0.1|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|50|\n",
       "|82.68%|2|32|0.1|<class 'keras.optimizer_v2.adam.Adam'>|25|\n",
       "|82.54%|2|32|0.1|<class 'keras.optimizer_v2.adam.Adam'>|50|\n",
       "|72.18%|2|32|0.2|<class 'keras.optimizer_v2.gradient_descent.SGD'>|25|\n",
       "|76.83%|2|32|0.2|<class 'keras.optimizer_v2.gradient_descent.SGD'>|50|\n",
       "|80.75%|2|32|0.2|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|25|\n",
       "|80.94%|2|32|0.2|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|50|\n",
       "|78.73%|2|32|0.2|<class 'keras.optimizer_v2.adam.Adam'>|25|\n",
       "|79.85%|2|32|0.2|<class 'keras.optimizer_v2.adam.Adam'>|50|\n",
       "|78.05%|2|128|0.1|<class 'keras.optimizer_v2.gradient_descent.SGD'>|25|\n",
       "|82.95%|2|128|0.1|<class 'keras.optimizer_v2.gradient_descent.SGD'>|50|\n",
       "|90.51%|2|128|0.1|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|25|\n",
       "|90.24%|2|128|0.1|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|50|\n",
       "|91.11%|2|128|0.1|<class 'keras.optimizer_v2.adam.Adam'>|25|\n",
       "|90.34%|2|128|0.1|<class 'keras.optimizer_v2.adam.Adam'>|50|\n",
       "|76.60%|2|128|0.2|<class 'keras.optimizer_v2.gradient_descent.SGD'>|25|\n",
       "|82.14%|2|128|0.2|<class 'keras.optimizer_v2.gradient_descent.SGD'>|50|\n",
       "|89.93%|2|128|0.2|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|25|\n",
       "|89.96%|2|128|0.2|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|50|\n",
       "|89.37%|2|128|0.2|<class 'keras.optimizer_v2.adam.Adam'>|25|\n",
       "|89.50%|2|128|0.2|<class 'keras.optimizer_v2.adam.Adam'>|50|\n",
       "|79.84%|2|512|0.1|<class 'keras.optimizer_v2.gradient_descent.SGD'>|25|\n",
       "|85.30%|2|512|0.1|<class 'keras.optimizer_v2.gradient_descent.SGD'>|50|\n",
       "|91.40%|2|512|0.1|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|25|\n",
       "|92.58%|2|512|0.1|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|50|\n",
       "|92.10%|2|512|0.1|<class 'keras.optimizer_v2.adam.Adam'>|25|\n",
       "|92.32%|2|512|0.1|<class 'keras.optimizer_v2.adam.Adam'>|50|\n",
       "|79.77%|2|512|0.2|<class 'keras.optimizer_v2.gradient_descent.SGD'>|25|\n",
       "|84.51%|2|512|0.2|<class 'keras.optimizer_v2.gradient_descent.SGD'>|50|\n",
       "|92.15%|2|512|0.2|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|25|\n",
       "|92.83%|2|512|0.2|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|50|\n",
       "|92.53%|2|512|0.2|<class 'keras.optimizer_v2.adam.Adam'>|25|\n",
       "|91.68%|2|512|0.2|<class 'keras.optimizer_v2.adam.Adam'>|50|\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_acc = 0\n",
    "md =  \"|accuracy|n_hidden|n_neurons|dropout|optimizer|epochs|\\n\"\n",
    "md += \"|--------|--------|---------|-------|---------|------|\\n\"\n",
    "for result in results:\n",
    "    acc = result[2]\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_build_model_params = result[0]\n",
    "        best_fit_and_predict_params = result[1]\n",
    "        best_cm = result[3]\n",
    "    md += f\"|{acc:.2f}%|{result[0]['n_hidden']}|{result[0]['n_neurons']}|{result[0]['dropout']}|{type(result[0]['optimizer'])}|{result[1]['epochs']}|\\n\"\n",
    "display(Markdown(md))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best accuracy: 92.83% - {'n_hidden': 2, 'n_neurons': 512, 'dropout': 0.2, 'optimizer': <keras.optimizer_v2.rmsprop.RMSprop object at 0x000001CC624D9C90>} {'epochs': 50}\n",
      "\n",
      "Best Confusion Matrix:\n",
      "[[946   1   2   0  14  11   2  17   7   0]\n",
      " [  1 894  15   1  13   7  34  11  12  12]\n",
      " [ 11   5 876  54   6  13   6  11   9   9]\n",
      " [  1   1  14 964   3   7   1   4   2   3]\n",
      " [ 19  16   4   9 901   6  10  13  18   4]\n",
      " [  2   7  17   7   1 943  14   3   2   4]\n",
      " [  5   7  18   5  11   0 945   4   3   2]\n",
      " [  5   3   7   1   1   4   9 956   4  10]\n",
      " [ 11  18   5  21   3   8   5   2 924   3]\n",
      " [ 11   4  14   6   8   2   8   6   7 934]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nBest accuracy: {best_acc:.2f}% - {best_build_model_params} {best_fit_and_predict_params}\\n\")\n",
    "print(\"Best Confusion Matrix:\")\n",
    "print(best_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More hidden layers, more neurons per layer, and the [Adam]() optimizer performed the best. Accuracy is now nearly 93%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing a Convolutional Neural Network\n",
    "\n",
    "For this, I will begin with my best parameters from the multi-layer perceptron model: 2 hidden Dense layers, 512 neurons per dense layer, with a .2 dropout and the [Adam](https://keras.io/api/optimizers/adam/) optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn_model(\n",
    "    n_filters=[32, 64], kernel_size=(3, 3), n_hidden=2, pooling=MaxPooling2D(pool_size=(2, 2)),\n",
    "    n_neurons=512, dropout=.2, loss='sparse_categorical_crossentropy', optimizer=Adam()):\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Input(shape=(28, 28, 1)))\n",
    "    model.add(Rescaling(scale=1./255))\n",
    "    \n",
    "    for filters in n_filters:\n",
    "        model.add(Conv2D(filters=filters, kernel_size=kernel_size))\n",
    "\n",
    "    if pooling:\n",
    "        model.add(pooling)\n",
    "    \n",
    "    if pooling is None or type(pooling) is MaxPooling2D:\n",
    "        model.add(Flatten())\n",
    "\n",
    "    for hidden_layer in range(n_hidden):\n",
    "        model.add(Dense(n_neurons, activation='relu'))\n",
    "        if dropout:\n",
    "            model.add(Dropout(dropout))\n",
    "    model.add(Dense(len(labels), activation='softmax'))\n",
    "    model.summary()\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_109\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_109 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 12, 12, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten_109 (Flatten)       (None, 9216)              0         \n",
      "                                                                 \n",
      " dense_219 (Dense)           (None, 512)               4719104   \n",
      "                                                                 \n",
      " dropout_108 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_220 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_109 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_221 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,005,706\n",
      "Trainable params: 5,005,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_cnn_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 34s 72ms/step - loss: 0.2584 - accuracy: 0.9200\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 34s 72ms/step - loss: 0.0780 - accuracy: 0.9759\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 34s 72ms/step - loss: 0.0470 - accuracy: 0.9845\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 34s 72ms/step - loss: 0.0334 - accuracy: 0.9891\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 34s 72ms/step - loss: 0.0264 - accuracy: 0.9914\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 34s 72ms/step - loss: 0.0274 - accuracy: 0.9913\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 34s 72ms/step - loss: 0.0224 - accuracy: 0.9931\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 34s 72ms/step - loss: 0.0185 - accuracy: 0.9940\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 34s 72ms/step - loss: 0.0172 - accuracy: 0.9946\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 34s 72ms/step - loss: 0.0188 - accuracy: 0.9946\n"
     ]
    }
   ],
   "source": [
    "acc, cm = fit_and_predict(model, batch_size=128, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.80%\n",
      "Confusion Matrix:\n",
      "[[947   0   3   1  23   5   1   9   7   4]\n",
      " [  1 917  13   2  17   2  19   2   9  18]\n",
      " [  6   3 867  83  11   6   8   2   8   6]\n",
      " [  0   0   5 989   1   3   1   1   0   0]\n",
      " [ 11   3   2  12 935   2   6   2  25   2]\n",
      " [  1   2  25  19   4 929  10   0   5   5]\n",
      " [  4   0  15   6   9   3 959   1   2   1]\n",
      " [  7   3   5   5   5   1  23 909  21  21]\n",
      " [  1   5   1  10   2   3   4   1 972   1]\n",
      " [  9   1   1   3   8   1   9   3   9 956]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {acc:.2f}%\")\n",
    "print(f\"Confusion Matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize the CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_110\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_110 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 24, 24, 16)        416       \n",
      "                                                                 \n",
      " flatten_110 (Flatten)       (None, 9216)              0         \n",
      "                                                                 \n",
      " dense_222 (Dense)           (None, 512)               4719104   \n",
      "                                                                 \n",
      " dropout_110 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_223 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_111 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_224 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,987,306\n",
      "Trainable params: 4,987,306\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 32s 33ms/step - loss: 0.3333 - accuracy: 0.8988\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 31s 33ms/step - loss: 0.1608 - accuracy: 0.9523\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 31s 34ms/step - loss: 0.1144 - accuracy: 0.9667\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 31s 33ms/step - loss: 0.0913 - accuracy: 0.9737\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 31s 33ms/step - loss: 0.0811 - accuracy: 0.9778\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 31s 33ms/step - loss: 0.0752 - accuracy: 0.9798\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 31s 33ms/step - loss: 0.0729 - accuracy: 0.9814\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 31s 33ms/step - loss: 0.0702 - accuracy: 0.9823\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 31s 33ms/step - loss: 0.0753 - accuracy: 0.9824\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 31s 33ms/step - loss: 0.0727 - accuracy: 0.9830\n",
      "Model: \"sequential_111\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_111 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 24, 24, 16)        416       \n",
      "                                                                 \n",
      " flatten_111 (Flatten)       (None, 9216)              0         \n",
      "                                                                 \n",
      " dense_225 (Dense)           (None, 512)               4719104   \n",
      "                                                                 \n",
      " dropout_112 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_226 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_113 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_227 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,987,306\n",
      "Trainable params: 4,987,306\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "938/938 [==============================] - 32s 33ms/step - loss: 0.3381 - accuracy: 0.8976\n",
      "Epoch 2/25\n",
      "938/938 [==============================] - 31s 33ms/step - loss: 0.1612 - accuracy: 0.9514\n",
      "Epoch 3/25\n",
      "938/938 [==============================] - 31s 33ms/step - loss: 0.1174 - accuracy: 0.9650\n",
      "Epoch 4/25\n",
      "938/938 [==============================] - 31s 33ms/step - loss: 0.0879 - accuracy: 0.9748\n",
      "Epoch 5/25\n",
      "938/938 [==============================] - 31s 33ms/step - loss: 0.0776 - accuracy: 0.9778\n",
      "Epoch 6/25\n",
      "938/938 [==============================] - 31s 33ms/step - loss: 0.0770 - accuracy: 0.9793\n",
      "Epoch 7/25\n",
      "938/938 [==============================] - 31s 33ms/step - loss: 0.0707 - accuracy: 0.9818\n",
      "Epoch 8/25\n",
      "938/938 [==============================] - 31s 33ms/step - loss: 0.0691 - accuracy: 0.9819\n",
      "Epoch 9/25\n",
      "938/938 [==============================] - 31s 33ms/step - loss: 0.0762 - accuracy: 0.9828\n",
      "Epoch 10/25\n",
      "938/938 [==============================] - 31s 33ms/step - loss: 0.0740 - accuracy: 0.9827\n",
      "Epoch 11/25\n",
      "938/938 [==============================] - 31s 33ms/step - loss: 0.0793 - accuracy: 0.9826\n",
      "Epoch 12/25\n",
      "938/938 [==============================] - 31s 33ms/step - loss: 0.0755 - accuracy: 0.9838\n",
      "Epoch 13/25\n",
      "938/938 [==============================] - 31s 33ms/step - loss: 0.0814 - accuracy: 0.9829\n",
      "Epoch 14/25\n",
      "938/938 [==============================] - 31s 34ms/step - loss: 0.0816 - accuracy: 0.9832\n",
      "Epoch 15/25\n",
      "938/938 [==============================] - 31s 33ms/step - loss: 0.0800 - accuracy: 0.9843\n",
      "Epoch 16/25\n",
      "938/938 [==============================] - 31s 33ms/step - loss: 0.0827 - accuracy: 0.9840\n",
      "Epoch 17/25\n",
      "938/938 [==============================] - 31s 33ms/step - loss: 0.0913 - accuracy: 0.9838\n",
      "Epoch 18/25\n",
      "938/938 [==============================] - 31s 33ms/step - loss: 0.0905 - accuracy: 0.9830\n",
      "Epoch 19/25\n",
      "938/938 [==============================] - 31s 33ms/step - loss: 0.0952 - accuracy: 0.9833\n",
      "Epoch 20/25\n",
      "938/938 [==============================] - 31s 33ms/step - loss: 0.0888 - accuracy: 0.9838\n",
      "Epoch 21/25\n",
      "938/938 [==============================] - 31s 33ms/step - loss: 0.0962 - accuracy: 0.9843\n",
      "Epoch 22/25\n",
      "938/938 [==============================] - 31s 33ms/step - loss: 0.1033 - accuracy: 0.9829\n",
      "Epoch 23/25\n",
      "938/938 [==============================] - 31s 33ms/step - loss: 0.0975 - accuracy: 0.9831\n",
      "Epoch 24/25\n",
      "938/938 [==============================] - 31s 33ms/step - loss: 0.0985 - accuracy: 0.9837\n",
      "Epoch 25/25\n",
      "938/938 [==============================] - 31s 33ms/step - loss: 0.0974 - accuracy: 0.9839\n",
      "Model: \"sequential_112\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_112 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 24, 24, 16)        416       \n",
      "                                                                 \n",
      " flatten_112 (Flatten)       (None, 9216)              0         \n",
      "                                                                 \n",
      " dense_228 (Dense)           (None, 512)               4719104   \n",
      "                                                                 \n",
      " dropout_114 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_229 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_115 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_230 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,987,306\n",
      "Trainable params: 4,987,306\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "469/469 [==============================] - 18s 38ms/step - loss: 0.3490 - accuracy: 0.8935\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 18s 38ms/step - loss: 0.1519 - accuracy: 0.9530\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 18s 38ms/step - loss: 0.0991 - accuracy: 0.9696\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 18s 38ms/step - loss: 0.0691 - accuracy: 0.9780\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 18s 38ms/step - loss: 0.0544 - accuracy: 0.9832\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 18s 38ms/step - loss: 0.0446 - accuracy: 0.9861\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 18s 38ms/step - loss: 0.0406 - accuracy: 0.9880\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 18s 38ms/step - loss: 0.0347 - accuracy: 0.9894\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 18s 38ms/step - loss: 0.0334 - accuracy: 0.9903\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 18s 38ms/step - loss: 0.0300 - accuracy: 0.9909\n",
      "Model: \"sequential_113\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_113 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 24, 24, 16)        416       \n",
      "                                                                 \n",
      " flatten_113 (Flatten)       (None, 9216)              0         \n",
      "                                                                 \n",
      " dense_231 (Dense)           (None, 512)               4719104   \n",
      "                                                                 \n",
      " dropout_116 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_232 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_117 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_233 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,987,306\n",
      "Trainable params: 4,987,306\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "469/469 [==============================] - 18s 38ms/step - loss: 0.3434 - accuracy: 0.8959\n",
      "Epoch 2/25\n",
      "469/469 [==============================] - 18s 38ms/step - loss: 0.1528 - accuracy: 0.9535\n",
      "Epoch 3/25\n",
      "469/469 [==============================] - 18s 38ms/step - loss: 0.1024 - accuracy: 0.9686\n",
      "Epoch 4/25\n",
      "469/469 [==============================] - 18s 38ms/step - loss: 0.0711 - accuracy: 0.9779\n",
      "Epoch 5/25\n",
      "469/469 [==============================] - 18s 38ms/step - loss: 0.0528 - accuracy: 0.9831\n",
      "Epoch 6/25\n",
      "469/469 [==============================] - 18s 38ms/step - loss: 0.0461 - accuracy: 0.9857\n",
      "Epoch 7/25\n",
      "469/469 [==============================] - 18s 38ms/step - loss: 0.0402 - accuracy: 0.9873\n",
      "Epoch 8/25\n",
      "469/469 [==============================] - 19s 40ms/step - loss: 0.0353 - accuracy: 0.9896\n",
      "Epoch 9/25\n",
      "469/469 [==============================] - 19s 40ms/step - loss: 0.0328 - accuracy: 0.9902\n",
      "Epoch 10/25\n",
      "469/469 [==============================] - 18s 38ms/step - loss: 0.0338 - accuracy: 0.9902\n",
      "Epoch 11/25\n",
      "469/469 [==============================] - 18s 38ms/step - loss: 0.0311 - accuracy: 0.9912\n",
      "Epoch 12/25\n",
      "469/469 [==============================] - 18s 38ms/step - loss: 0.0288 - accuracy: 0.9919\n",
      "Epoch 13/25\n",
      "469/469 [==============================] - 18s 39ms/step - loss: 0.0279 - accuracy: 0.9923\n",
      "Epoch 14/25\n",
      "469/469 [==============================] - 18s 38ms/step - loss: 0.0284 - accuracy: 0.9922\n",
      "Epoch 15/25\n",
      "469/469 [==============================] - 18s 38ms/step - loss: 0.0282 - accuracy: 0.9923\n",
      "Epoch 16/25\n",
      "469/469 [==============================] - 18s 38ms/step - loss: 0.0255 - accuracy: 0.9931\n",
      "Epoch 17/25\n",
      "469/469 [==============================] - 18s 38ms/step - loss: 0.0272 - accuracy: 0.9931\n",
      "Epoch 18/25\n",
      "469/469 [==============================] - 18s 38ms/step - loss: 0.0284 - accuracy: 0.9930\n",
      "Epoch 19/25\n",
      "469/469 [==============================] - 18s 38ms/step - loss: 0.0246 - accuracy: 0.9939\n",
      "Epoch 20/25\n",
      "469/469 [==============================] - 18s 38ms/step - loss: 0.0298 - accuracy: 0.9932\n",
      "Epoch 21/25\n",
      "469/469 [==============================] - 18s 38ms/step - loss: 0.0254 - accuracy: 0.9937\n",
      "Epoch 22/25\n",
      "469/469 [==============================] - 18s 38ms/step - loss: 0.0283 - accuracy: 0.9934\n",
      "Epoch 23/25\n",
      "469/469 [==============================] - 18s 38ms/step - loss: 0.0310 - accuracy: 0.9932\n",
      "Epoch 24/25\n",
      "469/469 [==============================] - 18s 37ms/step - loss: 0.0308 - accuracy: 0.9933\n",
      "Epoch 25/25\n",
      "469/469 [==============================] - 18s 38ms/step - loss: 0.0346 - accuracy: 0.9930\n",
      "Model: \"sequential_114\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_114 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 24, 24, 16)        416       \n",
      "                                                                 \n",
      " flatten_114 (Flatten)       (None, 9216)              0         \n",
      "                                                                 \n",
      " dense_234 (Dense)           (None, 512)               4719104   \n",
      "                                                                 \n",
      " dropout_118 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_235 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_119 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_236 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,987,306\n",
      "Trainable params: 4,987,306\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 0.3297 - accuracy: 0.8963\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 19s 21ms/step - loss: 0.1538 - accuracy: 0.9514\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 0.1081 - accuracy: 0.9660\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 0.0874 - accuracy: 0.9722\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 0.0742 - accuracy: 0.9762\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 0.0586 - accuracy: 0.9811\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 0.0603 - accuracy: 0.9811\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 0.0543 - accuracy: 0.9831\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 0.0447 - accuracy: 0.9864\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 0.0457 - accuracy: 0.9859\n",
      "Model: \"sequential_115\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_115 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 24, 24, 16)        416       \n",
      "                                                                 \n",
      " flatten_115 (Flatten)       (None, 9216)              0         \n",
      "                                                                 \n",
      " dense_237 (Dense)           (None, 512)               4719104   \n",
      "                                                                 \n",
      " dropout_120 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_238 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_121 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_239 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,987,306\n",
      "Trainable params: 4,987,306\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 0.3382 - accuracy: 0.8976\n",
      "Epoch 2/25\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 0.1464 - accuracy: 0.9549\n",
      "Epoch 3/25\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 0.1040 - accuracy: 0.9677\n",
      "Epoch 4/25\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 0.0846 - accuracy: 0.9730\n",
      "Epoch 5/25\n",
      "938/938 [==============================] - 20s 22ms/step - loss: 0.0690 - accuracy: 0.9779\n",
      "Epoch 6/25\n",
      "938/938 [==============================] - 21s 23ms/step - loss: 0.0600 - accuracy: 0.9813\n",
      "Epoch 7/25\n",
      "938/938 [==============================] - 21s 22ms/step - loss: 0.0537 - accuracy: 0.9824\n",
      "Epoch 8/25\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 0.0534 - accuracy: 0.9837\n",
      "Epoch 9/25\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 0.0463 - accuracy: 0.9855\n",
      "Epoch 10/25\n",
      "938/938 [==============================] - 19s 21ms/step - loss: 0.0478 - accuracy: 0.9854\n",
      "Epoch 11/25\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 0.0404 - accuracy: 0.9876\n",
      "Epoch 12/25\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 0.0455 - accuracy: 0.9863\n",
      "Epoch 13/25\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 0.0422 - accuracy: 0.9879\n",
      "Epoch 14/25\n",
      "938/938 [==============================] - 19s 21ms/step - loss: 0.0406 - accuracy: 0.9884\n",
      "Epoch 15/25\n",
      "938/938 [==============================] - 19s 21ms/step - loss: 0.0367 - accuracy: 0.9892\n",
      "Epoch 16/25\n",
      "938/938 [==============================] - 20s 21ms/step - loss: 0.0428 - accuracy: 0.9886\n",
      "Epoch 17/25\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 0.0337 - accuracy: 0.9906\n",
      "Epoch 18/25\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 0.0373 - accuracy: 0.9897\n",
      "Epoch 19/25\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 0.0383 - accuracy: 0.9894\n",
      "Epoch 20/25\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 0.0350 - accuracy: 0.9905\n",
      "Epoch 21/25\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 0.0391 - accuracy: 0.9894\n",
      "Epoch 22/25\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 0.0328 - accuracy: 0.9904\n",
      "Epoch 23/25\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 0.0329 - accuracy: 0.9908\n",
      "Epoch 24/25\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 0.0330 - accuracy: 0.9916\n",
      "Epoch 25/25\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 0.0346 - accuracy: 0.9906\n",
      "Model: \"sequential_116\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_116 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 24, 24, 16)        416       \n",
      "                                                                 \n",
      " flatten_116 (Flatten)       (None, 9216)              0         \n",
      "                                                                 \n",
      " dense_240 (Dense)           (None, 512)               4719104   \n",
      "                                                                 \n",
      " dropout_122 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_241 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_123 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_242 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,987,306\n",
      "Trainable params: 4,987,306\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "469/469 [==============================] - 12s 24ms/step - loss: 0.3522 - accuracy: 0.8933\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 11s 24ms/step - loss: 0.1397 - accuracy: 0.9570\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 11s 24ms/step - loss: 0.0941 - accuracy: 0.9707\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.0731 - accuracy: 0.9765\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 12s 26ms/step - loss: 0.0574 - accuracy: 0.9814\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.0489 - accuracy: 0.9838\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.0436 - accuracy: 0.9856\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.0406 - accuracy: 0.9869\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.0364 - accuracy: 0.9879\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.0341 - accuracy: 0.9887\n",
      "Model: \"sequential_117\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_117 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 24, 24, 16)        416       \n",
      "                                                                 \n",
      " flatten_117 (Flatten)       (None, 9216)              0         \n",
      "                                                                 \n",
      " dense_243 (Dense)           (None, 512)               4719104   \n",
      "                                                                 \n",
      " dropout_124 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_244 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_125 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_245 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,987,306\n",
      "Trainable params: 4,987,306\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "469/469 [==============================] - 12s 24ms/step - loss: 0.3782 - accuracy: 0.8846\n",
      "Epoch 2/25\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.1617 - accuracy: 0.9505\n",
      "Epoch 3/25\n",
      "469/469 [==============================] - 11s 25ms/step - loss: 0.1077 - accuracy: 0.9661\n",
      "Epoch 4/25\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.0799 - accuracy: 0.9748\n",
      "Epoch 5/25\n",
      "469/469 [==============================] - 11s 24ms/step - loss: 0.0655 - accuracy: 0.9783\n",
      "Epoch 6/25\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.0583 - accuracy: 0.9809\n",
      "Epoch 7/25\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.0476 - accuracy: 0.9847\n",
      "Epoch 8/25\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.0449 - accuracy: 0.9848\n",
      "Epoch 9/25\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.0393 - accuracy: 0.9875\n",
      "Epoch 10/25\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.0383 - accuracy: 0.9875\n",
      "Epoch 11/25\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.0355 - accuracy: 0.9887\n",
      "Epoch 12/25\n",
      "469/469 [==============================] - 11s 24ms/step - loss: 0.0340 - accuracy: 0.9892\n",
      "Epoch 13/25\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.0354 - accuracy: 0.9888\n",
      "Epoch 14/25\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.0296 - accuracy: 0.9905\n",
      "Epoch 15/25\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.0300 - accuracy: 0.9904\n",
      "Epoch 16/25\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.0300 - accuracy: 0.9907\n",
      "Epoch 17/25\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.0309 - accuracy: 0.9907\n",
      "Epoch 18/25\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.0272 - accuracy: 0.9915\n",
      "Epoch 19/25\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.0234 - accuracy: 0.9928\n",
      "Epoch 20/25\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.0248 - accuracy: 0.9922\n",
      "Epoch 21/25\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.0250 - accuracy: 0.9917\n",
      "Epoch 22/25\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.0270 - accuracy: 0.9913\n",
      "Epoch 23/25\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.0239 - accuracy: 0.9923\n",
      "Epoch 24/25\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.0209 - accuracy: 0.9935\n",
      "Epoch 25/25\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.0260 - accuracy: 0.9925\n",
      "Model: \"sequential_118\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_118 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 24, 24, 16)        416       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 12, 12, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_118 (Flatten)       (None, 2304)              0         \n",
      "                                                                 \n",
      " dense_246 (Dense)           (None, 512)               1180160   \n",
      "                                                                 \n",
      " dropout_126 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_247 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_127 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_248 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,448,362\n",
      "Trainable params: 1,448,362\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.2753 - accuracy: 0.9147\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.1068 - accuracy: 0.9688\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0657 - accuracy: 0.9805\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0476 - accuracy: 0.9862\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0366 - accuracy: 0.9894\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0324 - accuracy: 0.9904\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0280 - accuracy: 0.9924\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0248 - accuracy: 0.9937\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0237 - accuracy: 0.9933\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0239 - accuracy: 0.9942\n",
      "Model: \"sequential_119\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_119 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 24, 24, 16)        416       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 12, 12, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_119 (Flatten)       (None, 2304)              0         \n",
      "                                                                 \n",
      " dense_249 (Dense)           (None, 512)               1180160   \n",
      "                                                                 \n",
      " dropout_128 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_250 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_129 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_251 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,448,362\n",
      "Trainable params: 1,448,362\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.2727 - accuracy: 0.9164\n",
      "Epoch 2/25\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0957 - accuracy: 0.9711\n",
      "Epoch 3/25\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0583 - accuracy: 0.9822\n",
      "Epoch 4/25\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0416 - accuracy: 0.9883\n",
      "Epoch 5/25\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0333 - accuracy: 0.9899\n",
      "Epoch 6/25\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0314 - accuracy: 0.9915\n",
      "Epoch 7/25\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0284 - accuracy: 0.9928\n",
      "Epoch 8/25\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0262 - accuracy: 0.9934\n",
      "Epoch 9/25\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0230 - accuracy: 0.9941\n",
      "Epoch 10/25\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0210 - accuracy: 0.9948\n",
      "Epoch 11/25\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0200 - accuracy: 0.9953\n",
      "Epoch 12/25\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0191 - accuracy: 0.9956\n",
      "Epoch 13/25\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0217 - accuracy: 0.9956\n",
      "Epoch 14/25\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0199 - accuracy: 0.9957\n",
      "Epoch 15/25\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0224 - accuracy: 0.9956\n",
      "Epoch 16/25\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0211 - accuracy: 0.9957\n",
      "Epoch 17/25\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0204 - accuracy: 0.9957\n",
      "Epoch 18/25\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0207 - accuracy: 0.9960\n",
      "Epoch 19/25\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0166 - accuracy: 0.9966\n",
      "Epoch 20/25\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0190 - accuracy: 0.9965\n",
      "Epoch 21/25\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0182 - accuracy: 0.9968\n",
      "Epoch 22/25\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0192 - accuracy: 0.9966\n",
      "Epoch 23/25\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0207 - accuracy: 0.9964\n",
      "Epoch 24/25\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0203 - accuracy: 0.9966\n",
      "Epoch 25/25\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0204 - accuracy: 0.9969\n",
      "Model: \"sequential_120\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_120 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 24, 24, 16)        416       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 12, 12, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_120 (Flatten)       (None, 2304)              0         \n",
      "                                                                 \n",
      " dense_252 (Dense)           (None, 512)               1180160   \n",
      "                                                                 \n",
      " dropout_130 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_253 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_131 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_254 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,448,362\n",
      "Trainable params: 1,448,362\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "469/469 [==============================] - 9s 18ms/step - loss: 0.2973 - accuracy: 0.9080\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 9s 18ms/step - loss: 0.1031 - accuracy: 0.9691\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 0.0566 - accuracy: 0.9829\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 9s 18ms/step - loss: 0.0399 - accuracy: 0.9875\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 9s 18ms/step - loss: 0.0267 - accuracy: 0.9912\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 9s 18ms/step - loss: 0.0223 - accuracy: 0.9927\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 0.0197 - accuracy: 0.9938\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 0.0174 - accuracy: 0.9949\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 0.0170 - accuracy: 0.9951\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 0.0147 - accuracy: 0.9959\n",
      "Model: \"sequential_121\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_121 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 24, 24, 16)        416       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 12, 12, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_121 (Flatten)       (None, 2304)              0         \n",
      "                                                                 \n",
      " dense_255 (Dense)           (None, 512)               1180160   \n",
      "                                                                 \n",
      " dropout_132 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_256 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_133 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_257 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,448,362\n",
      "Trainable params: 1,448,362\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "469/469 [==============================] - 9s 18ms/step - loss: 0.3236 - accuracy: 0.8985\n",
      "Epoch 2/25\n",
      "469/469 [==============================] - 9s 18ms/step - loss: 0.1060 - accuracy: 0.9678\n",
      "Epoch 3/25\n",
      "469/469 [==============================] - 9s 18ms/step - loss: 0.0619 - accuracy: 0.9805\n",
      "Epoch 4/25\n",
      "469/469 [==============================] - 9s 18ms/step - loss: 0.0385 - accuracy: 0.9882\n",
      "Epoch 5/25\n",
      "469/469 [==============================] - 9s 18ms/step - loss: 0.0277 - accuracy: 0.9912\n",
      "Epoch 6/25\n",
      "469/469 [==============================] - 9s 18ms/step - loss: 0.0208 - accuracy: 0.9932\n",
      "Epoch 7/25\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 0.0186 - accuracy: 0.9945\n",
      "Epoch 8/25\n",
      "469/469 [==============================] - 9s 18ms/step - loss: 0.0162 - accuracy: 0.9950\n",
      "Epoch 9/25\n",
      "469/469 [==============================] - 9s 18ms/step - loss: 0.0139 - accuracy: 0.9956\n",
      "Epoch 10/25\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 0.0148 - accuracy: 0.9955\n",
      "Epoch 11/25\n",
      "469/469 [==============================] - 9s 18ms/step - loss: 0.0135 - accuracy: 0.9962\n",
      "Epoch 12/25\n",
      "469/469 [==============================] - 9s 18ms/step - loss: 0.0116 - accuracy: 0.9969\n",
      "Epoch 13/25\n",
      "469/469 [==============================] - 9s 18ms/step - loss: 0.0133 - accuracy: 0.9961\n",
      "Epoch 14/25\n",
      "469/469 [==============================] - 9s 18ms/step - loss: 0.0111 - accuracy: 0.9971\n",
      "Epoch 15/25\n",
      "469/469 [==============================] - 9s 18ms/step - loss: 0.0124 - accuracy: 0.9969\n",
      "Epoch 16/25\n",
      "469/469 [==============================] - 9s 18ms/step - loss: 0.0118 - accuracy: 0.9966\n",
      "Epoch 17/25\n",
      "469/469 [==============================] - 9s 18ms/step - loss: 0.0097 - accuracy: 0.9971\n",
      "Epoch 18/25\n",
      "469/469 [==============================] - 9s 18ms/step - loss: 0.0111 - accuracy: 0.9971\n",
      "Epoch 19/25\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 0.0092 - accuracy: 0.9975\n",
      "Epoch 20/25\n",
      "469/469 [==============================] - 9s 18ms/step - loss: 0.0109 - accuracy: 0.9973\n",
      "Epoch 21/25\n",
      "469/469 [==============================] - 9s 18ms/step - loss: 0.0090 - accuracy: 0.9974\n",
      "Epoch 22/25\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 0.0098 - accuracy: 0.9977\n",
      "Epoch 23/25\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 0.0105 - accuracy: 0.9976\n",
      "Epoch 24/25\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 0.0081 - accuracy: 0.9978\n",
      "Epoch 25/25\n",
      "469/469 [==============================] - 9s 18ms/step - loss: 0.0089 - accuracy: 0.9978\n",
      "Model: \"sequential_122\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_122 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 24, 24, 16)        416       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 12, 12, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_122 (Flatten)       (None, 2304)              0         \n",
      "                                                                 \n",
      " dense_258 (Dense)           (None, 512)               1180160   \n",
      "                                                                 \n",
      " dropout_134 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_259 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_135 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_260 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,448,362\n",
      "Trainable params: 1,448,362\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.2461 - accuracy: 0.9242\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0770 - accuracy: 0.9768\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0418 - accuracy: 0.9867\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0339 - accuracy: 0.9891\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0260 - accuracy: 0.9917\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0238 - accuracy: 0.9923\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0241 - accuracy: 0.9919\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0189 - accuracy: 0.9943\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0178 - accuracy: 0.9941\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0191 - accuracy: 0.9939\n",
      "Model: \"sequential_123\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_123 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 24, 24, 16)        416       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 12, 12, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_123 (Flatten)       (None, 2304)              0         \n",
      "                                                                 \n",
      " dense_261 (Dense)           (None, 512)               1180160   \n",
      "                                                                 \n",
      " dropout_136 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_262 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_137 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_263 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,448,362\n",
      "Trainable params: 1,448,362\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.2652 - accuracy: 0.9181\n",
      "Epoch 2/25\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0887 - accuracy: 0.9724\n",
      "Epoch 3/25\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0530 - accuracy: 0.9829\n",
      "Epoch 4/25\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0384 - accuracy: 0.9877\n",
      "Epoch 5/25\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0316 - accuracy: 0.9895\n",
      "Epoch 6/25\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0274 - accuracy: 0.9910\n",
      "Epoch 7/25\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0249 - accuracy: 0.9918\n",
      "Epoch 8/25\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0235 - accuracy: 0.9925\n",
      "Epoch 9/25\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0205 - accuracy: 0.9934\n",
      "Epoch 10/25\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0204 - accuracy: 0.9939\n",
      "Epoch 11/25\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0197 - accuracy: 0.9943\n",
      "Epoch 12/25\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0162 - accuracy: 0.9951\n",
      "Epoch 13/25\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0204 - accuracy: 0.9940\n",
      "Epoch 14/25\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0186 - accuracy: 0.9948\n",
      "Epoch 15/25\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0163 - accuracy: 0.9949\n",
      "Epoch 16/25\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0176 - accuracy: 0.9948\n",
      "Epoch 17/25\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0139 - accuracy: 0.9959\n",
      "Epoch 18/25\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0192 - accuracy: 0.9946\n",
      "Epoch 19/25\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0151 - accuracy: 0.9956\n",
      "Epoch 20/25\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0136 - accuracy: 0.9962\n",
      "Epoch 21/25\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0175 - accuracy: 0.9951\n",
      "Epoch 22/25\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0162 - accuracy: 0.9954\n",
      "Epoch 23/25\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0156 - accuracy: 0.9955\n",
      "Epoch 24/25\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0182 - accuracy: 0.9954\n",
      "Epoch 25/25\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0113 - accuracy: 0.9968\n",
      "Model: \"sequential_124\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_124 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 24, 24, 16)        416       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 12, 12, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_124 (Flatten)       (None, 2304)              0         \n",
      "                                                                 \n",
      " dense_264 (Dense)           (None, 512)               1180160   \n",
      "                                                                 \n",
      " dropout_138 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_265 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_139 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_266 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,448,362\n",
      "Trainable params: 1,448,362\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.2651 - accuracy: 0.9186\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.0803 - accuracy: 0.9746\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.0416 - accuracy: 0.9869\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.0267 - accuracy: 0.9912\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.0203 - accuracy: 0.9934\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.0182 - accuracy: 0.9941\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.0188 - accuracy: 0.9938\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.0140 - accuracy: 0.9953\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.0139 - accuracy: 0.9954\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.0166 - accuracy: 0.9948\n",
      "Model: \"sequential_125\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_125 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 24, 24, 16)        416       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 12, 12, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_125 (Flatten)       (None, 2304)              0         \n",
      "                                                                 \n",
      " dense_267 (Dense)           (None, 512)               1180160   \n",
      "                                                                 \n",
      " dropout_140 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_268 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_141 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_269 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,448,362\n",
      "Trainable params: 1,448,362\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.2635 - accuracy: 0.9189\n",
      "Epoch 2/25\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.0763 - accuracy: 0.9771\n",
      "Epoch 3/25\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.0389 - accuracy: 0.9876\n",
      "Epoch 4/25\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.0285 - accuracy: 0.9907\n",
      "Epoch 5/25\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.0194 - accuracy: 0.9937\n",
      "Epoch 6/25\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.0191 - accuracy: 0.9940\n",
      "Epoch 7/25\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.0159 - accuracy: 0.9946\n",
      "Epoch 8/25\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.0148 - accuracy: 0.9949\n",
      "Epoch 9/25\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.0145 - accuracy: 0.9951\n",
      "Epoch 10/25\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.0126 - accuracy: 0.9960\n",
      "Epoch 11/25\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.0129 - accuracy: 0.9958\n",
      "Epoch 12/25\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.0121 - accuracy: 0.9962\n",
      "Epoch 13/25\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.0117 - accuracy: 0.9962\n",
      "Epoch 14/25\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.0133 - accuracy: 0.9959\n",
      "Epoch 15/25\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.0119 - accuracy: 0.9963\n",
      "Epoch 16/25\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.0111 - accuracy: 0.9966\n",
      "Epoch 17/25\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.0109 - accuracy: 0.9969\n",
      "Epoch 18/25\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.0097 - accuracy: 0.9967\n",
      "Epoch 19/25\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.0112 - accuracy: 0.9970\n",
      "Epoch 20/25\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.0097 - accuracy: 0.9971\n",
      "Epoch 21/25\n",
      "469/469 [==============================] - 7s 14ms/step - loss: 0.0100 - accuracy: 0.9970\n",
      "Epoch 22/25\n",
      "469/469 [==============================] - 7s 14ms/step - loss: 0.0097 - accuracy: 0.9972\n",
      "Epoch 23/25\n",
      "469/469 [==============================] - 7s 14ms/step - loss: 0.0079 - accuracy: 0.9979\n",
      "Epoch 24/25\n",
      "469/469 [==============================] - 7s 14ms/step - loss: 0.0090 - accuracy: 0.9974\n",
      "Epoch 25/25\n",
      "469/469 [==============================] - 7s 14ms/step - loss: 0.0096 - accuracy: 0.9972\n",
      "Model: \"sequential_126\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_126 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 24, 24, 16)        416       \n",
      "                                                                 \n",
      " global_max_pooling2d (Globa  (None, 16)               0         \n",
      " lMaxPooling2D)                                                  \n",
      "                                                                 \n",
      " dense_270 (Dense)           (None, 512)               8704      \n",
      "                                                                 \n",
      " dropout_142 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_271 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_143 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_272 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 276,906\n",
      "Trainable params: 276,906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 1.4638 - accuracy: 0.4976\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 6s 7ms/step - loss: 1.0758 - accuracy: 0.6340\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 6s 7ms/step - loss: 0.9672 - accuracy: 0.6737\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 6s 7ms/step - loss: 0.9033 - accuracy: 0.6959\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 6s 7ms/step - loss: 0.8602 - accuracy: 0.7110\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 6s 7ms/step - loss: 0.8296 - accuracy: 0.7216\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 6s 7ms/step - loss: 0.8084 - accuracy: 0.7309\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 6s 7ms/step - loss: 0.7901 - accuracy: 0.7347\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 6s 7ms/step - loss: 0.7761 - accuracy: 0.7413\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 6s 7ms/step - loss: 0.7646 - accuracy: 0.7463\n",
      "Model: \"sequential_127\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_127 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 24, 24, 16)        416       \n",
      "                                                                 \n",
      " global_max_pooling2d (Globa  (None, 16)               0         \n",
      " lMaxPooling2D)                                                  \n",
      "                                                                 \n",
      " dense_273 (Dense)           (None, 512)               8704      \n",
      "                                                                 \n",
      " dropout_144 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_274 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_145 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_275 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 276,906\n",
      "Trainable params: 276,906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 1.5805 - accuracy: 0.4507\n",
      "Epoch 2/25\n",
      "938/938 [==============================] - 6s 7ms/step - loss: 1.2071 - accuracy: 0.5956\n",
      "Epoch 3/25\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 1.0751 - accuracy: 0.6396\n",
      "Epoch 4/25\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 1.0003 - accuracy: 0.6680\n",
      "Epoch 5/25\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.9477 - accuracy: 0.6844\n",
      "Epoch 6/25\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.9024 - accuracy: 0.7022\n",
      "Epoch 7/25\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.8715 - accuracy: 0.7135\n",
      "Epoch 8/25\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.8482 - accuracy: 0.7219\n",
      "Epoch 9/25\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.8307 - accuracy: 0.7266\n",
      "Epoch 10/25\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.8120 - accuracy: 0.7329\n",
      "Epoch 11/25\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.7990 - accuracy: 0.7362\n",
      "Epoch 12/25\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.7856 - accuracy: 0.7407\n",
      "Epoch 13/25\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.7729 - accuracy: 0.7452\n",
      "Epoch 14/25\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.7625 - accuracy: 0.7513\n",
      "Epoch 15/25\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.7571 - accuracy: 0.7524\n",
      "Epoch 16/25\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.7523 - accuracy: 0.7544\n",
      "Epoch 17/25\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.7443 - accuracy: 0.7569\n",
      "Epoch 18/25\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.7426 - accuracy: 0.7570\n",
      "Epoch 19/25\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.7391 - accuracy: 0.7596\n",
      "Epoch 20/25\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.7354 - accuracy: 0.7617\n",
      "Epoch 21/25\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.7326 - accuracy: 0.7608\n",
      "Epoch 22/25\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.7288 - accuracy: 0.7638\n",
      "Epoch 23/25\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.7220 - accuracy: 0.7658\n",
      "Epoch 24/25\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.7245 - accuracy: 0.7667\n",
      "Epoch 25/25\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.7249 - accuracy: 0.7666\n",
      "Model: \"sequential_128\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_128 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 24, 24, 16)        416       \n",
      "                                                                 \n",
      " global_max_pooling2d (Globa  (None, 16)               0         \n",
      " lMaxPooling2D)                                                  \n",
      "                                                                 \n",
      " dense_276 (Dense)           (None, 512)               8704      \n",
      "                                                                 \n",
      " dropout_146 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_277 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_147 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_278 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 276,906\n",
      "Trainable params: 276,906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "469/469 [==============================] - 5s 11ms/step - loss: 1.6781 - accuracy: 0.4083\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 5s 11ms/step - loss: 1.2527 - accuracy: 0.5733\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 5s 11ms/step - loss: 1.1278 - accuracy: 0.6161\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 5s 11ms/step - loss: 1.0580 - accuracy: 0.6405\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 5s 11ms/step - loss: 0.9992 - accuracy: 0.6598\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 5s 11ms/step - loss: 0.9609 - accuracy: 0.6747\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 5s 11ms/step - loss: 0.9290 - accuracy: 0.6848\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 5s 11ms/step - loss: 0.9028 - accuracy: 0.6950\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 5s 11ms/step - loss: 0.8784 - accuracy: 0.7024\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 5s 11ms/step - loss: 0.8567 - accuracy: 0.7089\n",
      "Model: \"sequential_129\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_129 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 24, 24, 16)        416       \n",
      "                                                                 \n",
      " global_max_pooling2d (Globa  (None, 16)               0         \n",
      " lMaxPooling2D)                                                  \n",
      "                                                                 \n",
      " dense_279 (Dense)           (None, 512)               8704      \n",
      "                                                                 \n",
      " dropout_148 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_280 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_149 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_281 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 276,906\n",
      "Trainable params: 276,906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 1.6762 - accuracy: 0.4157\n",
      "Epoch 2/25\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 1.2524 - accuracy: 0.5711\n",
      "Epoch 3/25\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 1.1139 - accuracy: 0.6225\n",
      "Epoch 4/25\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 1.0367 - accuracy: 0.6492\n",
      "Epoch 5/25\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.9858 - accuracy: 0.6683\n",
      "Epoch 6/25\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.9437 - accuracy: 0.6832\n",
      "Epoch 7/25\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.9163 - accuracy: 0.6913\n",
      "Epoch 8/25\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.8918 - accuracy: 0.7010\n",
      "Epoch 9/25\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.8708 - accuracy: 0.7069\n",
      "Epoch 10/25\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.8555 - accuracy: 0.7149\n",
      "Epoch 11/25\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.8340 - accuracy: 0.7214\n",
      "Epoch 12/25\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.8219 - accuracy: 0.7270\n",
      "Epoch 13/25\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.8062 - accuracy: 0.7305\n",
      "Epoch 14/25\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.7925 - accuracy: 0.7361\n",
      "Epoch 15/25\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.7809 - accuracy: 0.7384\n",
      "Epoch 16/25\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.7681 - accuracy: 0.7431\n",
      "Epoch 17/25\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.7576 - accuracy: 0.7478\n",
      "Epoch 18/25\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.7517 - accuracy: 0.7504\n",
      "Epoch 19/25\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.7387 - accuracy: 0.7533\n",
      "Epoch 20/25\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.7336 - accuracy: 0.7574\n",
      "Epoch 21/25\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.7272 - accuracy: 0.7550\n",
      "Epoch 22/25\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.7201 - accuracy: 0.7595\n",
      "Epoch 23/25\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.7137 - accuracy: 0.7610\n",
      "Epoch 24/25\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.7103 - accuracy: 0.7629\n",
      "Epoch 25/25\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.7008 - accuracy: 0.7660\n",
      "Model: \"sequential_130\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_130 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 24, 24, 16)        416       \n",
      "                                                                 \n",
      " global_max_pooling2d (Globa  (None, 16)               0         \n",
      " lMaxPooling2D)                                                  \n",
      "                                                                 \n",
      " dense_282 (Dense)           (None, 512)               8704      \n",
      "                                                                 \n",
      " dropout_150 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_283 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_151 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_284 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 276,906\n",
      "Trainable params: 276,906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 1.4491 - accuracy: 0.5008\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 1.0389 - accuracy: 0.6569\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 0.9439 - accuracy: 0.6884\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 0.8963 - accuracy: 0.7042\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 0.8614 - accuracy: 0.7143\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 0.8392 - accuracy: 0.7208\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 0.8169 - accuracy: 0.7297\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 0.8021 - accuracy: 0.7352\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 0.7870 - accuracy: 0.7398\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 0.7746 - accuracy: 0.7416\n",
      "Model: \"sequential_131\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_131 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 24, 24, 16)        416       \n",
      "                                                                 \n",
      " global_max_pooling2d (Globa  (None, 16)               0         \n",
      " lMaxPooling2D)                                                  \n",
      "                                                                 \n",
      " dense_285 (Dense)           (None, 512)               8704      \n",
      "                                                                 \n",
      " dropout_152 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_286 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_153 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_287 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 276,906\n",
      "Trainable params: 276,906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 1.4008 - accuracy: 0.5040\n",
      "Epoch 2/25\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 1.1191 - accuracy: 0.6173\n",
      "Epoch 3/25\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 1.0408 - accuracy: 0.6469\n",
      "Epoch 4/25\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 0.9892 - accuracy: 0.6653\n",
      "Epoch 5/25\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 0.9598 - accuracy: 0.6755\n",
      "Epoch 6/25\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 0.9292 - accuracy: 0.6878\n",
      "Epoch 7/25\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 0.9023 - accuracy: 0.6963\n",
      "Epoch 8/25\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 0.8780 - accuracy: 0.7037\n",
      "Epoch 9/25\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 0.8591 - accuracy: 0.7128\n",
      "Epoch 10/25\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 0.8364 - accuracy: 0.7200\n",
      "Epoch 11/25\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 0.8200 - accuracy: 0.7258\n",
      "Epoch 12/25\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 0.8053 - accuracy: 0.7315\n",
      "Epoch 13/25\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 0.7925 - accuracy: 0.7343\n",
      "Epoch 14/25\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 0.7808 - accuracy: 0.7391\n",
      "Epoch 15/25\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 0.7662 - accuracy: 0.7435\n",
      "Epoch 16/25\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 0.7521 - accuracy: 0.7502\n",
      "Epoch 17/25\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 0.7424 - accuracy: 0.7527\n",
      "Epoch 18/25\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 0.7292 - accuracy: 0.7572\n",
      "Epoch 19/25\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 0.7224 - accuracy: 0.7585\n",
      "Epoch 20/25\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 0.7109 - accuracy: 0.7634\n",
      "Epoch 21/25\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 0.7058 - accuracy: 0.7664\n",
      "Epoch 22/25\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 0.6980 - accuracy: 0.7667\n",
      "Epoch 23/25\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 0.6922 - accuracy: 0.7712\n",
      "Epoch 24/25\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 0.6833 - accuracy: 0.7731\n",
      "Epoch 25/25\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 0.6766 - accuracy: 0.7739\n",
      "Model: \"sequential_132\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_132 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_24 (Conv2D)          (None, 24, 24, 16)        416       \n",
      "                                                                 \n",
      " global_max_pooling2d (Globa  (None, 16)               0         \n",
      " lMaxPooling2D)                                                  \n",
      "                                                                 \n",
      " dense_288 (Dense)           (None, 512)               8704      \n",
      "                                                                 \n",
      " dropout_154 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_289 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_155 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_290 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 276,906\n",
      "Trainable params: 276,906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 1.4068 - accuracy: 0.5109\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 1.0588 - accuracy: 0.6425\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.9815 - accuracy: 0.6674\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.9384 - accuracy: 0.6829\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.9050 - accuracy: 0.6954\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.8798 - accuracy: 0.7045\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.8641 - accuracy: 0.7124\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.8444 - accuracy: 0.7186\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.8339 - accuracy: 0.7224\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.8210 - accuracy: 0.7271\n",
      "Model: \"sequential_133\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_133 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 24, 24, 16)        416       \n",
      "                                                                 \n",
      " global_max_pooling2d (Globa  (None, 16)               0         \n",
      " lMaxPooling2D)                                                  \n",
      "                                                                 \n",
      " dense_291 (Dense)           (None, 512)               8704      \n",
      "                                                                 \n",
      " dropout_156 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_292 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_157 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_293 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 276,906\n",
      "Trainable params: 276,906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 1.3854 - accuracy: 0.5159\n",
      "Epoch 2/25\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 1.0644 - accuracy: 0.6402\n",
      "Epoch 3/25\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.9854 - accuracy: 0.6671\n",
      "Epoch 4/25\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.9373 - accuracy: 0.6848\n",
      "Epoch 5/25\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.9100 - accuracy: 0.6940\n",
      "Epoch 6/25\n",
      "469/469 [==============================] - 4s 10ms/step - loss: 0.8797 - accuracy: 0.7041\n",
      "Epoch 7/25\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.8596 - accuracy: 0.7114\n",
      "Epoch 8/25\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.8437 - accuracy: 0.7166\n",
      "Epoch 9/25\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.8274 - accuracy: 0.7217\n",
      "Epoch 10/25\n",
      "469/469 [==============================] - 4s 10ms/step - loss: 0.8120 - accuracy: 0.7281\n",
      "Epoch 11/25\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.8012 - accuracy: 0.7315\n",
      "Epoch 12/25\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.7917 - accuracy: 0.7348\n",
      "Epoch 13/25\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.7785 - accuracy: 0.7392\n",
      "Epoch 14/25\n",
      "469/469 [==============================] - 4s 10ms/step - loss: 0.7709 - accuracy: 0.7427\n",
      "Epoch 15/25\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.7604 - accuracy: 0.7454\n",
      "Epoch 16/25\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.7529 - accuracy: 0.7489\n",
      "Epoch 17/25\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.7459 - accuracy: 0.7512\n",
      "Epoch 18/25\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.7373 - accuracy: 0.7533\n",
      "Epoch 19/25\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.7297 - accuracy: 0.7567\n",
      "Epoch 20/25\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.7241 - accuracy: 0.7594\n",
      "Epoch 21/25\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.7183 - accuracy: 0.7602\n",
      "Epoch 22/25\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.7117 - accuracy: 0.7630\n",
      "Epoch 23/25\n",
      "469/469 [==============================] - 4s 10ms/step - loss: 0.7097 - accuracy: 0.7636\n",
      "Epoch 24/25\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.7034 - accuracy: 0.7670\n",
      "Epoch 25/25\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.6991 - accuracy: 0.7665\n",
      "Model: \"sequential_134\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_134 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 22, 22, 16)        800       \n",
      "                                                                 \n",
      " flatten_126 (Flatten)       (None, 7744)              0         \n",
      "                                                                 \n",
      " dense_294 (Dense)           (None, 512)               3965440   \n",
      "                                                                 \n",
      " dropout_158 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_295 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_159 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_296 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,234,026\n",
      "Trainable params: 4,234,026\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 28s 30ms/step - loss: 0.3502 - accuracy: 0.8935\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 28s 30ms/step - loss: 0.1764 - accuracy: 0.9481\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 28s 30ms/step - loss: 0.1354 - accuracy: 0.9610\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 28s 30ms/step - loss: 0.1151 - accuracy: 0.9678\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 28s 30ms/step - loss: 0.1055 - accuracy: 0.9712\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 28s 30ms/step - loss: 0.1026 - accuracy: 0.9728\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 28s 30ms/step - loss: 0.1027 - accuracy: 0.9740\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 28s 30ms/step - loss: 0.0967 - accuracy: 0.9767\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 28s 30ms/step - loss: 0.0985 - accuracy: 0.9762\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 28s 30ms/step - loss: 0.1049 - accuracy: 0.9768\n",
      "Model: \"sequential_135\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_135 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_27 (Conv2D)          (None, 22, 22, 16)        800       \n",
      "                                                                 \n",
      " flatten_127 (Flatten)       (None, 7744)              0         \n",
      "                                                                 \n",
      " dense_297 (Dense)           (None, 512)               3965440   \n",
      "                                                                 \n",
      " dropout_160 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_298 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_161 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_299 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,234,026\n",
      "Trainable params: 4,234,026\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "938/938 [==============================] - 29s 30ms/step - loss: 0.3408 - accuracy: 0.8978\n",
      "Epoch 2/25\n",
      "938/938 [==============================] - 28s 30ms/step - loss: 0.1781 - accuracy: 0.9483\n",
      "Epoch 3/25\n",
      "938/938 [==============================] - 28s 30ms/step - loss: 0.1359 - accuracy: 0.9608\n",
      "Epoch 4/25\n",
      "938/938 [==============================] - 28s 30ms/step - loss: 0.1155 - accuracy: 0.9673\n",
      "Epoch 5/25\n",
      "938/938 [==============================] - 28s 30ms/step - loss: 0.1079 - accuracy: 0.9704\n",
      "Epoch 6/25\n",
      "938/938 [==============================] - 28s 30ms/step - loss: 0.1038 - accuracy: 0.9733\n",
      "Epoch 7/25\n",
      "938/938 [==============================] - 28s 30ms/step - loss: 0.0988 - accuracy: 0.9749\n",
      "Epoch 8/25\n",
      "938/938 [==============================] - 28s 30ms/step - loss: 0.1022 - accuracy: 0.9764\n",
      "Epoch 9/25\n",
      "938/938 [==============================] - 28s 30ms/step - loss: 0.1016 - accuracy: 0.9765\n",
      "Epoch 10/25\n",
      "938/938 [==============================] - 30s 32ms/step - loss: 0.0992 - accuracy: 0.9776\n",
      "Epoch 11/25\n",
      "938/938 [==============================] - 30s 32ms/step - loss: 0.0973 - accuracy: 0.9783\n",
      "Epoch 12/25\n",
      "938/938 [==============================] - 30s 32ms/step - loss: 0.1136 - accuracy: 0.9764\n",
      "Epoch 13/25\n",
      "938/938 [==============================] - 30s 32ms/step - loss: 0.1088 - accuracy: 0.9774\n",
      "Epoch 14/25\n",
      "938/938 [==============================] - 30s 32ms/step - loss: 0.1105 - accuracy: 0.9777\n",
      "Epoch 15/25\n",
      "938/938 [==============================] - 30s 32ms/step - loss: 0.1100 - accuracy: 0.9786\n",
      "Epoch 16/25\n",
      "938/938 [==============================] - 30s 32ms/step - loss: 0.1148 - accuracy: 0.9788\n",
      "Epoch 17/25\n",
      "938/938 [==============================] - 30s 32ms/step - loss: 0.1199 - accuracy: 0.9784\n",
      "Epoch 18/25\n",
      "938/938 [==============================] - 30s 31ms/step - loss: 0.1092 - accuracy: 0.9807\n",
      "Epoch 19/25\n",
      "938/938 [==============================] - 30s 31ms/step - loss: 0.1116 - accuracy: 0.9805\n",
      "Epoch 20/25\n",
      "938/938 [==============================] - 30s 32ms/step - loss: 0.1158 - accuracy: 0.9794\n",
      "Epoch 21/25\n",
      "938/938 [==============================] - 30s 32ms/step - loss: 0.1092 - accuracy: 0.9816\n",
      "Epoch 22/25\n",
      "938/938 [==============================] - 30s 31ms/step - loss: 0.1191 - accuracy: 0.9806\n",
      "Epoch 23/25\n",
      "938/938 [==============================] - 30s 32ms/step - loss: 0.1209 - accuracy: 0.9812\n",
      "Epoch 24/25\n",
      "938/938 [==============================] - 30s 32ms/step - loss: 0.1225 - accuracy: 0.9818\n",
      "Epoch 25/25\n",
      "938/938 [==============================] - 30s 32ms/step - loss: 0.1270 - accuracy: 0.9807\n",
      "Model: \"sequential_136\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_136 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_28 (Conv2D)          (None, 22, 22, 16)        800       \n",
      "                                                                 \n",
      " flatten_128 (Flatten)       (None, 7744)              0         \n",
      "                                                                 \n",
      " dense_300 (Dense)           (None, 512)               3965440   \n",
      "                                                                 \n",
      " dropout_162 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_301 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_163 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_302 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,234,026\n",
      "Trainable params: 4,234,026\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "469/469 [==============================] - 21s 44ms/step - loss: 0.3572 - accuracy: 0.8899\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 20s 44ms/step - loss: 0.1614 - accuracy: 0.9506\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 20s 44ms/step - loss: 0.1146 - accuracy: 0.9658\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 20s 44ms/step - loss: 0.0865 - accuracy: 0.9730\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 20s 44ms/step - loss: 0.0691 - accuracy: 0.9790\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 20s 44ms/step - loss: 0.0571 - accuracy: 0.9828\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 21s 44ms/step - loss: 0.0491 - accuracy: 0.9850\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 21s 44ms/step - loss: 0.0442 - accuracy: 0.9864\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 20s 44ms/step - loss: 0.0447 - accuracy: 0.9869\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 21s 44ms/step - loss: 0.0406 - accuracy: 0.9884\n",
      "Model: \"sequential_137\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_137 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_29 (Conv2D)          (None, 22, 22, 16)        800       \n",
      "                                                                 \n",
      " flatten_129 (Flatten)       (None, 7744)              0         \n",
      "                                                                 \n",
      " dense_303 (Dense)           (None, 512)               3965440   \n",
      "                                                                 \n",
      " dropout_164 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_304 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_165 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_305 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,234,026\n",
      "Trainable params: 4,234,026\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "469/469 [==============================] - 21s 43ms/step - loss: 0.3553 - accuracy: 0.8912\n",
      "Epoch 2/25\n",
      "469/469 [==============================] - 20s 43ms/step - loss: 0.1602 - accuracy: 0.9514\n",
      "Epoch 3/25\n",
      "469/469 [==============================] - 20s 43ms/step - loss: 0.1127 - accuracy: 0.9655\n",
      "Epoch 4/25\n",
      "469/469 [==============================] - 20s 43ms/step - loss: 0.0864 - accuracy: 0.9735\n",
      "Epoch 5/25\n",
      "469/469 [==============================] - 20s 43ms/step - loss: 0.0703 - accuracy: 0.9786\n",
      "Epoch 6/25\n",
      "469/469 [==============================] - 20s 43ms/step - loss: 0.0565 - accuracy: 0.9826\n",
      "Epoch 7/25\n",
      "469/469 [==============================] - 20s 43ms/step - loss: 0.0516 - accuracy: 0.9840\n",
      "Epoch 8/25\n",
      "469/469 [==============================] - 20s 43ms/step - loss: 0.0479 - accuracy: 0.9862\n",
      "Epoch 9/25\n",
      "469/469 [==============================] - 20s 43ms/step - loss: 0.0440 - accuracy: 0.9866\n",
      "Epoch 10/25\n",
      "469/469 [==============================] - 20s 43ms/step - loss: 0.0425 - accuracy: 0.9881\n",
      "Epoch 11/25\n",
      "469/469 [==============================] - 20s 43ms/step - loss: 0.0389 - accuracy: 0.9889\n",
      "Epoch 12/25\n",
      "469/469 [==============================] - 20s 43ms/step - loss: 0.0413 - accuracy: 0.9893\n",
      "Epoch 13/25\n",
      "469/469 [==============================] - 20s 43ms/step - loss: 0.0391 - accuracy: 0.9899\n",
      "Epoch 14/25\n",
      "469/469 [==============================] - 20s 43ms/step - loss: 0.0388 - accuracy: 0.9901\n",
      "Epoch 15/25\n",
      "469/469 [==============================] - 20s 43ms/step - loss: 0.0399 - accuracy: 0.9894\n",
      "Epoch 16/25\n",
      "469/469 [==============================] - 20s 43ms/step - loss: 0.0368 - accuracy: 0.9909\n",
      "Epoch 17/25\n",
      "469/469 [==============================] - 20s 43ms/step - loss: 0.0366 - accuracy: 0.9910\n",
      "Epoch 18/25\n",
      "469/469 [==============================] - 20s 43ms/step - loss: 0.0383 - accuracy: 0.9907\n",
      "Epoch 19/25\n",
      "469/469 [==============================] - 20s 43ms/step - loss: 0.0391 - accuracy: 0.9906\n",
      "Epoch 20/25\n",
      "469/469 [==============================] - 20s 42ms/step - loss: 0.0369 - accuracy: 0.9910\n",
      "Epoch 21/25\n",
      "469/469 [==============================] - 20s 42ms/step - loss: 0.0403 - accuracy: 0.9911\n",
      "Epoch 22/25\n",
      "469/469 [==============================] - 20s 42ms/step - loss: 0.0388 - accuracy: 0.9918\n",
      "Epoch 23/25\n",
      "469/469 [==============================] - 20s 43ms/step - loss: 0.0422 - accuracy: 0.9906\n",
      "Epoch 24/25\n",
      "469/469 [==============================] - 20s 43ms/step - loss: 0.0428 - accuracy: 0.9906\n",
      "Epoch 25/25\n",
      "469/469 [==============================] - 20s 42ms/step - loss: 0.0425 - accuracy: 0.9911\n",
      "Model: \"sequential_138\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_138 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_30 (Conv2D)          (None, 22, 22, 16)        800       \n",
      "                                                                 \n",
      " flatten_130 (Flatten)       (None, 7744)              0         \n",
      "                                                                 \n",
      " dense_306 (Dense)           (None, 512)               3965440   \n",
      "                                                                 \n",
      " dropout_166 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_307 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_167 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_308 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,234,026\n",
      "Trainable params: 4,234,026\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 22s 23ms/step - loss: 0.3682 - accuracy: 0.8889\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 22s 23ms/step - loss: 0.1700 - accuracy: 0.9478\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 22s 23ms/step - loss: 0.1285 - accuracy: 0.9595\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 22s 23ms/step - loss: 0.1037 - accuracy: 0.9682\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 22s 23ms/step - loss: 0.0954 - accuracy: 0.9703\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 21s 23ms/step - loss: 0.0831 - accuracy: 0.9748\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 22s 23ms/step - loss: 0.0714 - accuracy: 0.9775\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 22s 23ms/step - loss: 0.0697 - accuracy: 0.9785\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 22s 23ms/step - loss: 0.0661 - accuracy: 0.9791\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 22s 23ms/step - loss: 0.0585 - accuracy: 0.9827\n",
      "Model: \"sequential_139\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_139 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_31 (Conv2D)          (None, 22, 22, 16)        800       \n",
      "                                                                 \n",
      " flatten_131 (Flatten)       (None, 7744)              0         \n",
      "                                                                 \n",
      " dense_309 (Dense)           (None, 512)               3965440   \n",
      "                                                                 \n",
      " dropout_168 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_310 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_169 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_311 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,234,026\n",
      "Trainable params: 4,234,026\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "938/938 [==============================] - 22s 23ms/step - loss: 0.3469 - accuracy: 0.8968\n",
      "Epoch 2/25\n",
      "938/938 [==============================] - 22s 23ms/step - loss: 0.1567 - accuracy: 0.9511\n",
      "Epoch 3/25\n",
      "938/938 [==============================] - 21s 23ms/step - loss: 0.1211 - accuracy: 0.9629\n",
      "Epoch 4/25\n",
      "938/938 [==============================] - 21s 23ms/step - loss: 0.0963 - accuracy: 0.9708\n",
      "Epoch 5/25\n",
      "938/938 [==============================] - 21s 22ms/step - loss: 0.0815 - accuracy: 0.9744\n",
      "Epoch 6/25\n",
      "938/938 [==============================] - 21s 22ms/step - loss: 0.0799 - accuracy: 0.9748\n",
      "Epoch 7/25\n",
      "938/938 [==============================] - 21s 23ms/step - loss: 0.0710 - accuracy: 0.9782\n",
      "Epoch 8/25\n",
      "938/938 [==============================] - 21s 22ms/step - loss: 0.0619 - accuracy: 0.9811\n",
      "Epoch 9/25\n",
      "938/938 [==============================] - 21s 22ms/step - loss: 0.0598 - accuracy: 0.9821\n",
      "Epoch 10/25\n",
      "938/938 [==============================] - 21s 22ms/step - loss: 0.0575 - accuracy: 0.9827\n",
      "Epoch 11/25\n",
      "938/938 [==============================] - 21s 22ms/step - loss: 0.0541 - accuracy: 0.9840\n",
      "Epoch 12/25\n",
      "938/938 [==============================] - 21s 22ms/step - loss: 0.0513 - accuracy: 0.9845\n",
      "Epoch 13/25\n",
      "938/938 [==============================] - 21s 22ms/step - loss: 0.0536 - accuracy: 0.9850\n",
      "Epoch 14/25\n",
      "938/938 [==============================] - 21s 22ms/step - loss: 0.0533 - accuracy: 0.9850\n",
      "Epoch 15/25\n",
      "938/938 [==============================] - 21s 22ms/step - loss: 0.0538 - accuracy: 0.9851\n",
      "Epoch 16/25\n",
      "938/938 [==============================] - 21s 22ms/step - loss: 0.0472 - accuracy: 0.9868\n",
      "Epoch 17/25\n",
      "938/938 [==============================] - 21s 23ms/step - loss: 0.0455 - accuracy: 0.9878\n",
      "Epoch 18/25\n",
      "938/938 [==============================] - 21s 23ms/step - loss: 0.0505 - accuracy: 0.9869\n",
      "Epoch 19/25\n",
      "938/938 [==============================] - 22s 23ms/step - loss: 0.0464 - accuracy: 0.9872\n",
      "Epoch 20/25\n",
      "938/938 [==============================] - 21s 23ms/step - loss: 0.0465 - accuracy: 0.9879\n",
      "Epoch 21/25\n",
      "938/938 [==============================] - 21s 23ms/step - loss: 0.0478 - accuracy: 0.9880\n",
      "Epoch 22/25\n",
      "938/938 [==============================] - 21s 23ms/step - loss: 0.0478 - accuracy: 0.9880\n",
      "Epoch 23/25\n",
      "938/938 [==============================] - 21s 23ms/step - loss: 0.0427 - accuracy: 0.9888\n",
      "Epoch 24/25\n",
      "938/938 [==============================] - 21s 23ms/step - loss: 0.0459 - accuracy: 0.9886\n",
      "Epoch 25/25\n",
      "938/938 [==============================] - 21s 23ms/step - loss: 0.0559 - accuracy: 0.9873\n",
      "Model: \"sequential_140\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_140 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_32 (Conv2D)          (None, 22, 22, 16)        800       \n",
      "                                                                 \n",
      " flatten_132 (Flatten)       (None, 7744)              0         \n",
      "                                                                 \n",
      " dense_312 (Dense)           (None, 512)               3965440   \n",
      "                                                                 \n",
      " dropout_170 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_313 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_171 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_314 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,234,026\n",
      "Trainable params: 4,234,026\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 0.3570 - accuracy: 0.8937\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 0.1505 - accuracy: 0.9547\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 0.1064 - accuracy: 0.9668\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 0.0822 - accuracy: 0.9732\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 0.0654 - accuracy: 0.9802\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 0.0579 - accuracy: 0.9814\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 0.0538 - accuracy: 0.9825\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 0.0470 - accuracy: 0.9848\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 0.0419 - accuracy: 0.9864\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 0.0365 - accuracy: 0.9884\n",
      "Model: \"sequential_141\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_141 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_33 (Conv2D)          (None, 22, 22, 16)        800       \n",
      "                                                                 \n",
      " flatten_133 (Flatten)       (None, 7744)              0         \n",
      "                                                                 \n",
      " dense_315 (Dense)           (None, 512)               3965440   \n",
      "                                                                 \n",
      " dropout_172 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_316 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_173 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_317 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,234,026\n",
      "Trainable params: 4,234,026\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 0.3919 - accuracy: 0.8849\n",
      "Epoch 2/25\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 0.1652 - accuracy: 0.9492\n",
      "Epoch 3/25\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 0.1186 - accuracy: 0.9628\n",
      "Epoch 4/25\n",
      "469/469 [==============================] - 15s 31ms/step - loss: 0.0907 - accuracy: 0.9717\n",
      "Epoch 5/25\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 0.0734 - accuracy: 0.9766\n",
      "Epoch 6/25\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 0.0688 - accuracy: 0.9780\n",
      "Epoch 7/25\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 0.0641 - accuracy: 0.9789\n",
      "Epoch 8/25\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 0.0557 - accuracy: 0.9822\n",
      "Epoch 9/25\n",
      "469/469 [==============================] - 15s 31ms/step - loss: 0.0497 - accuracy: 0.9842\n",
      "Epoch 10/25\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 0.0484 - accuracy: 0.9840\n",
      "Epoch 11/25\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 0.0438 - accuracy: 0.9856\n",
      "Epoch 12/25\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 0.0419 - accuracy: 0.9868\n",
      "Epoch 13/25\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 0.0425 - accuracy: 0.9865\n",
      "Epoch 14/25\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 0.0400 - accuracy: 0.9867\n",
      "Epoch 15/25\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 0.0348 - accuracy: 0.9891\n",
      "Epoch 16/25\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 0.0358 - accuracy: 0.9894\n",
      "Epoch 17/25\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 0.0363 - accuracy: 0.9886\n",
      "Epoch 18/25\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 0.0372 - accuracy: 0.9889\n",
      "Epoch 19/25\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 0.0345 - accuracy: 0.9897\n",
      "Epoch 20/25\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 0.0363 - accuracy: 0.9893\n",
      "Epoch 21/25\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 0.0297 - accuracy: 0.9906\n",
      "Epoch 22/25\n",
      "469/469 [==============================] - 15s 31ms/step - loss: 0.0330 - accuracy: 0.9904\n",
      "Epoch 23/25\n",
      "469/469 [==============================] - 15s 31ms/step - loss: 0.0307 - accuracy: 0.9911\n",
      "Epoch 24/25\n",
      "469/469 [==============================] - 15s 31ms/step - loss: 0.0335 - accuracy: 0.9898\n",
      "Epoch 25/25\n",
      "469/469 [==============================] - 15s 31ms/step - loss: 0.0306 - accuracy: 0.9909\n",
      "Model: \"sequential_142\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_142 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_34 (Conv2D)          (None, 22, 22, 16)        800       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  multiple                 0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_134 (Flatten)       (None, 1936)              0         \n",
      "                                                                 \n",
      " dense_318 (Dense)           (None, 512)               991744    \n",
      "                                                                 \n",
      " dropout_174 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_319 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_175 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_320 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,260,330\n",
      "Trainable params: 1,260,330\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.2880 - accuracy: 0.9113\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1101 - accuracy: 0.9662\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0736 - accuracy: 0.9787\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0526 - accuracy: 0.9844\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0463 - accuracy: 0.9868\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0392 - accuracy: 0.9897\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0366 - accuracy: 0.9904\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0356 - accuracy: 0.9913\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0312 - accuracy: 0.9919\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 13s 13ms/step - loss: 0.0332 - accuracy: 0.9923\n",
      "Model: \"sequential_143\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_143 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_35 (Conv2D)          (None, 22, 22, 16)        800       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  multiple                 0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_135 (Flatten)       (None, 1936)              0         \n",
      "                                                                 \n",
      " dense_321 (Dense)           (None, 512)               991744    \n",
      "                                                                 \n",
      " dropout_176 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_322 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_177 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_323 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,260,330\n",
      "Trainable params: 1,260,330\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "938/938 [==============================] - 13s 13ms/step - loss: 0.2874 - accuracy: 0.9100\n",
      "Epoch 2/25\n",
      "938/938 [==============================] - 13s 13ms/step - loss: 0.1119 - accuracy: 0.9665\n",
      "Epoch 3/25\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0751 - accuracy: 0.9774\n",
      "Epoch 4/25\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0554 - accuracy: 0.9841\n",
      "Epoch 5/25\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0452 - accuracy: 0.9867\n",
      "Epoch 6/25\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0390 - accuracy: 0.9891\n",
      "Epoch 7/25\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0367 - accuracy: 0.9898\n",
      "Epoch 8/25\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0336 - accuracy: 0.9914\n",
      "Epoch 9/25\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0344 - accuracy: 0.9919\n",
      "Epoch 10/25\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0351 - accuracy: 0.9922\n",
      "Epoch 11/25\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0286 - accuracy: 0.9929\n",
      "Epoch 12/25\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0274 - accuracy: 0.9942\n",
      "Epoch 13/25\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0292 - accuracy: 0.9935\n",
      "Epoch 14/25\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0286 - accuracy: 0.9937\n",
      "Epoch 15/25\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0306 - accuracy: 0.9943\n",
      "Epoch 16/25\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0299 - accuracy: 0.9939\n",
      "Epoch 17/25\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0289 - accuracy: 0.9944\n",
      "Epoch 18/25\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0265 - accuracy: 0.9943\n",
      "Epoch 19/25\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0319 - accuracy: 0.9947\n",
      "Epoch 20/25\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0298 - accuracy: 0.9948\n",
      "Epoch 21/25\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0303 - accuracy: 0.9948\n",
      "Epoch 22/25\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0350 - accuracy: 0.9941\n",
      "Epoch 23/25\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0366 - accuracy: 0.9942\n",
      "Epoch 24/25\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0373 - accuracy: 0.9940\n",
      "Epoch 25/25\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0350 - accuracy: 0.9948\n",
      "Model: \"sequential_144\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_144 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_36 (Conv2D)          (None, 22, 22, 16)        800       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  multiple                 0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_136 (Flatten)       (None, 1936)              0         \n",
      "                                                                 \n",
      " dense_324 (Dense)           (None, 512)               991744    \n",
      "                                                                 \n",
      " dropout_178 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_325 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_179 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_326 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,260,330\n",
      "Trainable params: 1,260,330\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.3169 - accuracy: 0.9013\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.1194 - accuracy: 0.9642\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0739 - accuracy: 0.9777\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0494 - accuracy: 0.9849\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0399 - accuracy: 0.9874\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0312 - accuracy: 0.9902\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0274 - accuracy: 0.9916\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0256 - accuracy: 0.9925\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.0214 - accuracy: 0.9933\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0187 - accuracy: 0.9945\n",
      "Model: \"sequential_145\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_145 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_37 (Conv2D)          (None, 22, 22, 16)        800       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  multiple                 0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_137 (Flatten)       (None, 1936)              0         \n",
      "                                                                 \n",
      " dense_327 (Dense)           (None, 512)               991744    \n",
      "                                                                 \n",
      " dropout_180 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_328 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_181 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_329 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,260,330\n",
      "Trainable params: 1,260,330\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "469/469 [==============================] - 11s 22ms/step - loss: 0.3220 - accuracy: 0.8996\n",
      "Epoch 2/25\n",
      "469/469 [==============================] - 11s 23ms/step - loss: 0.1198 - accuracy: 0.9650\n",
      "Epoch 3/25\n",
      "469/469 [==============================] - 11s 23ms/step - loss: 0.0744 - accuracy: 0.9773\n",
      "Epoch 4/25\n",
      "469/469 [==============================] - 11s 22ms/step - loss: 0.0514 - accuracy: 0.9840\n",
      "Epoch 5/25\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.0381 - accuracy: 0.9879\n",
      "Epoch 6/25\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.0303 - accuracy: 0.9906\n",
      "Epoch 7/25\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.0277 - accuracy: 0.9915\n",
      "Epoch 8/25\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0250 - accuracy: 0.9923\n",
      "Epoch 9/25\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.0211 - accuracy: 0.9937\n",
      "Epoch 10/25\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.0211 - accuracy: 0.9943\n",
      "Epoch 11/25\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.0191 - accuracy: 0.9944\n",
      "Epoch 12/25\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0177 - accuracy: 0.9953\n",
      "Epoch 13/25\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0182 - accuracy: 0.9950\n",
      "Epoch 14/25\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.0185 - accuracy: 0.9947\n",
      "Epoch 15/25\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.0157 - accuracy: 0.9957\n",
      "Epoch 16/25\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.0179 - accuracy: 0.9959\n",
      "Epoch 17/25\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.0179 - accuracy: 0.9956\n",
      "Epoch 18/25\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.0169 - accuracy: 0.9960\n",
      "Epoch 19/25\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.0150 - accuracy: 0.9962\n",
      "Epoch 20/25\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.0149 - accuracy: 0.9965\n",
      "Epoch 21/25\n",
      "469/469 [==============================] - 11s 22ms/step - loss: 0.0171 - accuracy: 0.9962\n",
      "Epoch 22/25\n",
      "469/469 [==============================] - 11s 23ms/step - loss: 0.0154 - accuracy: 0.9966\n",
      "Epoch 23/25\n",
      "469/469 [==============================] - 11s 23ms/step - loss: 0.0120 - accuracy: 0.9970\n",
      "Epoch 24/25\n",
      "469/469 [==============================] - 11s 23ms/step - loss: 0.0163 - accuracy: 0.9967\n",
      "Epoch 25/25\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.0158 - accuracy: 0.9970\n",
      "Model: \"sequential_146\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_146 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_38 (Conv2D)          (None, 22, 22, 16)        800       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  multiple                 0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_138 (Flatten)       (None, 1936)              0         \n",
      "                                                                 \n",
      " dense_330 (Dense)           (None, 512)               991744    \n",
      "                                                                 \n",
      " dropout_182 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_331 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_183 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_332 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,260,330\n",
      "Trainable params: 1,260,330\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.2678 - accuracy: 0.9183\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.0943 - accuracy: 0.9703\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.0591 - accuracy: 0.9811\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.0431 - accuracy: 0.9861\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.0368 - accuracy: 0.9880\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.0331 - accuracy: 0.9897\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.0302 - accuracy: 0.9902\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.0265 - accuracy: 0.9918\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.0243 - accuracy: 0.9925\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.0248 - accuracy: 0.9924\n",
      "Model: \"sequential_147\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_147 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_39 (Conv2D)          (None, 22, 22, 16)        800       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  multiple                 0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_139 (Flatten)       (None, 1936)              0         \n",
      "                                                                 \n",
      " dense_333 (Dense)           (None, 512)               991744    \n",
      "                                                                 \n",
      " dropout_184 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_334 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_185 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_335 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,260,330\n",
      "Trainable params: 1,260,330\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.2664 - accuracy: 0.9193\n",
      "Epoch 2/25\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0938 - accuracy: 0.9712\n",
      "Epoch 3/25\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0615 - accuracy: 0.9800\n",
      "Epoch 4/25\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0430 - accuracy: 0.9863\n",
      "Epoch 5/25\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0359 - accuracy: 0.9883\n",
      "Epoch 6/25\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0314 - accuracy: 0.9898\n",
      "Epoch 7/25\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.0314 - accuracy: 0.9896\n",
      "Epoch 8/25\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0247 - accuracy: 0.9922\n",
      "Epoch 9/25\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0274 - accuracy: 0.9913\n",
      "Epoch 10/25\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0255 - accuracy: 0.9922\n",
      "Epoch 11/25\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0218 - accuracy: 0.9929\n",
      "Epoch 12/25\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0182 - accuracy: 0.9945\n",
      "Epoch 13/25\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0252 - accuracy: 0.9930\n",
      "Epoch 14/25\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0212 - accuracy: 0.9942\n",
      "Epoch 15/25\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0234 - accuracy: 0.9934\n",
      "Epoch 16/25\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0185 - accuracy: 0.9947\n",
      "Epoch 17/25\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0170 - accuracy: 0.9952\n",
      "Epoch 18/25\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0227 - accuracy: 0.9938\n",
      "Epoch 19/25\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0217 - accuracy: 0.9941\n",
      "Epoch 20/25\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0154 - accuracy: 0.9959\n",
      "Epoch 21/25\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0202 - accuracy: 0.9950\n",
      "Epoch 22/25\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0191 - accuracy: 0.9948\n",
      "Epoch 23/25\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0207 - accuracy: 0.9950\n",
      "Epoch 24/25\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.0164 - accuracy: 0.9959\n",
      "Epoch 25/25\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0197 - accuracy: 0.9952\n",
      "Model: \"sequential_148\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_148 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_40 (Conv2D)          (None, 22, 22, 16)        800       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  multiple                 0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_140 (Flatten)       (None, 1936)              0         \n",
      "                                                                 \n",
      " dense_336 (Dense)           (None, 512)               991744    \n",
      "                                                                 \n",
      " dropout_186 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_337 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_187 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_338 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,260,330\n",
      "Trainable params: 1,260,330\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "469/469 [==============================] - 8s 16ms/step - loss: 0.2872 - accuracy: 0.9102\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 7s 16ms/step - loss: 0.0932 - accuracy: 0.9715\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 7s 16ms/step - loss: 0.0567 - accuracy: 0.9818\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.0365 - accuracy: 0.9883\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 7s 16ms/step - loss: 0.0257 - accuracy: 0.9914\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 7s 16ms/step - loss: 0.0239 - accuracy: 0.9923\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 7s 16ms/step - loss: 0.0228 - accuracy: 0.9925\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 7s 16ms/step - loss: 0.0234 - accuracy: 0.9925\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 7s 16ms/step - loss: 0.0156 - accuracy: 0.9948\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 7s 16ms/step - loss: 0.0180 - accuracy: 0.9941\n",
      "Model: \"sequential_149\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_149 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_41 (Conv2D)          (None, 22, 22, 16)        800       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  multiple                 0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_141 (Flatten)       (None, 1936)              0         \n",
      "                                                                 \n",
      " dense_339 (Dense)           (None, 512)               991744    \n",
      "                                                                 \n",
      " dropout_188 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_340 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_189 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_341 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,260,330\n",
      "Trainable params: 1,260,330\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "469/469 [==============================] - 8s 16ms/step - loss: 0.2758 - accuracy: 0.9153\n",
      "Epoch 2/25\n",
      "469/469 [==============================] - 8s 16ms/step - loss: 0.0911 - accuracy: 0.9725\n",
      "Epoch 3/25\n",
      "469/469 [==============================] - 9s 18ms/step - loss: 0.0530 - accuracy: 0.9835\n",
      "Epoch 4/25\n",
      "469/469 [==============================] - 8s 17ms/step - loss: 0.0324 - accuracy: 0.9895\n",
      "Epoch 5/25\n",
      "469/469 [==============================] - 7s 16ms/step - loss: 0.0274 - accuracy: 0.9907\n",
      "Epoch 6/25\n",
      "469/469 [==============================] - 8s 16ms/step - loss: 0.0220 - accuracy: 0.9927\n",
      "Epoch 7/25\n",
      "469/469 [==============================] - 8s 17ms/step - loss: 0.0231 - accuracy: 0.9922\n",
      "Epoch 8/25\n",
      "469/469 [==============================] - 8s 17ms/step - loss: 0.0187 - accuracy: 0.9942\n",
      "Epoch 9/25\n",
      "469/469 [==============================] - 8s 17ms/step - loss: 0.0188 - accuracy: 0.9937\n",
      "Epoch 10/25\n",
      "469/469 [==============================] - 8s 17ms/step - loss: 0.0138 - accuracy: 0.9955\n",
      "Epoch 11/25\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.0190 - accuracy: 0.9944\n",
      "Epoch 12/25\n",
      "469/469 [==============================] - 7s 16ms/step - loss: 0.0167 - accuracy: 0.9950\n",
      "Epoch 13/25\n",
      "469/469 [==============================] - 7s 16ms/step - loss: 0.0137 - accuracy: 0.9956\n",
      "Epoch 14/25\n",
      "469/469 [==============================] - 8s 16ms/step - loss: 0.0148 - accuracy: 0.9955\n",
      "Epoch 15/25\n",
      "469/469 [==============================] - 8s 16ms/step - loss: 0.0124 - accuracy: 0.9962\n",
      "Epoch 16/25\n",
      "469/469 [==============================] - 7s 16ms/step - loss: 0.0132 - accuracy: 0.9958\n",
      "Epoch 17/25\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.0150 - accuracy: 0.9957\n",
      "Epoch 18/25\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.0106 - accuracy: 0.9968\n",
      "Epoch 19/25\n",
      "469/469 [==============================] - 7s 16ms/step - loss: 0.0119 - accuracy: 0.9965\n",
      "Epoch 20/25\n",
      "469/469 [==============================] - 7s 16ms/step - loss: 0.0155 - accuracy: 0.9957\n",
      "Epoch 21/25\n",
      "469/469 [==============================] - 7s 16ms/step - loss: 0.0084 - accuracy: 0.9974\n",
      "Epoch 22/25\n",
      "469/469 [==============================] - 7s 16ms/step - loss: 0.0141 - accuracy: 0.9962\n",
      "Epoch 23/25\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.0122 - accuracy: 0.9965\n",
      "Epoch 24/25\n",
      "469/469 [==============================] - 7s 16ms/step - loss: 0.0127 - accuracy: 0.9961\n",
      "Epoch 25/25\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.0098 - accuracy: 0.9973\n",
      "Model: \"sequential_150\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_150 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_42 (Conv2D)          (None, 22, 22, 16)        800       \n",
      "                                                                 \n",
      " global_max_pooling2d (Globa  (None, 16)               0         \n",
      " lMaxPooling2D)                                                  \n",
      "                                                                 \n",
      " dense_342 (Dense)           (None, 512)               8704      \n",
      "                                                                 \n",
      " dropout_190 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_343 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_191 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_344 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 277,290\n",
      "Trainable params: 277,290\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 1.3035 - accuracy: 0.5539\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.8771 - accuracy: 0.7090\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.7552 - accuracy: 0.7524\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 7s 8ms/step - loss: 0.6862 - accuracy: 0.7765\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.6391 - accuracy: 0.7915\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.6069 - accuracy: 0.8034\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.5861 - accuracy: 0.8107\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.5694 - accuracy: 0.8147\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.5599 - accuracy: 0.8221\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.5493 - accuracy: 0.8238\n",
      "Model: \"sequential_151\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_151 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_43 (Conv2D)          (None, 22, 22, 16)        800       \n",
      "                                                                 \n",
      " global_max_pooling2d (Globa  (None, 16)               0         \n",
      " lMaxPooling2D)                                                  \n",
      "                                                                 \n",
      " dense_345 (Dense)           (None, 512)               8704      \n",
      "                                                                 \n",
      " dropout_192 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_346 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_193 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_347 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 277,290\n",
      "Trainable params: 277,290\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 1.2124 - accuracy: 0.5928\n",
      "Epoch 2/25\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.8223 - accuracy: 0.7260\n",
      "Epoch 3/25\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.7282 - accuracy: 0.7586\n",
      "Epoch 4/25\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.6791 - accuracy: 0.7768\n",
      "Epoch 5/25\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.6468 - accuracy: 0.7890\n",
      "Epoch 6/25\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.6231 - accuracy: 0.7968\n",
      "Epoch 7/25\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.6046 - accuracy: 0.8044\n",
      "Epoch 8/25\n",
      "938/938 [==============================] - 7s 8ms/step - loss: 0.5936 - accuracy: 0.8068\n",
      "Epoch 9/25\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.5780 - accuracy: 0.8140\n",
      "Epoch 10/25\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.5709 - accuracy: 0.8162\n",
      "Epoch 11/25\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.5599 - accuracy: 0.8199\n",
      "Epoch 12/25\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.5564 - accuracy: 0.8209\n",
      "Epoch 13/25\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.5513 - accuracy: 0.8232\n",
      "Epoch 14/25\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.5459 - accuracy: 0.8269\n",
      "Epoch 15/25\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.5406 - accuracy: 0.8273\n",
      "Epoch 16/25\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.5403 - accuracy: 0.8254\n",
      "Epoch 17/25\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.5381 - accuracy: 0.8293\n",
      "Epoch 18/25\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.5326 - accuracy: 0.8311\n",
      "Epoch 19/25\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.5358 - accuracy: 0.8311\n",
      "Epoch 20/25\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.5336 - accuracy: 0.8317\n",
      "Epoch 21/25\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.5298 - accuracy: 0.8332\n",
      "Epoch 22/25\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.5287 - accuracy: 0.8343\n",
      "Epoch 23/25\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.5294 - accuracy: 0.8338\n",
      "Epoch 24/25\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.5303 - accuracy: 0.8326\n",
      "Epoch 25/25\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.5311 - accuracy: 0.8350\n",
      "Model: \"sequential_152\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_152 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_44 (Conv2D)          (None, 22, 22, 16)        800       \n",
      "                                                                 \n",
      " global_max_pooling2d (Globa  (None, 16)               0         \n",
      " lMaxPooling2D)                                                  \n",
      "                                                                 \n",
      " dense_348 (Dense)           (None, 512)               8704      \n",
      "                                                                 \n",
      " dropout_194 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_349 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_195 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_350 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 277,290\n",
      "Trainable params: 277,290\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 1.3523 - accuracy: 0.5425\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 5s 12ms/step - loss: 0.9526 - accuracy: 0.6844\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 5s 12ms/step - loss: 0.8351 - accuracy: 0.7232\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 5s 12ms/step - loss: 0.7608 - accuracy: 0.7486\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 5s 12ms/step - loss: 0.7040 - accuracy: 0.7669\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 5s 12ms/step - loss: 0.6633 - accuracy: 0.7812\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 5s 12ms/step - loss: 0.6324 - accuracy: 0.7911\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 5s 12ms/step - loss: 0.6070 - accuracy: 0.7990\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 5s 12ms/step - loss: 0.5883 - accuracy: 0.8068\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 5s 12ms/step - loss: 0.5689 - accuracy: 0.8133\n",
      "Model: \"sequential_153\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_153 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_45 (Conv2D)          (None, 22, 22, 16)        800       \n",
      "                                                                 \n",
      " global_max_pooling2d (Globa  (None, 16)               0         \n",
      " lMaxPooling2D)                                                  \n",
      "                                                                 \n",
      " dense_351 (Dense)           (None, 512)               8704      \n",
      "                                                                 \n",
      " dropout_196 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_352 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_197 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_353 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 277,290\n",
      "Trainable params: 277,290\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "469/469 [==============================] - 8s 15ms/step - loss: 1.4554 - accuracy: 0.5079\n",
      "Epoch 2/25\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 1.0076 - accuracy: 0.6684\n",
      "Epoch 3/25\n",
      "469/469 [==============================] - 7s 16ms/step - loss: 0.8627 - accuracy: 0.7174\n",
      "Epoch 4/25\n",
      "469/469 [==============================] - 7s 16ms/step - loss: 0.7744 - accuracy: 0.7462\n",
      "Epoch 5/25\n",
      "469/469 [==============================] - 7s 16ms/step - loss: 0.7153 - accuracy: 0.7653\n",
      "Epoch 6/25\n",
      "469/469 [==============================] - 7s 16ms/step - loss: 0.6758 - accuracy: 0.7786\n",
      "Epoch 7/25\n",
      "469/469 [==============================] - 7s 16ms/step - loss: 0.6420 - accuracy: 0.7908\n",
      "Epoch 8/25\n",
      "469/469 [==============================] - 7s 16ms/step - loss: 0.6136 - accuracy: 0.7993\n",
      "Epoch 9/25\n",
      "469/469 [==============================] - 7s 16ms/step - loss: 0.5926 - accuracy: 0.8079\n",
      "Epoch 10/25\n",
      "469/469 [==============================] - 7s 16ms/step - loss: 0.5728 - accuracy: 0.8131\n",
      "Epoch 11/25\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.5560 - accuracy: 0.8204\n",
      "Epoch 12/25\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.5424 - accuracy: 0.8231\n",
      "Epoch 13/25\n",
      "469/469 [==============================] - 7s 16ms/step - loss: 0.5283 - accuracy: 0.8282\n",
      "Epoch 14/25\n",
      "469/469 [==============================] - 7s 16ms/step - loss: 0.5211 - accuracy: 0.8322\n",
      "Epoch 15/25\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.5103 - accuracy: 0.8348\n",
      "Epoch 16/25\n",
      "469/469 [==============================] - 7s 16ms/step - loss: 0.4993 - accuracy: 0.8391\n",
      "Epoch 17/25\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.4916 - accuracy: 0.8406\n",
      "Epoch 18/25\n",
      "469/469 [==============================] - 7s 16ms/step - loss: 0.4810 - accuracy: 0.8453\n",
      "Epoch 19/25\n",
      "469/469 [==============================] - 7s 16ms/step - loss: 0.4749 - accuracy: 0.8479\n",
      "Epoch 20/25\n",
      "469/469 [==============================] - 7s 16ms/step - loss: 0.4659 - accuracy: 0.8497\n",
      "Epoch 21/25\n",
      "469/469 [==============================] - 7s 16ms/step - loss: 0.4638 - accuracy: 0.8495\n",
      "Epoch 22/25\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.4570 - accuracy: 0.8528\n",
      "Epoch 23/25\n",
      "469/469 [==============================] - 7s 16ms/step - loss: 0.4529 - accuracy: 0.8545\n",
      "Epoch 24/25\n",
      "469/469 [==============================] - 7s 16ms/step - loss: 0.4468 - accuracy: 0.8563\n",
      "Epoch 25/25\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.4453 - accuracy: 0.8558\n",
      "Model: \"sequential_154\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_154 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_46 (Conv2D)          (None, 22, 22, 16)        800       \n",
      "                                                                 \n",
      " global_max_pooling2d (Globa  (None, 16)               0         \n",
      " lMaxPooling2D)                                                  \n",
      "                                                                 \n",
      " dense_354 (Dense)           (None, 512)               8704      \n",
      "                                                                 \n",
      " dropout_198 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_355 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_199 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_356 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 277,290\n",
      "Trainable params: 277,290\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 9s 9ms/step - loss: 1.1110 - accuracy: 0.6189\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 9s 9ms/step - loss: 0.8203 - accuracy: 0.7277\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 9s 9ms/step - loss: 0.7361 - accuracy: 0.7565\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 9s 9ms/step - loss: 0.6936 - accuracy: 0.7715\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 9s 9ms/step - loss: 0.6572 - accuracy: 0.7836\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 9s 9ms/step - loss: 0.6282 - accuracy: 0.7919\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 9s 9ms/step - loss: 0.6111 - accuracy: 0.7994\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 9s 9ms/step - loss: 0.5915 - accuracy: 0.8051\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 9s 9ms/step - loss: 0.5720 - accuracy: 0.8124\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 9s 9ms/step - loss: 0.5572 - accuracy: 0.8156\n",
      "Model: \"sequential_155\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_155 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_47 (Conv2D)          (None, 22, 22, 16)        800       \n",
      "                                                                 \n",
      " global_max_pooling2d (Globa  (None, 16)               0         \n",
      " lMaxPooling2D)                                                  \n",
      "                                                                 \n",
      " dense_357 (Dense)           (None, 512)               8704      \n",
      "                                                                 \n",
      " dropout_200 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_358 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_201 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_359 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 277,290\n",
      "Trainable params: 277,290\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "938/938 [==============================] - 9s 9ms/step - loss: 1.1473 - accuracy: 0.6148\n",
      "Epoch 2/25\n",
      "938/938 [==============================] - 8s 9ms/step - loss: 0.8256 - accuracy: 0.7305\n",
      "Epoch 3/25\n",
      "938/938 [==============================] - 9s 9ms/step - loss: 0.7473 - accuracy: 0.7564\n",
      "Epoch 4/25\n",
      "938/938 [==============================] - 8s 9ms/step - loss: 0.7005 - accuracy: 0.7705\n",
      "Epoch 5/25\n",
      "938/938 [==============================] - 8s 9ms/step - loss: 0.6668 - accuracy: 0.7812\n",
      "Epoch 6/25\n",
      "938/938 [==============================] - 8s 9ms/step - loss: 0.6399 - accuracy: 0.7897\n",
      "Epoch 7/25\n",
      "938/938 [==============================] - 8s 9ms/step - loss: 0.6183 - accuracy: 0.7980\n",
      "Epoch 8/25\n",
      "938/938 [==============================] - 8s 9ms/step - loss: 0.5999 - accuracy: 0.8041\n",
      "Epoch 9/25\n",
      "938/938 [==============================] - 8s 9ms/step - loss: 0.5838 - accuracy: 0.8084\n",
      "Epoch 10/25\n",
      "938/938 [==============================] - 8s 9ms/step - loss: 0.5727 - accuracy: 0.8120\n",
      "Epoch 11/25\n",
      "938/938 [==============================] - 8s 9ms/step - loss: 0.5586 - accuracy: 0.8151\n",
      "Epoch 12/25\n",
      "938/938 [==============================] - 8s 9ms/step - loss: 0.5484 - accuracy: 0.8204\n",
      "Epoch 13/25\n",
      "938/938 [==============================] - 8s 9ms/step - loss: 0.5394 - accuracy: 0.8239\n",
      "Epoch 14/25\n",
      "938/938 [==============================] - 8s 9ms/step - loss: 0.5287 - accuracy: 0.8258\n",
      "Epoch 15/25\n",
      "938/938 [==============================] - 8s 9ms/step - loss: 0.5221 - accuracy: 0.8276\n",
      "Epoch 16/25\n",
      "938/938 [==============================] - 8s 9ms/step - loss: 0.5118 - accuracy: 0.8315\n",
      "Epoch 17/25\n",
      "938/938 [==============================] - 8s 9ms/step - loss: 0.5044 - accuracy: 0.8351\n",
      "Epoch 18/25\n",
      "938/938 [==============================] - 8s 9ms/step - loss: 0.4988 - accuracy: 0.8363\n",
      "Epoch 19/25\n",
      "938/938 [==============================] - 8s 9ms/step - loss: 0.4908 - accuracy: 0.8373\n",
      "Epoch 20/25\n",
      "938/938 [==============================] - 8s 9ms/step - loss: 0.4845 - accuracy: 0.8406\n",
      "Epoch 21/25\n",
      "938/938 [==============================] - 8s 9ms/step - loss: 0.4761 - accuracy: 0.8419\n",
      "Epoch 22/25\n",
      "938/938 [==============================] - 8s 9ms/step - loss: 0.4700 - accuracy: 0.8457\n",
      "Epoch 23/25\n",
      "938/938 [==============================] - 8s 9ms/step - loss: 0.4645 - accuracy: 0.8460\n",
      "Epoch 24/25\n",
      "938/938 [==============================] - 8s 9ms/step - loss: 0.4555 - accuracy: 0.8493\n",
      "Epoch 25/25\n",
      "938/938 [==============================] - 8s 9ms/step - loss: 0.4474 - accuracy: 0.8508\n",
      "Model: \"sequential_156\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_156 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_48 (Conv2D)          (None, 22, 22, 16)        800       \n",
      "                                                                 \n",
      " global_max_pooling2d (Globa  (None, 16)               0         \n",
      " lMaxPooling2D)                                                  \n",
      "                                                                 \n",
      " dense_360 (Dense)           (None, 512)               8704      \n",
      "                                                                 \n",
      " dropout_202 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_361 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_203 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_362 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 277,290\n",
      "Trainable params: 277,290\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "469/469 [==============================] - 7s 14ms/step - loss: 1.1066 - accuracy: 0.6215\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 7s 14ms/step - loss: 0.7713 - accuracy: 0.7436\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 7s 14ms/step - loss: 0.6923 - accuracy: 0.7720\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 7s 14ms/step - loss: 0.6425 - accuracy: 0.7900\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 7s 14ms/step - loss: 0.6138 - accuracy: 0.7992\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 7s 14ms/step - loss: 0.5907 - accuracy: 0.8063\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 7s 14ms/step - loss: 0.5695 - accuracy: 0.8132\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 7s 14ms/step - loss: 0.5556 - accuracy: 0.8179\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 7s 14ms/step - loss: 0.5398 - accuracy: 0.8233\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 7s 14ms/step - loss: 0.5290 - accuracy: 0.8269\n",
      "Model: \"sequential_157\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_157 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_49 (Conv2D)          (None, 22, 22, 16)        800       \n",
      "                                                                 \n",
      " global_max_pooling2d (Globa  (None, 16)               0         \n",
      " lMaxPooling2D)                                                  \n",
      "                                                                 \n",
      " dense_363 (Dense)           (None, 512)               8704      \n",
      "                                                                 \n",
      " dropout_204 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_364 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_205 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_365 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 277,290\n",
      "Trainable params: 277,290\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "469/469 [==============================] - 7s 14ms/step - loss: 1.1553 - accuracy: 0.5967\n",
      "Epoch 2/25\n",
      "469/469 [==============================] - 7s 14ms/step - loss: 0.8351 - accuracy: 0.7203\n",
      "Epoch 3/25\n",
      "469/469 [==============================] - 7s 14ms/step - loss: 0.7469 - accuracy: 0.7509\n",
      "Epoch 4/25\n",
      "469/469 [==============================] - 7s 14ms/step - loss: 0.6978 - accuracy: 0.7673\n",
      "Epoch 5/25\n",
      "469/469 [==============================] - 7s 14ms/step - loss: 0.6577 - accuracy: 0.7828\n",
      "Epoch 6/25\n",
      "469/469 [==============================] - 7s 14ms/step - loss: 0.6330 - accuracy: 0.7899\n",
      "Epoch 7/25\n",
      "469/469 [==============================] - 7s 14ms/step - loss: 0.6122 - accuracy: 0.7983\n",
      "Epoch 8/25\n",
      "469/469 [==============================] - 7s 14ms/step - loss: 0.6007 - accuracy: 0.8028\n",
      "Epoch 9/25\n",
      "469/469 [==============================] - 7s 14ms/step - loss: 0.5803 - accuracy: 0.8084\n",
      "Epoch 10/25\n",
      "469/469 [==============================] - 7s 14ms/step - loss: 0.5674 - accuracy: 0.8134\n",
      "Epoch 11/25\n",
      "469/469 [==============================] - 7s 14ms/step - loss: 0.5552 - accuracy: 0.8194\n",
      "Epoch 12/25\n",
      "469/469 [==============================] - 7s 14ms/step - loss: 0.5475 - accuracy: 0.8208\n",
      "Epoch 13/25\n",
      "469/469 [==============================] - 7s 14ms/step - loss: 0.5386 - accuracy: 0.8236\n",
      "Epoch 14/25\n",
      "469/469 [==============================] - 7s 14ms/step - loss: 0.5293 - accuracy: 0.8279\n",
      "Epoch 15/25\n",
      "469/469 [==============================] - 7s 14ms/step - loss: 0.5172 - accuracy: 0.8304\n",
      "Epoch 16/25\n",
      "469/469 [==============================] - 7s 14ms/step - loss: 0.5145 - accuracy: 0.8306\n",
      "Epoch 17/25\n",
      "469/469 [==============================] - 7s 14ms/step - loss: 0.5072 - accuracy: 0.8344\n",
      "Epoch 18/25\n",
      "469/469 [==============================] - 7s 14ms/step - loss: 0.5013 - accuracy: 0.8345\n",
      "Epoch 19/25\n",
      "469/469 [==============================] - 7s 14ms/step - loss: 0.4959 - accuracy: 0.8363\n",
      "Epoch 20/25\n",
      "469/469 [==============================] - 7s 14ms/step - loss: 0.4864 - accuracy: 0.8401\n",
      "Epoch 21/25\n",
      "469/469 [==============================] - 7s 14ms/step - loss: 0.4850 - accuracy: 0.8406\n",
      "Epoch 22/25\n",
      "469/469 [==============================] - 7s 14ms/step - loss: 0.4812 - accuracy: 0.8423\n",
      "Epoch 23/25\n",
      "469/469 [==============================] - 7s 14ms/step - loss: 0.4766 - accuracy: 0.8426\n",
      "Epoch 24/25\n",
      "469/469 [==============================] - 7s 14ms/step - loss: 0.4699 - accuracy: 0.8457\n",
      "Epoch 25/25\n",
      "469/469 [==============================] - 7s 14ms/step - loss: 0.4650 - accuracy: 0.8463\n",
      "Model: \"sequential_158\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_158 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_50 (Conv2D)          (None, 24, 24, 32)        832       \n",
      "                                                                 \n",
      " conv2d_51 (Conv2D)          (None, 20, 20, 64)        51264     \n",
      "                                                                 \n",
      " flatten_142 (Flatten)       (None, 25600)             0         \n",
      "                                                                 \n",
      " dense_366 (Dense)           (None, 512)               13107712  \n",
      "                                                                 \n",
      " dropout_206 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_367 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_207 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_368 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,427,594\n",
      "Trainable params: 13,427,594\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 137s 146ms/step - loss: 0.4168 - accuracy: 0.8780\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 137s 146ms/step - loss: 0.2209 - accuracy: 0.9364\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 138s 147ms/step - loss: 0.1823 - accuracy: 0.9482\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 137s 146ms/step - loss: 0.1712 - accuracy: 0.9543\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 136s 145ms/step - loss: 0.1720 - accuracy: 0.9571\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 136s 145ms/step - loss: 0.1716 - accuracy: 0.9602\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 135s 144ms/step - loss: 0.1859 - accuracy: 0.9577\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 128s 137ms/step - loss: 0.1847 - accuracy: 0.9616\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 128s 137ms/step - loss: 0.1901 - accuracy: 0.9589\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 130s 138ms/step - loss: 0.2038 - accuracy: 0.9585\n",
      "Model: \"sequential_159\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_159 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_52 (Conv2D)          (None, 24, 24, 32)        832       \n",
      "                                                                 \n",
      " conv2d_53 (Conv2D)          (None, 20, 20, 64)        51264     \n",
      "                                                                 \n",
      " flatten_143 (Flatten)       (None, 25600)             0         \n",
      "                                                                 \n",
      " dense_369 (Dense)           (None, 512)               13107712  \n",
      "                                                                 \n",
      " dropout_208 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_370 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_209 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_371 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,427,594\n",
      "Trainable params: 13,427,594\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "938/938 [==============================] - 127s 135ms/step - loss: 0.3905 - accuracy: 0.8836\n",
      "Epoch 2/25\n",
      "938/938 [==============================] - 126s 135ms/step - loss: 0.2169 - accuracy: 0.9367\n",
      "Epoch 3/25\n",
      "938/938 [==============================] - 126s 135ms/step - loss: 0.1775 - accuracy: 0.9496\n",
      "Epoch 4/25\n",
      "938/938 [==============================] - 126s 135ms/step - loss: 0.1619 - accuracy: 0.9568\n",
      "Epoch 5/25\n",
      "938/938 [==============================] - 126s 135ms/step - loss: 0.1597 - accuracy: 0.9590\n",
      "Epoch 6/25\n",
      "938/938 [==============================] - 126s 135ms/step - loss: 0.1624 - accuracy: 0.9613\n",
      "Epoch 7/25\n",
      "938/938 [==============================] - 126s 135ms/step - loss: 0.1760 - accuracy: 0.9598\n",
      "Epoch 8/25\n",
      "938/938 [==============================] - 126s 135ms/step - loss: 0.1879 - accuracy: 0.9598\n",
      "Epoch 9/25\n",
      "938/938 [==============================] - 126s 135ms/step - loss: 0.1911 - accuracy: 0.9600\n",
      "Epoch 10/25\n",
      "938/938 [==============================] - 126s 135ms/step - loss: 0.1958 - accuracy: 0.9616\n",
      "Epoch 11/25\n",
      "938/938 [==============================] - 126s 135ms/step - loss: 0.2038 - accuracy: 0.9608\n",
      "Epoch 12/25\n",
      "938/938 [==============================] - 126s 135ms/step - loss: 0.2209 - accuracy: 0.9592\n",
      "Epoch 13/25\n",
      "938/938 [==============================] - 126s 135ms/step - loss: 0.2131 - accuracy: 0.9606\n",
      "Epoch 14/25\n",
      "938/938 [==============================] - 126s 135ms/step - loss: 0.2307 - accuracy: 0.9600\n",
      "Epoch 15/25\n",
      "938/938 [==============================] - 126s 135ms/step - loss: 0.2310 - accuracy: 0.9589\n",
      "Epoch 16/25\n",
      "938/938 [==============================] - 126s 135ms/step - loss: 0.2271 - accuracy: 0.9603\n",
      "Epoch 17/25\n",
      "938/938 [==============================] - 126s 135ms/step - loss: 0.2320 - accuracy: 0.9611\n",
      "Epoch 18/25\n",
      "938/938 [==============================] - 126s 135ms/step - loss: 0.2317 - accuracy: 0.9623\n",
      "Epoch 19/25\n",
      "938/938 [==============================] - 126s 135ms/step - loss: 0.2329 - accuracy: 0.9625\n",
      "Epoch 20/25\n",
      "938/938 [==============================] - 127s 135ms/step - loss: 0.2446 - accuracy: 0.9627\n",
      "Epoch 21/25\n",
      "938/938 [==============================] - 127s 135ms/step - loss: 0.2631 - accuracy: 0.9586\n",
      "Epoch 22/25\n",
      "938/938 [==============================] - 127s 135ms/step - loss: 0.2598 - accuracy: 0.9594\n",
      "Epoch 23/25\n",
      "938/938 [==============================] - 127s 135ms/step - loss: 0.2683 - accuracy: 0.9592\n",
      "Epoch 24/25\n",
      "938/938 [==============================] - 127s 135ms/step - loss: 0.2856 - accuracy: 0.9575\n",
      "Epoch 25/25\n",
      "938/938 [==============================] - 127s 135ms/step - loss: 0.2687 - accuracy: 0.9600\n",
      "Model: \"sequential_160\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_160 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_54 (Conv2D)          (None, 24, 24, 32)        832       \n",
      "                                                                 \n",
      " conv2d_55 (Conv2D)          (None, 20, 20, 64)        51264     \n",
      "                                                                 \n",
      " flatten_144 (Flatten)       (None, 25600)             0         \n",
      "                                                                 \n",
      " dense_372 (Dense)           (None, 512)               13107712  \n",
      "                                                                 \n",
      " dropout_210 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_373 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_211 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_374 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,427,594\n",
      "Trainable params: 13,427,594\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "469/469 [==============================] - 93s 198ms/step - loss: 0.4756 - accuracy: 0.8700\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 93s 198ms/step - loss: 0.1930 - accuracy: 0.9424\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 94s 199ms/step - loss: 0.1389 - accuracy: 0.9584\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 93s 199ms/step - loss: 0.1081 - accuracy: 0.9675\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 93s 199ms/step - loss: 0.0880 - accuracy: 0.9737\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 93s 199ms/step - loss: 0.0789 - accuracy: 0.9768\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 93s 199ms/step - loss: 0.0739 - accuracy: 0.9790\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 93s 199ms/step - loss: 0.0673 - accuracy: 0.9817\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 93s 199ms/step - loss: 0.0657 - accuracy: 0.9826\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 93s 199ms/step - loss: 0.0635 - accuracy: 0.9836\n",
      "Model: \"sequential_161\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_161 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_56 (Conv2D)          (None, 24, 24, 32)        832       \n",
      "                                                                 \n",
      " conv2d_57 (Conv2D)          (None, 20, 20, 64)        51264     \n",
      "                                                                 \n",
      " flatten_145 (Flatten)       (None, 25600)             0         \n",
      "                                                                 \n",
      " dense_375 (Dense)           (None, 512)               13107712  \n",
      "                                                                 \n",
      " dropout_212 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_376 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_213 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_377 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,427,594\n",
      "Trainable params: 13,427,594\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "469/469 [==============================] - 92s 196ms/step - loss: 0.4452 - accuracy: 0.8726\n",
      "Epoch 2/25\n",
      "469/469 [==============================] - 92s 196ms/step - loss: 0.1922 - accuracy: 0.9424\n",
      "Epoch 3/25\n",
      "469/469 [==============================] - 92s 196ms/step - loss: 0.1394 - accuracy: 0.9584\n",
      "Epoch 4/25\n",
      "469/469 [==============================] - 92s 196ms/step - loss: 0.1066 - accuracy: 0.9681\n",
      "Epoch 5/25\n",
      "469/469 [==============================] - 92s 196ms/step - loss: 0.0921 - accuracy: 0.9730\n",
      "Epoch 6/25\n",
      "469/469 [==============================] - 92s 196ms/step - loss: 0.0767 - accuracy: 0.9769\n",
      "Epoch 7/25\n",
      "469/469 [==============================] - 92s 196ms/step - loss: 0.0701 - accuracy: 0.9800\n",
      "Epoch 8/25\n",
      "469/469 [==============================] - 92s 196ms/step - loss: 0.0696 - accuracy: 0.9807\n",
      "Epoch 9/25\n",
      "469/469 [==============================] - 92s 196ms/step - loss: 0.0670 - accuracy: 0.9829\n",
      "Epoch 10/25\n",
      "469/469 [==============================] - 93s 199ms/step - loss: 0.0652 - accuracy: 0.9829\n",
      "Epoch 11/25\n",
      "469/469 [==============================] - 93s 198ms/step - loss: 0.0672 - accuracy: 0.9833\n",
      "Epoch 12/25\n",
      "469/469 [==============================] - 92s 197ms/step - loss: 0.0650 - accuracy: 0.9840\n",
      "Epoch 13/25\n",
      "469/469 [==============================] - 92s 197ms/step - loss: 0.0678 - accuracy: 0.9839\n",
      "Epoch 14/25\n",
      "469/469 [==============================] - 93s 197ms/step - loss: 0.0711 - accuracy: 0.9837\n",
      "Epoch 15/25\n",
      "469/469 [==============================] - 92s 197ms/step - loss: 0.0717 - accuracy: 0.9851\n",
      "Epoch 16/25\n",
      "469/469 [==============================] - 92s 197ms/step - loss: 0.0715 - accuracy: 0.9850\n",
      "Epoch 17/25\n",
      "469/469 [==============================] - 92s 197ms/step - loss: 0.0751 - accuracy: 0.9850\n",
      "Epoch 18/25\n",
      "469/469 [==============================] - 92s 197ms/step - loss: 0.0739 - accuracy: 0.9854\n",
      "Epoch 19/25\n",
      "469/469 [==============================] - 92s 197ms/step - loss: 0.0768 - accuracy: 0.9848\n",
      "Epoch 20/25\n",
      "469/469 [==============================] - 93s 198ms/step - loss: 0.0767 - accuracy: 0.9852\n",
      "Epoch 21/25\n",
      "469/469 [==============================] - 92s 197ms/step - loss: 0.0744 - accuracy: 0.9848\n",
      "Epoch 22/25\n",
      "469/469 [==============================] - 93s 197ms/step - loss: 0.0858 - accuracy: 0.9843\n",
      "Epoch 23/25\n",
      "469/469 [==============================] - 92s 197ms/step - loss: 0.0832 - accuracy: 0.9848\n",
      "Epoch 24/25\n",
      "469/469 [==============================] - 92s 197ms/step - loss: 0.0822 - accuracy: 0.9853\n",
      "Epoch 25/25\n",
      "469/469 [==============================] - 92s 197ms/step - loss: 0.0894 - accuracy: 0.9841\n",
      "Model: \"sequential_162\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_162 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_58 (Conv2D)          (None, 24, 24, 32)        832       \n",
      "                                                                 \n",
      " conv2d_59 (Conv2D)          (None, 20, 20, 64)        51264     \n",
      "                                                                 \n",
      " flatten_146 (Flatten)       (None, 25600)             0         \n",
      "                                                                 \n",
      " dense_378 (Dense)           (None, 512)               13107712  \n",
      "                                                                 \n",
      " dropout_214 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_379 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_215 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_380 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,427,594\n",
      "Trainable params: 13,427,594\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 97s 103ms/step - loss: 1.4807 - accuracy: 0.5553\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 97s 104ms/step - loss: 0.4794 - accuracy: 0.8490\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 98s 104ms/step - loss: 0.3630 - accuracy: 0.8882\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 98s 104ms/step - loss: 0.2998 - accuracy: 0.9076\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 97s 104ms/step - loss: 0.2612 - accuracy: 0.9190\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 97s 104ms/step - loss: 0.2318 - accuracy: 0.9277\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 98s 104ms/step - loss: 0.2121 - accuracy: 0.9350\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 98s 104ms/step - loss: 0.1981 - accuracy: 0.9398\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 97s 104ms/step - loss: 0.1855 - accuracy: 0.9423\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 97s 104ms/step - loss: 0.1776 - accuracy: 0.9451\n",
      "Model: \"sequential_163\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_163 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_60 (Conv2D)          (None, 24, 24, 32)        832       \n",
      "                                                                 \n",
      " conv2d_61 (Conv2D)          (None, 20, 20, 64)        51264     \n",
      "                                                                 \n",
      " flatten_147 (Flatten)       (None, 25600)             0         \n",
      "                                                                 \n",
      " dense_381 (Dense)           (None, 512)               13107712  \n",
      "                                                                 \n",
      " dropout_216 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_382 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_217 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_383 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,427,594\n",
      "Trainable params: 13,427,594\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "938/938 [==============================] - 97s 103ms/step - loss: 0.8179 - accuracy: 0.8053\n",
      "Epoch 2/25\n",
      "938/938 [==============================] - 97s 104ms/step - loss: 0.3205 - accuracy: 0.9012\n",
      "Epoch 3/25\n",
      "938/938 [==============================] - 98s 104ms/step - loss: 0.2640 - accuracy: 0.9186\n",
      "Epoch 4/25\n",
      "938/938 [==============================] - 98s 104ms/step - loss: 0.2266 - accuracy: 0.9302\n",
      "Epoch 5/25\n",
      "938/938 [==============================] - 98s 104ms/step - loss: 0.1911 - accuracy: 0.9405\n",
      "Epoch 6/25\n",
      "938/938 [==============================] - 98s 104ms/step - loss: 0.1760 - accuracy: 0.9455\n",
      "Epoch 7/25\n",
      "938/938 [==============================] - 98s 104ms/step - loss: 0.1616 - accuracy: 0.9509\n",
      "Epoch 8/25\n",
      "938/938 [==============================] - 100s 106ms/step - loss: 0.1498 - accuracy: 0.9536\n",
      "Epoch 9/25\n",
      "938/938 [==============================] - 104s 111ms/step - loss: 0.1396 - accuracy: 0.9580\n",
      "Epoch 10/25\n",
      "938/938 [==============================] - 104s 111ms/step - loss: 0.1404 - accuracy: 0.9573\n",
      "Epoch 11/25\n",
      "938/938 [==============================] - 104s 111ms/step - loss: 0.1321 - accuracy: 0.9600\n",
      "Epoch 12/25\n",
      "938/938 [==============================] - 103s 110ms/step - loss: 0.1265 - accuracy: 0.9631\n",
      "Epoch 13/25\n",
      "938/938 [==============================] - 103s 109ms/step - loss: 0.1203 - accuracy: 0.9647\n",
      "Epoch 14/25\n",
      "938/938 [==============================] - 103s 110ms/step - loss: 0.1198 - accuracy: 0.9657\n",
      "Epoch 15/25\n",
      "938/938 [==============================] - 103s 110ms/step - loss: 0.1151 - accuracy: 0.9674\n",
      "Epoch 16/25\n",
      "938/938 [==============================] - 103s 110ms/step - loss: 0.1075 - accuracy: 0.9690\n",
      "Epoch 17/25\n",
      "938/938 [==============================] - 103s 110ms/step - loss: 0.1128 - accuracy: 0.9690\n",
      "Epoch 18/25\n",
      "938/938 [==============================] - 104s 111ms/step - loss: 0.1137 - accuracy: 0.9684\n",
      "Epoch 19/25\n",
      "938/938 [==============================] - 104s 111ms/step - loss: 0.1042 - accuracy: 0.9722\n",
      "Epoch 20/25\n",
      "938/938 [==============================] - 104s 111ms/step - loss: 0.1081 - accuracy: 0.9716\n",
      "Epoch 21/25\n",
      "938/938 [==============================] - 105s 111ms/step - loss: 0.0971 - accuracy: 0.9738\n",
      "Epoch 22/25\n",
      "938/938 [==============================] - 104s 111ms/step - loss: 0.1081 - accuracy: 0.9711\n",
      "Epoch 23/25\n",
      "938/938 [==============================] - 104s 111ms/step - loss: 0.1162 - accuracy: 0.9709\n",
      "Epoch 24/25\n",
      "938/938 [==============================] - 105s 112ms/step - loss: 0.0904 - accuracy: 0.9759\n",
      "Epoch 25/25\n",
      "938/938 [==============================] - 104s 111ms/step - loss: 0.1073 - accuracy: 0.9726\n",
      "Model: \"sequential_164\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_164 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_62 (Conv2D)          (None, 24, 24, 32)        832       \n",
      "                                                                 \n",
      " conv2d_63 (Conv2D)          (None, 20, 20, 64)        51264     \n",
      "                                                                 \n",
      " flatten_148 (Flatten)       (None, 25600)             0         \n",
      "                                                                 \n",
      " dense_384 (Dense)           (None, 512)               13107712  \n",
      "                                                                 \n",
      " dropout_218 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_385 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_219 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_386 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,427,594\n",
      "Trainable params: 13,427,594\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "469/469 [==============================] - 88s 186ms/step - loss: 0.8807 - accuracy: 0.8206\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 84s 179ms/step - loss: 0.2867 - accuracy: 0.9111\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 83s 178ms/step - loss: 0.2282 - accuracy: 0.9292\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 83s 178ms/step - loss: 0.1970 - accuracy: 0.9383\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 83s 178ms/step - loss: 0.1762 - accuracy: 0.9445\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 83s 178ms/step - loss: 0.1577 - accuracy: 0.9503\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 83s 178ms/step - loss: 0.1406 - accuracy: 0.9549\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 83s 178ms/step - loss: 0.1308 - accuracy: 0.9581\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 83s 178ms/step - loss: 0.1166 - accuracy: 0.9616\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 84s 178ms/step - loss: 0.1091 - accuracy: 0.9650\n",
      "Model: \"sequential_165\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_165 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_64 (Conv2D)          (None, 24, 24, 32)        832       \n",
      "                                                                 \n",
      " conv2d_65 (Conv2D)          (None, 20, 20, 64)        51264     \n",
      "                                                                 \n",
      " flatten_149 (Flatten)       (None, 25600)             0         \n",
      "                                                                 \n",
      " dense_387 (Dense)           (None, 512)               13107712  \n",
      "                                                                 \n",
      " dropout_220 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_388 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_221 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_389 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,427,594\n",
      "Trainable params: 13,427,594\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "469/469 [==============================] - 75s 160ms/step - loss: 0.6506 - accuracy: 0.8424\n",
      "Epoch 2/25\n",
      "469/469 [==============================] - 75s 160ms/step - loss: 0.2485 - accuracy: 0.9238\n",
      "Epoch 3/25\n",
      "469/469 [==============================] - 75s 160ms/step - loss: 0.1966 - accuracy: 0.9388\n",
      "Epoch 4/25\n",
      "469/469 [==============================] - 75s 160ms/step - loss: 0.1653 - accuracy: 0.9487\n",
      "Epoch 5/25\n",
      "469/469 [==============================] - 75s 160ms/step - loss: 0.1452 - accuracy: 0.9548\n",
      "Epoch 6/25\n",
      "469/469 [==============================] - 75s 161ms/step - loss: 0.1287 - accuracy: 0.9594\n",
      "Epoch 7/25\n",
      "469/469 [==============================] - 74s 159ms/step - loss: 0.1162 - accuracy: 0.9629\n",
      "Epoch 8/25\n",
      "469/469 [==============================] - 74s 158ms/step - loss: 0.1081 - accuracy: 0.9662\n",
      "Epoch 9/25\n",
      "469/469 [==============================] - 74s 158ms/step - loss: 0.0996 - accuracy: 0.9689\n",
      "Epoch 10/25\n",
      "469/469 [==============================] - 74s 158ms/step - loss: 0.0916 - accuracy: 0.9716\n",
      "Epoch 11/25\n",
      "469/469 [==============================] - 74s 158ms/step - loss: 0.0874 - accuracy: 0.9728\n",
      "Epoch 12/25\n",
      "469/469 [==============================] - 74s 158ms/step - loss: 0.0829 - accuracy: 0.9742\n",
      "Epoch 13/25\n",
      "469/469 [==============================] - 74s 158ms/step - loss: 0.0821 - accuracy: 0.9745\n",
      "Epoch 14/25\n",
      "469/469 [==============================] - 75s 160ms/step - loss: 0.0820 - accuracy: 0.9746\n",
      "Epoch 15/25\n",
      "469/469 [==============================] - 75s 160ms/step - loss: 0.0726 - accuracy: 0.9772\n",
      "Epoch 16/25\n",
      "469/469 [==============================] - 75s 160ms/step - loss: 0.0762 - accuracy: 0.9771\n",
      "Epoch 17/25\n",
      "469/469 [==============================] - 75s 160ms/step - loss: 0.0729 - accuracy: 0.9779\n",
      "Epoch 18/25\n",
      "469/469 [==============================] - 75s 160ms/step - loss: 0.0669 - accuracy: 0.9799\n",
      "Epoch 19/25\n",
      "469/469 [==============================] - 75s 160ms/step - loss: 0.0649 - accuracy: 0.9806\n",
      "Epoch 20/25\n",
      "469/469 [==============================] - 75s 160ms/step - loss: 0.0715 - accuracy: 0.9787\n",
      "Epoch 21/25\n",
      "469/469 [==============================] - 75s 160ms/step - loss: 0.0673 - accuracy: 0.9803\n",
      "Epoch 22/25\n",
      "469/469 [==============================] - 75s 160ms/step - loss: 0.0648 - accuracy: 0.9817\n",
      "Epoch 23/25\n",
      "469/469 [==============================] - 75s 160ms/step - loss: 0.0587 - accuracy: 0.9831\n",
      "Epoch 24/25\n",
      "469/469 [==============================] - 75s 160ms/step - loss: 0.0570 - accuracy: 0.9835\n",
      "Epoch 25/25\n",
      "469/469 [==============================] - 75s 160ms/step - loss: 0.0577 - accuracy: 0.9837\n",
      "Model: \"sequential_166\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_166 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_66 (Conv2D)          (None, 24, 24, 32)        832       \n",
      "                                                                 \n",
      " conv2d_67 (Conv2D)          (None, 20, 20, 64)        51264     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  multiple                 0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_150 (Flatten)       (None, 6400)              0         \n",
      "                                                                 \n",
      " dense_390 (Dense)           (None, 512)               3277312   \n",
      "                                                                 \n",
      " dropout_222 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_391 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_223 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_392 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,597,194\n",
      "Trainable params: 3,597,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 74s 79ms/step - loss: 0.2619 - accuracy: 0.9198\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 74s 79ms/step - loss: 0.0973 - accuracy: 0.9719\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 74s 79ms/step - loss: 0.0735 - accuracy: 0.9808\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 74s 79ms/step - loss: 0.0586 - accuracy: 0.9844\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 74s 79ms/step - loss: 0.0506 - accuracy: 0.9876\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 74s 79ms/step - loss: 0.0463 - accuracy: 0.9890\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 74s 79ms/step - loss: 0.0486 - accuracy: 0.9900\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 74s 79ms/step - loss: 0.0475 - accuracy: 0.9908\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 74s 79ms/step - loss: 0.0503 - accuracy: 0.9906\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 74s 79ms/step - loss: 0.0487 - accuracy: 0.9914\n",
      "Model: \"sequential_167\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_167 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_68 (Conv2D)          (None, 24, 24, 32)        832       \n",
      "                                                                 \n",
      " conv2d_69 (Conv2D)          (None, 20, 20, 64)        51264     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  multiple                 0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_151 (Flatten)       (None, 6400)              0         \n",
      "                                                                 \n",
      " dense_393 (Dense)           (None, 512)               3277312   \n",
      "                                                                 \n",
      " dropout_224 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_394 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_225 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_395 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,597,194\n",
      "Trainable params: 3,597,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "938/938 [==============================] - 64s 68ms/step - loss: 0.2566 - accuracy: 0.9215\n",
      "Epoch 2/25\n",
      "938/938 [==============================] - 63s 68ms/step - loss: 0.0970 - accuracy: 0.9721\n",
      "Epoch 3/25\n",
      "938/938 [==============================] - 64s 68ms/step - loss: 0.0686 - accuracy: 0.9807\n",
      "Epoch 4/25\n",
      "938/938 [==============================] - 63s 67ms/step - loss: 0.0579 - accuracy: 0.9855\n",
      "Epoch 5/25\n",
      "938/938 [==============================] - 63s 68ms/step - loss: 0.0513 - accuracy: 0.9872\n",
      "Epoch 6/25\n",
      "938/938 [==============================] - 64s 68ms/step - loss: 0.0504 - accuracy: 0.9888\n",
      "Epoch 7/25\n",
      "938/938 [==============================] - 63s 68ms/step - loss: 0.0482 - accuracy: 0.9899\n",
      "Epoch 8/25\n",
      "938/938 [==============================] - 63s 68ms/step - loss: 0.0511 - accuracy: 0.9899\n",
      "Epoch 9/25\n",
      "938/938 [==============================] - 63s 67ms/step - loss: 0.0527 - accuracy: 0.9905\n",
      "Epoch 10/25\n",
      "938/938 [==============================] - 64s 68ms/step - loss: 0.0499 - accuracy: 0.9911\n",
      "Epoch 11/25\n",
      "938/938 [==============================] - 63s 68ms/step - loss: 0.0514 - accuracy: 0.9913\n",
      "Epoch 12/25\n",
      "938/938 [==============================] - 63s 68ms/step - loss: 0.0493 - accuracy: 0.9926\n",
      "Epoch 13/25\n",
      "938/938 [==============================] - 63s 68ms/step - loss: 0.0554 - accuracy: 0.9922\n",
      "Epoch 14/25\n",
      "938/938 [==============================] - 63s 68ms/step - loss: 0.0579 - accuracy: 0.9926\n",
      "Epoch 15/25\n",
      "938/938 [==============================] - 64s 68ms/step - loss: 0.0584 - accuracy: 0.9924\n",
      "Epoch 16/25\n",
      "938/938 [==============================] - 63s 68ms/step - loss: 0.0514 - accuracy: 0.9934\n",
      "Epoch 17/25\n",
      "938/938 [==============================] - 64s 68ms/step - loss: 0.0638 - accuracy: 0.9930\n",
      "Epoch 18/25\n",
      "938/938 [==============================] - 63s 68ms/step - loss: 0.0529 - accuracy: 0.9937\n",
      "Epoch 19/25\n",
      "938/938 [==============================] - 63s 68ms/step - loss: 0.0610 - accuracy: 0.9932\n",
      "Epoch 20/25\n",
      "938/938 [==============================] - 64s 68ms/step - loss: 0.0559 - accuracy: 0.9937\n",
      "Epoch 21/25\n",
      "938/938 [==============================] - 63s 68ms/step - loss: 0.0576 - accuracy: 0.9935\n",
      "Epoch 22/25\n",
      "938/938 [==============================] - 64s 68ms/step - loss: 0.0665 - accuracy: 0.9940\n",
      "Epoch 23/25\n",
      "938/938 [==============================] - 63s 68ms/step - loss: 0.0648 - accuracy: 0.9936\n",
      "Epoch 24/25\n",
      "938/938 [==============================] - 64s 68ms/step - loss: 0.0589 - accuracy: 0.9948\n",
      "Epoch 25/25\n",
      "938/938 [==============================] - 64s 68ms/step - loss: 0.0742 - accuracy: 0.9944\n",
      "Model: \"sequential_168\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_168 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_70 (Conv2D)          (None, 24, 24, 32)        832       \n",
      "                                                                 \n",
      " conv2d_71 (Conv2D)          (None, 20, 20, 64)        51264     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  multiple                 0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_152 (Flatten)       (None, 6400)              0         \n",
      "                                                                 \n",
      " dense_396 (Dense)           (None, 512)               3277312   \n",
      "                                                                 \n",
      " dropout_226 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_397 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_227 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_398 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,597,194\n",
      "Trainable params: 3,597,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "469/469 [==============================] - 81s 170ms/step - loss: 0.2875 - accuracy: 0.9119\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 80s 170ms/step - loss: 0.0906 - accuracy: 0.9733\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 80s 170ms/step - loss: 0.0550 - accuracy: 0.9829\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 80s 170ms/step - loss: 0.0394 - accuracy: 0.9881\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 80s 170ms/step - loss: 0.0339 - accuracy: 0.9902\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 80s 171ms/step - loss: 0.0293 - accuracy: 0.9920\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 80s 170ms/step - loss: 0.0297 - accuracy: 0.9923\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 80s 170ms/step - loss: 0.0252 - accuracy: 0.9935\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 80s 171ms/step - loss: 0.0233 - accuracy: 0.9942\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 80s 170ms/step - loss: 0.0245 - accuracy: 0.9943\n",
      "Model: \"sequential_169\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_169 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_72 (Conv2D)          (None, 24, 24, 32)        832       \n",
      "                                                                 \n",
      " conv2d_73 (Conv2D)          (None, 20, 20, 64)        51264     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  multiple                 0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_153 (Flatten)       (None, 6400)              0         \n",
      "                                                                 \n",
      " dense_399 (Dense)           (None, 512)               3277312   \n",
      "                                                                 \n",
      " dropout_228 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_400 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_229 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_401 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,597,194\n",
      "Trainable params: 3,597,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "469/469 [==============================] - 81s 171ms/step - loss: 0.3059 - accuracy: 0.9066\n",
      "Epoch 2/25\n",
      "469/469 [==============================] - 80s 171ms/step - loss: 0.0922 - accuracy: 0.9716\n",
      "Epoch 3/25\n",
      "469/469 [==============================] - 80s 171ms/step - loss: 0.0559 - accuracy: 0.9828\n",
      "Epoch 4/25\n",
      "469/469 [==============================] - 80s 171ms/step - loss: 0.0420 - accuracy: 0.9876\n",
      "Epoch 5/25\n",
      "469/469 [==============================] - 80s 171ms/step - loss: 0.0353 - accuracy: 0.9901\n",
      "Epoch 6/25\n",
      "469/469 [==============================] - 80s 171ms/step - loss: 0.0294 - accuracy: 0.9918\n",
      "Epoch 7/25\n",
      "469/469 [==============================] - 80s 171ms/step - loss: 0.0272 - accuracy: 0.9923\n",
      "Epoch 8/25\n",
      "469/469 [==============================] - 80s 171ms/step - loss: 0.0263 - accuracy: 0.9934\n",
      "Epoch 9/25\n",
      "469/469 [==============================] - 80s 171ms/step - loss: 0.0239 - accuracy: 0.9943\n",
      "Epoch 10/25\n",
      "469/469 [==============================] - 80s 171ms/step - loss: 0.0264 - accuracy: 0.9940\n",
      "Epoch 11/25\n",
      "469/469 [==============================] - 80s 171ms/step - loss: 0.0224 - accuracy: 0.9948\n",
      "Epoch 12/25\n",
      "469/469 [==============================] - 80s 171ms/step - loss: 0.0208 - accuracy: 0.9955\n",
      "Epoch 13/25\n",
      "469/469 [==============================] - 80s 171ms/step - loss: 0.0239 - accuracy: 0.9954\n",
      "Epoch 14/25\n",
      "469/469 [==============================] - 80s 171ms/step - loss: 0.0208 - accuracy: 0.9953\n",
      "Epoch 15/25\n",
      "469/469 [==============================] - 80s 171ms/step - loss: 0.0233 - accuracy: 0.9957\n",
      "Epoch 16/25\n",
      "469/469 [==============================] - 80s 171ms/step - loss: 0.0195 - accuracy: 0.9962\n",
      "Epoch 17/25\n",
      "469/469 [==============================] - 80s 171ms/step - loss: 0.0190 - accuracy: 0.9965\n",
      "Epoch 18/25\n",
      "469/469 [==============================] - 80s 171ms/step - loss: 0.0212 - accuracy: 0.9965\n",
      "Epoch 19/25\n",
      "469/469 [==============================] - 80s 171ms/step - loss: 0.0217 - accuracy: 0.9963\n",
      "Epoch 20/25\n",
      "469/469 [==============================] - 80s 171ms/step - loss: 0.0196 - accuracy: 0.9969\n",
      "Epoch 21/25\n",
      "469/469 [==============================] - 80s 171ms/step - loss: 0.0213 - accuracy: 0.9967\n",
      "Epoch 22/25\n",
      "469/469 [==============================] - 80s 171ms/step - loss: 0.0200 - accuracy: 0.9969\n",
      "Epoch 23/25\n",
      "469/469 [==============================] - 80s 171ms/step - loss: 0.0229 - accuracy: 0.9968\n",
      "Epoch 24/25\n",
      "469/469 [==============================] - 80s 171ms/step - loss: 0.0187 - accuracy: 0.9973\n",
      "Epoch 25/25\n",
      "469/469 [==============================] - 80s 171ms/step - loss: 0.0204 - accuracy: 0.9972\n",
      "Model: \"sequential_170\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_170 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_74 (Conv2D)          (None, 24, 24, 32)        832       \n",
      "                                                                 \n",
      " conv2d_75 (Conv2D)          (None, 20, 20, 64)        51264     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  multiple                 0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_154 (Flatten)       (None, 6400)              0         \n",
      "                                                                 \n",
      " dense_402 (Dense)           (None, 512)               3277312   \n",
      "                                                                 \n",
      " dropout_230 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_403 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_231 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_404 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,597,194\n",
      "Trainable params: 3,597,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 83s 88ms/step - loss: 0.5022 - accuracy: 0.8647\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 82s 88ms/step - loss: 0.1654 - accuracy: 0.9499\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 82s 88ms/step - loss: 0.1131 - accuracy: 0.9645\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 82s 88ms/step - loss: 0.0844 - accuracy: 0.9739\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 82s 88ms/step - loss: 0.0706 - accuracy: 0.9778\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 82s 88ms/step - loss: 0.0617 - accuracy: 0.9812\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 82s 88ms/step - loss: 0.0592 - accuracy: 0.9825\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 82s 88ms/step - loss: 0.0532 - accuracy: 0.9839\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 82s 88ms/step - loss: 0.0552 - accuracy: 0.9841\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 82s 88ms/step - loss: 0.0495 - accuracy: 0.9849\n",
      "Model: \"sequential_171\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_171 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_76 (Conv2D)          (None, 24, 24, 32)        832       \n",
      "                                                                 \n",
      " conv2d_77 (Conv2D)          (None, 20, 20, 64)        51264     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  multiple                 0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_155 (Flatten)       (None, 6400)              0         \n",
      "                                                                 \n",
      " dense_405 (Dense)           (None, 512)               3277312   \n",
      "                                                                 \n",
      " dropout_232 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_406 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_233 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_407 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,597,194\n",
      "Trainable params: 3,597,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "938/938 [==============================] - 81s 86ms/step - loss: 0.3381 - accuracy: 0.9016\n",
      "Epoch 2/25\n",
      "938/938 [==============================] - 80s 86ms/step - loss: 0.1104 - accuracy: 0.9660\n",
      "Epoch 3/25\n",
      "938/938 [==============================] - 80s 86ms/step - loss: 0.0771 - accuracy: 0.9757\n",
      "Epoch 4/25\n",
      "938/938 [==============================] - 80s 86ms/step - loss: 0.0645 - accuracy: 0.9797\n",
      "Epoch 5/25\n",
      "938/938 [==============================] - 80s 86ms/step - loss: 0.0573 - accuracy: 0.9827\n",
      "Epoch 6/25\n",
      "938/938 [==============================] - 80s 86ms/step - loss: 0.0509 - accuracy: 0.9846\n",
      "Epoch 7/25\n",
      "938/938 [==============================] - 80s 86ms/step - loss: 0.0522 - accuracy: 0.9844\n",
      "Epoch 8/25\n",
      "938/938 [==============================] - 80s 86ms/step - loss: 0.0453 - accuracy: 0.9871\n",
      "Epoch 9/25\n",
      "938/938 [==============================] - 80s 86ms/step - loss: 0.0407 - accuracy: 0.9880\n",
      "Epoch 10/25\n",
      "938/938 [==============================] - 80s 86ms/step - loss: 0.0482 - accuracy: 0.9866\n",
      "Epoch 11/25\n",
      "938/938 [==============================] - 80s 86ms/step - loss: 0.0409 - accuracy: 0.9885\n",
      "Epoch 12/25\n",
      "938/938 [==============================] - 80s 86ms/step - loss: 0.0400 - accuracy: 0.9892\n",
      "Epoch 13/25\n",
      "938/938 [==============================] - 80s 86ms/step - loss: 0.0348 - accuracy: 0.9903\n",
      "Epoch 14/25\n",
      "938/938 [==============================] - 80s 86ms/step - loss: 0.0430 - accuracy: 0.9892\n",
      "Epoch 15/25\n",
      "938/938 [==============================] - 80s 86ms/step - loss: 0.0367 - accuracy: 0.9907\n",
      "Epoch 16/25\n",
      "938/938 [==============================] - 80s 86ms/step - loss: 0.0461 - accuracy: 0.9895\n",
      "Epoch 17/25\n",
      "938/938 [==============================] - 80s 86ms/step - loss: 0.0385 - accuracy: 0.9908\n",
      "Epoch 18/25\n",
      "938/938 [==============================] - 80s 86ms/step - loss: 0.0391 - accuracy: 0.9904\n",
      "Epoch 19/25\n",
      "938/938 [==============================] - 80s 86ms/step - loss: 0.0408 - accuracy: 0.9907\n",
      "Epoch 20/25\n",
      "938/938 [==============================] - 80s 86ms/step - loss: 0.0440 - accuracy: 0.9906\n",
      "Epoch 21/25\n",
      "938/938 [==============================] - 80s 86ms/step - loss: 0.0383 - accuracy: 0.9917\n",
      "Epoch 22/25\n",
      "938/938 [==============================] - 80s 86ms/step - loss: 0.0314 - accuracy: 0.9926\n",
      "Epoch 23/25\n",
      "938/938 [==============================] - 80s 86ms/step - loss: 0.0466 - accuracy: 0.9903\n",
      "Epoch 24/25\n",
      "938/938 [==============================] - 80s 86ms/step - loss: 0.0378 - accuracy: 0.9919\n",
      "Epoch 25/25\n",
      "938/938 [==============================] - 80s 86ms/step - loss: 0.0430 - accuracy: 0.9915\n",
      "Model: \"sequential_172\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_172 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_78 (Conv2D)          (None, 24, 24, 32)        832       \n",
      "                                                                 \n",
      " conv2d_79 (Conv2D)          (None, 20, 20, 64)        51264     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  multiple                 0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_156 (Flatten)       (None, 6400)              0         \n",
      "                                                                 \n",
      " dense_408 (Dense)           (None, 512)               3277312   \n",
      "                                                                 \n",
      " dropout_234 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_409 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_235 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_410 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,597,194\n",
      "Trainable params: 3,597,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "469/469 [==============================] - 73s 154ms/step - loss: 0.3992 - accuracy: 0.8867\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 72s 154ms/step - loss: 0.1132 - accuracy: 0.9656\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 72s 154ms/step - loss: 0.0681 - accuracy: 0.9784\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 72s 154ms/step - loss: 0.0491 - accuracy: 0.9848\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 72s 154ms/step - loss: 0.0414 - accuracy: 0.9870\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 72s 154ms/step - loss: 0.0338 - accuracy: 0.9891\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 72s 154ms/step - loss: 0.0334 - accuracy: 0.9895\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 72s 154ms/step - loss: 0.0273 - accuracy: 0.9915\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 72s 154ms/step - loss: 0.0290 - accuracy: 0.9909\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 72s 154ms/step - loss: 0.0329 - accuracy: 0.9897\n",
      "Model: \"sequential_173\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_173 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_80 (Conv2D)          (None, 24, 24, 32)        832       \n",
      "                                                                 \n",
      " conv2d_81 (Conv2D)          (None, 20, 20, 64)        51264     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  multiple                 0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_157 (Flatten)       (None, 6400)              0         \n",
      "                                                                 \n",
      " dense_411 (Dense)           (None, 512)               3277312   \n",
      "                                                                 \n",
      " dropout_236 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_412 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_237 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_413 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,597,194\n",
      "Trainable params: 3,597,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "469/469 [==============================] - 71s 150ms/step - loss: 0.4187 - accuracy: 0.8822\n",
      "Epoch 2/25\n",
      "469/469 [==============================] - 71s 151ms/step - loss: 0.1185 - accuracy: 0.9647\n",
      "Epoch 3/25\n",
      "469/469 [==============================] - 71s 151ms/step - loss: 0.0719 - accuracy: 0.9775\n",
      "Epoch 4/25\n",
      "469/469 [==============================] - 71s 151ms/step - loss: 0.0544 - accuracy: 0.9826\n",
      "Epoch 5/25\n",
      "469/469 [==============================] - 71s 151ms/step - loss: 0.0429 - accuracy: 0.9868\n",
      "Epoch 6/25\n",
      "469/469 [==============================] - 71s 150ms/step - loss: 0.0347 - accuracy: 0.9885\n",
      "Epoch 7/25\n",
      "469/469 [==============================] - 71s 151ms/step - loss: 0.0404 - accuracy: 0.9871\n",
      "Epoch 8/25\n",
      "469/469 [==============================] - 71s 150ms/step - loss: 0.0329 - accuracy: 0.9896\n",
      "Epoch 9/25\n",
      "469/469 [==============================] - 71s 150ms/step - loss: 0.0284 - accuracy: 0.9908\n",
      "Epoch 10/25\n",
      "469/469 [==============================] - 71s 150ms/step - loss: 0.0330 - accuracy: 0.9895\n",
      "Epoch 11/25\n",
      "469/469 [==============================] - 71s 150ms/step - loss: 0.0293 - accuracy: 0.9912\n",
      "Epoch 12/25\n",
      "469/469 [==============================] - 71s 150ms/step - loss: 0.0284 - accuracy: 0.9918\n",
      "Epoch 13/25\n",
      "469/469 [==============================] - 71s 151ms/step - loss: 0.0229 - accuracy: 0.9931\n",
      "Epoch 14/25\n",
      "469/469 [==============================] - 71s 150ms/step - loss: 0.0260 - accuracy: 0.9926\n",
      "Epoch 15/25\n",
      "469/469 [==============================] - 71s 151ms/step - loss: 0.0255 - accuracy: 0.9929\n",
      "Epoch 16/25\n",
      "469/469 [==============================] - 71s 150ms/step - loss: 0.0282 - accuracy: 0.9920\n",
      "Epoch 17/25\n",
      "469/469 [==============================] - 71s 150ms/step - loss: 0.0241 - accuracy: 0.9931\n",
      "Epoch 18/25\n",
      "469/469 [==============================] - 71s 150ms/step - loss: 0.0209 - accuracy: 0.9943\n",
      "Epoch 19/25\n",
      "469/469 [==============================] - 71s 150ms/step - loss: 0.0256 - accuracy: 0.9929\n",
      "Epoch 20/25\n",
      "469/469 [==============================] - 71s 150ms/step - loss: 0.0214 - accuracy: 0.9940\n",
      "Epoch 21/25\n",
      "469/469 [==============================] - 71s 150ms/step - loss: 0.0238 - accuracy: 0.9937\n",
      "Epoch 22/25\n",
      "469/469 [==============================] - 71s 150ms/step - loss: 0.0268 - accuracy: 0.9931\n",
      "Epoch 23/25\n",
      "469/469 [==============================] - 71s 150ms/step - loss: 0.0176 - accuracy: 0.9952\n",
      "Epoch 24/25\n",
      "469/469 [==============================] - 71s 150ms/step - loss: 0.0272 - accuracy: 0.9931\n",
      "Epoch 25/25\n",
      "469/469 [==============================] - 71s 151ms/step - loss: 0.0223 - accuracy: 0.9944\n",
      "Model: \"sequential_174\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_174 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_82 (Conv2D)          (None, 24, 24, 32)        832       \n",
      "                                                                 \n",
      " conv2d_83 (Conv2D)          (None, 20, 20, 64)        51264     \n",
      "                                                                 \n",
      " global_max_pooling2d (Globa  multiple                 0         \n",
      " lMaxPooling2D)                                                  \n",
      "                                                                 \n",
      " dense_414 (Dense)           (None, 512)               33280     \n",
      "                                                                 \n",
      " dropout_238 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_415 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_239 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_416 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 353,162\n",
      "Trainable params: 353,162\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 64s 67ms/step - loss: 0.7234 - accuracy: 0.7647\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 63s 67ms/step - loss: 0.2760 - accuracy: 0.9139\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 63s 67ms/step - loss: 0.2121 - accuracy: 0.9340\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 63s 67ms/step - loss: 0.1872 - accuracy: 0.9442\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 63s 68ms/step - loss: 0.1738 - accuracy: 0.9481\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 63s 68ms/step - loss: 0.1694 - accuracy: 0.9513\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 63s 68ms/step - loss: 0.1667 - accuracy: 0.9525\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 63s 67ms/step - loss: 0.1676 - accuracy: 0.9533\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 63s 68ms/step - loss: 0.1699 - accuracy: 0.9529\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 63s 68ms/step - loss: 0.1686 - accuracy: 0.9536\n",
      "Model: \"sequential_175\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_175 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_84 (Conv2D)          (None, 24, 24, 32)        832       \n",
      "                                                                 \n",
      " conv2d_85 (Conv2D)          (None, 20, 20, 64)        51264     \n",
      "                                                                 \n",
      " global_max_pooling2d (Globa  multiple                 0         \n",
      " lMaxPooling2D)                                                  \n",
      "                                                                 \n",
      " dense_417 (Dense)           (None, 512)               33280     \n",
      "                                                                 \n",
      " dropout_240 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_418 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_241 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_419 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 353,162\n",
      "Trainable params: 353,162\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 0.7032 - accuracy: 0.7689\n",
      "Epoch 2/25\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 0.2633 - accuracy: 0.9184\n",
      "Epoch 3/25\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 0.2050 - accuracy: 0.9373\n",
      "Epoch 4/25\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 0.1756 - accuracy: 0.9470\n",
      "Epoch 5/25\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 0.1680 - accuracy: 0.9504\n",
      "Epoch 6/25\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 0.1633 - accuracy: 0.9516\n",
      "Epoch 7/25\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 0.1617 - accuracy: 0.9539\n",
      "Epoch 8/25\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 0.1638 - accuracy: 0.9539\n",
      "Epoch 9/25\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 0.1648 - accuracy: 0.9536\n",
      "Epoch 10/25\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 0.1648 - accuracy: 0.9546\n",
      "Epoch 11/25\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 0.1700 - accuracy: 0.9553\n",
      "Epoch 12/25\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 0.1709 - accuracy: 0.9555\n",
      "Epoch 13/25\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 0.1718 - accuracy: 0.9542\n",
      "Epoch 14/25\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 0.1746 - accuracy: 0.9548\n",
      "Epoch 15/25\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 0.1770 - accuracy: 0.9545\n",
      "Epoch 16/25\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 0.1776 - accuracy: 0.9536\n",
      "Epoch 17/25\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 0.1839 - accuracy: 0.9529\n",
      "Epoch 18/25\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 0.1841 - accuracy: 0.9539\n",
      "Epoch 19/25\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 0.1886 - accuracy: 0.9531\n",
      "Epoch 20/25\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 0.1893 - accuracy: 0.9525\n",
      "Epoch 21/25\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 0.2073 - accuracy: 0.9499\n",
      "Epoch 22/25\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 0.1995 - accuracy: 0.9513\n",
      "Epoch 23/25\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 0.1978 - accuracy: 0.9518\n",
      "Epoch 24/25\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 0.2014 - accuracy: 0.9509\n",
      "Epoch 25/25\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 0.2072 - accuracy: 0.9506\n",
      "Model: \"sequential_176\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_176 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_86 (Conv2D)          (None, 24, 24, 32)        832       \n",
      "                                                                 \n",
      " conv2d_87 (Conv2D)          (None, 20, 20, 64)        51264     \n",
      "                                                                 \n",
      " global_max_pooling2d (Globa  multiple                 0         \n",
      " lMaxPooling2D)                                                  \n",
      "                                                                 \n",
      " dense_420 (Dense)           (None, 512)               33280     \n",
      "                                                                 \n",
      " dropout_242 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_421 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_243 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_422 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 353,162\n",
      "Trainable params: 353,162\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "469/469 [==============================] - 54s 115ms/step - loss: 0.8764 - accuracy: 0.7125\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 54s 114ms/step - loss: 0.3175 - accuracy: 0.9001\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 54s 115ms/step - loss: 0.2112 - accuracy: 0.9341\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 54s 115ms/step - loss: 0.1735 - accuracy: 0.9451\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 54s 114ms/step - loss: 0.1475 - accuracy: 0.9532\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 53s 114ms/step - loss: 0.1300 - accuracy: 0.9585\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 54s 114ms/step - loss: 0.1204 - accuracy: 0.9625\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 54s 114ms/step - loss: 0.1109 - accuracy: 0.9649\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 55s 118ms/step - loss: 0.1040 - accuracy: 0.9684\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 54s 114ms/step - loss: 0.0996 - accuracy: 0.9693\n",
      "Model: \"sequential_177\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_177 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_88 (Conv2D)          (None, 24, 24, 32)        832       \n",
      "                                                                 \n",
      " conv2d_89 (Conv2D)          (None, 20, 20, 64)        51264     \n",
      "                                                                 \n",
      " global_max_pooling2d (Globa  multiple                 0         \n",
      " lMaxPooling2D)                                                  \n",
      "                                                                 \n",
      " dense_423 (Dense)           (None, 512)               33280     \n",
      "                                                                 \n",
      " dropout_244 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_424 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_245 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_425 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 353,162\n",
      "Trainable params: 353,162\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "469/469 [==============================] - 56s 119ms/step - loss: 0.8866 - accuracy: 0.7126\n",
      "Epoch 2/25\n",
      "469/469 [==============================] - 56s 119ms/step - loss: 0.3278 - accuracy: 0.8952\n",
      "Epoch 3/25\n",
      "469/469 [==============================] - 55s 118ms/step - loss: 0.2136 - accuracy: 0.9326\n",
      "Epoch 4/25\n",
      "469/469 [==============================] - 55s 118ms/step - loss: 0.1696 - accuracy: 0.9466\n",
      "Epoch 5/25\n",
      "469/469 [==============================] - 56s 119ms/step - loss: 0.1481 - accuracy: 0.9544\n",
      "Epoch 6/25\n",
      "469/469 [==============================] - 56s 119ms/step - loss: 0.1316 - accuracy: 0.9583\n",
      "Epoch 7/25\n",
      "469/469 [==============================] - 56s 119ms/step - loss: 0.1199 - accuracy: 0.9628\n",
      "Epoch 8/25\n",
      "469/469 [==============================] - 56s 119ms/step - loss: 0.1110 - accuracy: 0.9649\n",
      "Epoch 9/25\n",
      "469/469 [==============================] - 56s 119ms/step - loss: 0.1027 - accuracy: 0.9687\n",
      "Epoch 10/25\n",
      "469/469 [==============================] - 56s 120ms/step - loss: 0.0979 - accuracy: 0.9692\n",
      "Epoch 11/25\n",
      "469/469 [==============================] - 55s 118ms/step - loss: 0.0969 - accuracy: 0.9696\n",
      "Epoch 12/25\n",
      "469/469 [==============================] - 55s 118ms/step - loss: 0.0939 - accuracy: 0.9713\n",
      "Epoch 13/25\n",
      "469/469 [==============================] - 55s 118ms/step - loss: 0.0908 - accuracy: 0.9722\n",
      "Epoch 14/25\n",
      "469/469 [==============================] - 55s 118ms/step - loss: 0.0902 - accuracy: 0.9732\n",
      "Epoch 15/25\n",
      "469/469 [==============================] - 55s 118ms/step - loss: 0.0843 - accuracy: 0.9748\n",
      "Epoch 16/25\n",
      "469/469 [==============================] - 55s 117ms/step - loss: 0.0844 - accuracy: 0.9749\n",
      "Epoch 17/25\n",
      "469/469 [==============================] - 55s 117ms/step - loss: 0.0857 - accuracy: 0.9757\n",
      "Epoch 18/25\n",
      "469/469 [==============================] - 55s 117ms/step - loss: 0.0879 - accuracy: 0.9755\n",
      "Epoch 19/25\n",
      "469/469 [==============================] - 55s 117ms/step - loss: 0.0826 - accuracy: 0.9755\n",
      "Epoch 20/25\n",
      "469/469 [==============================] - 55s 117ms/step - loss: 0.0850 - accuracy: 0.9753\n",
      "Epoch 21/25\n",
      "469/469 [==============================] - 55s 117ms/step - loss: 0.0853 - accuracy: 0.9766\n",
      "Epoch 22/25\n",
      "469/469 [==============================] - 55s 117ms/step - loss: 0.0866 - accuracy: 0.9765\n",
      "Epoch 23/25\n",
      "469/469 [==============================] - 55s 117ms/step - loss: 0.0889 - accuracy: 0.9751\n",
      "Epoch 24/25\n",
      "469/469 [==============================] - 55s 117ms/step - loss: 0.0863 - accuracy: 0.9759\n",
      "Epoch 25/25\n",
      "469/469 [==============================] - 55s 118ms/step - loss: 0.0857 - accuracy: 0.9769\n",
      "Model: \"sequential_178\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_178 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_90 (Conv2D)          (None, 24, 24, 32)        832       \n",
      "                                                                 \n",
      " conv2d_91 (Conv2D)          (None, 20, 20, 64)        51264     \n",
      "                                                                 \n",
      " global_max_pooling2d (Globa  multiple                 0         \n",
      " lMaxPooling2D)                                                  \n",
      "                                                                 \n",
      " dense_426 (Dense)           (None, 512)               33280     \n",
      "                                                                 \n",
      " dropout_246 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_427 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_247 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_428 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 353,162\n",
      "Trainable params: 353,162\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 65s 69ms/step - loss: 0.5634 - accuracy: 0.8160\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 64s 68ms/step - loss: 0.2470 - accuracy: 0.9219\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 64s 68ms/step - loss: 0.1917 - accuracy: 0.9389\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 64s 68ms/step - loss: 0.1654 - accuracy: 0.9473\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 64s 68ms/step - loss: 0.1420 - accuracy: 0.9548\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 64s 68ms/step - loss: 0.1293 - accuracy: 0.9581\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 64s 68ms/step - loss: 0.1187 - accuracy: 0.9623\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 64s 68ms/step - loss: 0.1088 - accuracy: 0.9647\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 64s 68ms/step - loss: 0.0995 - accuracy: 0.9673\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 64s 68ms/step - loss: 0.0943 - accuracy: 0.9682\n",
      "Model: \"sequential_179\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_179 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_92 (Conv2D)          (None, 24, 24, 32)        832       \n",
      "                                                                 \n",
      " conv2d_93 (Conv2D)          (None, 20, 20, 64)        51264     \n",
      "                                                                 \n",
      " global_max_pooling2d (Globa  multiple                 0         \n",
      " lMaxPooling2D)                                                  \n",
      "                                                                 \n",
      " dense_429 (Dense)           (None, 512)               33280     \n",
      "                                                                 \n",
      " dropout_248 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_430 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_249 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_431 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 353,162\n",
      "Trainable params: 353,162\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "938/938 [==============================] - 67s 71ms/step - loss: 0.5412 - accuracy: 0.8232\n",
      "Epoch 2/25\n",
      "938/938 [==============================] - 67s 71ms/step - loss: 0.2360 - accuracy: 0.9250\n",
      "Epoch 3/25\n",
      "938/938 [==============================] - 67s 71ms/step - loss: 0.1826 - accuracy: 0.9418\n",
      "Epoch 4/25\n",
      "938/938 [==============================] - 67s 71ms/step - loss: 0.1563 - accuracy: 0.9508\n",
      "Epoch 5/25\n",
      "938/938 [==============================] - 67s 71ms/step - loss: 0.1356 - accuracy: 0.9564\n",
      "Epoch 6/25\n",
      "938/938 [==============================] - 67s 71ms/step - loss: 0.1237 - accuracy: 0.9592\n",
      "Epoch 7/25\n",
      "938/938 [==============================] - 67s 71ms/step - loss: 0.1120 - accuracy: 0.9644\n",
      "Epoch 8/25\n",
      "938/938 [==============================] - 67s 71ms/step - loss: 0.0988 - accuracy: 0.9668\n",
      "Epoch 9/25\n",
      "938/938 [==============================] - 67s 71ms/step - loss: 0.0946 - accuracy: 0.9694\n",
      "Epoch 10/25\n",
      "938/938 [==============================] - 67s 71ms/step - loss: 0.0894 - accuracy: 0.9711\n",
      "Epoch 11/25\n",
      "938/938 [==============================] - 67s 72ms/step - loss: 0.0814 - accuracy: 0.9735\n",
      "Epoch 12/25\n",
      "938/938 [==============================] - 67s 71ms/step - loss: 0.0745 - accuracy: 0.9753\n",
      "Epoch 13/25\n",
      "938/938 [==============================] - 67s 71ms/step - loss: 0.0743 - accuracy: 0.9756\n",
      "Epoch 14/25\n",
      "938/938 [==============================] - 67s 71ms/step - loss: 0.0711 - accuracy: 0.9773\n",
      "Epoch 15/25\n",
      "938/938 [==============================] - 67s 71ms/step - loss: 0.0688 - accuracy: 0.9774\n",
      "Epoch 16/25\n",
      "938/938 [==============================] - 67s 71ms/step - loss: 0.0641 - accuracy: 0.9792\n",
      "Epoch 17/25\n",
      "938/938 [==============================] - 67s 71ms/step - loss: 0.0627 - accuracy: 0.9794\n",
      "Epoch 18/25\n",
      "938/938 [==============================] - 67s 71ms/step - loss: 0.0568 - accuracy: 0.9816\n",
      "Epoch 19/25\n",
      "938/938 [==============================] - 67s 71ms/step - loss: 0.0598 - accuracy: 0.9804\n",
      "Epoch 20/25\n",
      "938/938 [==============================] - 67s 71ms/step - loss: 0.0562 - accuracy: 0.9814\n",
      "Epoch 21/25\n",
      "938/938 [==============================] - 67s 71ms/step - loss: 0.0534 - accuracy: 0.9828\n",
      "Epoch 22/25\n",
      "938/938 [==============================] - 67s 71ms/step - loss: 0.0526 - accuracy: 0.9827\n",
      "Epoch 23/25\n",
      "938/938 [==============================] - 67s 71ms/step - loss: 0.0527 - accuracy: 0.9831\n",
      "Epoch 24/25\n",
      "938/938 [==============================] - 67s 71ms/step - loss: 0.0502 - accuracy: 0.9839\n",
      "Epoch 25/25\n",
      "938/938 [==============================] - 67s 71ms/step - loss: 0.0518 - accuracy: 0.9837\n",
      "Model: \"sequential_180\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_180 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_94 (Conv2D)          (None, 24, 24, 32)        832       \n",
      "                                                                 \n",
      " conv2d_95 (Conv2D)          (None, 20, 20, 64)        51264     \n",
      "                                                                 \n",
      " global_max_pooling2d (Globa  multiple                 0         \n",
      " lMaxPooling2D)                                                  \n",
      "                                                                 \n",
      " dense_432 (Dense)           (None, 512)               33280     \n",
      "                                                                 \n",
      " dropout_250 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_433 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_251 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_434 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 353,162\n",
      "Trainable params: 353,162\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "469/469 [==============================] - 61s 129ms/step - loss: 0.6060 - accuracy: 0.8005\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 61s 129ms/step - loss: 0.2370 - accuracy: 0.9261\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 61s 129ms/step - loss: 0.1802 - accuracy: 0.9438\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 61s 129ms/step - loss: 0.1469 - accuracy: 0.9537\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 61s 129ms/step - loss: 0.1245 - accuracy: 0.9599\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 61s 129ms/step - loss: 0.1110 - accuracy: 0.9639\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 61s 129ms/step - loss: 0.1012 - accuracy: 0.9669\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 61s 129ms/step - loss: 0.0896 - accuracy: 0.9709\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 61s 129ms/step - loss: 0.0825 - accuracy: 0.9742\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 60s 129ms/step - loss: 0.0769 - accuracy: 0.9740\n",
      "Model: \"sequential_181\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_181 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_96 (Conv2D)          (None, 24, 24, 32)        832       \n",
      "                                                                 \n",
      " conv2d_97 (Conv2D)          (None, 20, 20, 64)        51264     \n",
      "                                                                 \n",
      " global_max_pooling2d (Globa  multiple                 0         \n",
      " lMaxPooling2D)                                                  \n",
      "                                                                 \n",
      " dense_435 (Dense)           (None, 512)               33280     \n",
      "                                                                 \n",
      " dropout_252 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_436 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_253 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_437 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 353,162\n",
      "Trainable params: 353,162\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "469/469 [==============================] - 55s 117ms/step - loss: 0.5550 - accuracy: 0.8185\n",
      "Epoch 2/25\n",
      "469/469 [==============================] - 55s 117ms/step - loss: 0.2181 - accuracy: 0.9320\n",
      "Epoch 3/25\n",
      "469/469 [==============================] - 55s 117ms/step - loss: 0.1637 - accuracy: 0.9489\n",
      "Epoch 4/25\n",
      "469/469 [==============================] - 55s 117ms/step - loss: 0.1352 - accuracy: 0.9574\n",
      "Epoch 5/25\n",
      "469/469 [==============================] - 55s 116ms/step - loss: 0.1161 - accuracy: 0.9630\n",
      "Epoch 6/25\n",
      "469/469 [==============================] - 55s 116ms/step - loss: 0.1021 - accuracy: 0.9675\n",
      "Epoch 7/25\n",
      "469/469 [==============================] - 54s 116ms/step - loss: 0.0954 - accuracy: 0.9690\n",
      "Epoch 8/25\n",
      "469/469 [==============================] - 55s 116ms/step - loss: 0.0800 - accuracy: 0.9730\n",
      "Epoch 9/25\n",
      "469/469 [==============================] - 55s 116ms/step - loss: 0.0766 - accuracy: 0.9750\n",
      "Epoch 10/25\n",
      "469/469 [==============================] - 54s 116ms/step - loss: 0.0663 - accuracy: 0.9776\n",
      "Epoch 11/25\n",
      "469/469 [==============================] - 54s 116ms/step - loss: 0.0665 - accuracy: 0.9782\n",
      "Epoch 12/25\n",
      "469/469 [==============================] - 54s 116ms/step - loss: 0.0585 - accuracy: 0.9805\n",
      "Epoch 13/25\n",
      "469/469 [==============================] - 54s 116ms/step - loss: 0.0576 - accuracy: 0.9810\n",
      "Epoch 14/25\n",
      "469/469 [==============================] - 55s 117ms/step - loss: 0.0515 - accuracy: 0.9829\n",
      "Epoch 15/25\n",
      "469/469 [==============================] - 55s 117ms/step - loss: 0.0518 - accuracy: 0.9825\n",
      "Epoch 16/25\n",
      "469/469 [==============================] - 55s 116ms/step - loss: 0.0509 - accuracy: 0.9827\n",
      "Epoch 17/25\n",
      "469/469 [==============================] - 55s 116ms/step - loss: 0.0437 - accuracy: 0.9850\n",
      "Epoch 18/25\n",
      "469/469 [==============================] - 55s 117ms/step - loss: 0.0437 - accuracy: 0.9855\n",
      "Epoch 19/25\n",
      "469/469 [==============================] - 55s 117ms/step - loss: 0.0396 - accuracy: 0.9868\n",
      "Epoch 20/25\n",
      "469/469 [==============================] - 55s 117ms/step - loss: 0.0391 - accuracy: 0.9861\n",
      "Epoch 21/25\n",
      "469/469 [==============================] - 55s 117ms/step - loss: 0.0416 - accuracy: 0.9861\n",
      "Epoch 22/25\n",
      "469/469 [==============================] - 55s 117ms/step - loss: 0.0367 - accuracy: 0.9880\n",
      "Epoch 23/25\n",
      "469/469 [==============================] - 55s 117ms/step - loss: 0.0352 - accuracy: 0.9886\n",
      "Epoch 24/25\n",
      "469/469 [==============================] - 55s 118ms/step - loss: 0.0376 - accuracy: 0.9877\n",
      "Epoch 25/25\n",
      "469/469 [==============================] - 55s 118ms/step - loss: 0.0360 - accuracy: 0.9882\n",
      "Model: \"sequential_182\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_182 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_98 (Conv2D)          (None, 22, 22, 32)        1600      \n",
      "                                                                 \n",
      " conv2d_99 (Conv2D)          (None, 16, 16, 64)        100416    \n",
      "                                                                 \n",
      " flatten_158 (Flatten)       (None, 16384)             0         \n",
      "                                                                 \n",
      " dense_438 (Dense)           (None, 512)               8389120   \n",
      "                                                                 \n",
      " dropout_254 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_439 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_255 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_440 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,758,922\n",
      "Trainable params: 8,758,922\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 92s 98ms/step - loss: 0.4856 - accuracy: 0.8611\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 91s 97ms/step - loss: 0.2731 - accuracy: 0.9230\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 91s 97ms/step - loss: 0.2528 - accuracy: 0.9320\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 91s 97ms/step - loss: 0.2563 - accuracy: 0.9362\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 92s 98ms/step - loss: 0.2664 - accuracy: 0.9374\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 91s 97ms/step - loss: 0.2812 - accuracy: 0.9371\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 91s 97ms/step - loss: 0.3017 - accuracy: 0.9349\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 91s 98ms/step - loss: 0.3077 - accuracy: 0.9373\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 91s 97ms/step - loss: 0.3193 - accuracy: 0.9341\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 91s 97ms/step - loss: 0.3486 - accuracy: 0.9332\n",
      "Model: \"sequential_183\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_183 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_100 (Conv2D)         (None, 22, 22, 32)        1600      \n",
      "                                                                 \n",
      " conv2d_101 (Conv2D)         (None, 16, 16, 64)        100416    \n",
      "                                                                 \n",
      " flatten_159 (Flatten)       (None, 16384)             0         \n",
      "                                                                 \n",
      " dense_441 (Dense)           (None, 512)               8389120   \n",
      "                                                                 \n",
      " dropout_256 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_442 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_257 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_443 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,758,922\n",
      "Trainable params: 8,758,922\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "938/938 [==============================] - 94s 100ms/step - loss: 0.4914 - accuracy: 0.8617\n",
      "Epoch 2/25\n",
      "938/938 [==============================] - 94s 100ms/step - loss: 0.2713 - accuracy: 0.9241\n",
      "Epoch 3/25\n",
      "938/938 [==============================] - 94s 100ms/step - loss: 0.2458 - accuracy: 0.9341\n",
      "Epoch 4/25\n",
      "938/938 [==============================] - 94s 100ms/step - loss: 0.2537 - accuracy: 0.9367\n",
      "Epoch 5/25\n",
      "938/938 [==============================] - 94s 100ms/step - loss: 0.2551 - accuracy: 0.9396\n",
      "Epoch 6/25\n",
      "938/938 [==============================] - 94s 100ms/step - loss: 0.2729 - accuracy: 0.9395\n",
      "Epoch 7/25\n",
      "938/938 [==============================] - 94s 101ms/step - loss: 0.2839 - accuracy: 0.9385\n",
      "Epoch 8/25\n",
      "938/938 [==============================] - 94s 100ms/step - loss: 0.2968 - accuracy: 0.9376\n",
      "Epoch 9/25\n",
      "938/938 [==============================] - 94s 100ms/step - loss: 0.3128 - accuracy: 0.9344\n",
      "Epoch 10/25\n",
      "938/938 [==============================] - 94s 100ms/step - loss: 0.3201 - accuracy: 0.9357\n",
      "Epoch 11/25\n",
      "938/938 [==============================] - 94s 100ms/step - loss: 0.3537 - accuracy: 0.9307\n",
      "Epoch 12/25\n",
      "938/938 [==============================] - 94s 100ms/step - loss: 0.3773 - accuracy: 0.9269\n",
      "Epoch 13/25\n",
      "938/938 [==============================] - 94s 100ms/step - loss: 0.3792 - accuracy: 0.9271\n",
      "Epoch 14/25\n",
      "938/938 [==============================] - 94s 100ms/step - loss: 0.3767 - accuracy: 0.9253\n",
      "Epoch 15/25\n",
      "938/938 [==============================] - 94s 100ms/step - loss: 0.4218 - accuracy: 0.9195\n",
      "Epoch 16/25\n",
      "938/938 [==============================] - 94s 100ms/step - loss: 0.4331 - accuracy: 0.9161\n",
      "Epoch 17/25\n",
      "938/938 [==============================] - 94s 100ms/step - loss: 0.4444 - accuracy: 0.9179\n",
      "Epoch 18/25\n",
      "938/938 [==============================] - 94s 100ms/step - loss: 0.4463 - accuracy: 0.9149\n",
      "Epoch 19/25\n",
      "938/938 [==============================] - 94s 100ms/step - loss: 0.4406 - accuracy: 0.9148\n",
      "Epoch 20/25\n",
      "938/938 [==============================] - 93s 100ms/step - loss: 0.4510 - accuracy: 0.9133\n",
      "Epoch 21/25\n",
      "938/938 [==============================] - 94s 100ms/step - loss: 0.4682 - accuracy: 0.9108\n",
      "Epoch 22/25\n",
      "938/938 [==============================] - 94s 100ms/step - loss: 0.4750 - accuracy: 0.9027\n",
      "Epoch 23/25\n",
      "938/938 [==============================] - 94s 100ms/step - loss: 0.4939 - accuracy: 0.9011\n",
      "Epoch 24/25\n",
      "938/938 [==============================] - 94s 100ms/step - loss: 0.5024 - accuracy: 0.8978\n",
      "Epoch 25/25\n",
      "938/938 [==============================] - 94s 100ms/step - loss: 0.4986 - accuracy: 0.8950\n",
      "Model: \"sequential_184\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_184 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_102 (Conv2D)         (None, 22, 22, 32)        1600      \n",
      "                                                                 \n",
      " conv2d_103 (Conv2D)         (None, 16, 16, 64)        100416    \n",
      "                                                                 \n",
      " flatten_160 (Flatten)       (None, 16384)             0         \n",
      "                                                                 \n",
      " dense_444 (Dense)           (None, 512)               8389120   \n",
      "                                                                 \n",
      " dropout_258 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_445 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_259 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_446 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,758,922\n",
      "Trainable params: 8,758,922\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "469/469 [==============================] - 115s 244ms/step - loss: 0.5182 - accuracy: 0.8577\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 114s 244ms/step - loss: 0.2301 - accuracy: 0.9309\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 115s 244ms/step - loss: 0.1776 - accuracy: 0.9479\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 119s 253ms/step - loss: 0.1485 - accuracy: 0.9564\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 116s 247ms/step - loss: 0.1297 - accuracy: 0.9626\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 115s 245ms/step - loss: 0.1218 - accuracy: 0.9662\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 116s 248ms/step - loss: 0.1132 - accuracy: 0.9693\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 116s 247ms/step - loss: 0.1134 - accuracy: 0.9710\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 116s 247ms/step - loss: 0.1174 - accuracy: 0.9719\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 116s 246ms/step - loss: 0.1126 - accuracy: 0.9733\n",
      "Model: \"sequential_185\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_185 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_104 (Conv2D)         (None, 22, 22, 32)        1600      \n",
      "                                                                 \n",
      " conv2d_105 (Conv2D)         (None, 16, 16, 64)        100416    \n",
      "                                                                 \n",
      " flatten_161 (Flatten)       (None, 16384)             0         \n",
      "                                                                 \n",
      " dense_447 (Dense)           (None, 512)               8389120   \n",
      "                                                                 \n",
      " dropout_260 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_448 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_261 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_449 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,758,922\n",
      "Trainable params: 8,758,922\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "469/469 [==============================] - 111s 236ms/step - loss: 0.5079 - accuracy: 0.8573\n",
      "Epoch 2/25\n",
      "469/469 [==============================] - 112s 240ms/step - loss: 0.2326 - accuracy: 0.9305\n",
      "Epoch 3/25\n",
      "469/469 [==============================] - 111s 236ms/step - loss: 0.1821 - accuracy: 0.9445\n",
      "Epoch 4/25\n",
      "469/469 [==============================] - 110s 234ms/step - loss: 0.1494 - accuracy: 0.9568\n",
      "Epoch 5/25\n",
      "469/469 [==============================] - 110s 234ms/step - loss: 0.1354 - accuracy: 0.9613\n",
      "Epoch 6/25\n",
      "469/469 [==============================] - 110s 234ms/step - loss: 0.1231 - accuracy: 0.9654\n",
      "Epoch 7/25\n",
      "469/469 [==============================] - 110s 234ms/step - loss: 0.1154 - accuracy: 0.9695\n",
      "Epoch 8/25\n",
      "469/469 [==============================] - 110s 234ms/step - loss: 0.1134 - accuracy: 0.9701\n",
      "Epoch 9/25\n",
      "469/469 [==============================] - 110s 234ms/step - loss: 0.1142 - accuracy: 0.9717\n",
      "Epoch 10/25\n",
      "469/469 [==============================] - 110s 234ms/step - loss: 0.1133 - accuracy: 0.9729\n",
      "Epoch 11/25\n",
      "469/469 [==============================] - 110s 234ms/step - loss: 0.1121 - accuracy: 0.9743\n",
      "Epoch 12/25\n",
      "469/469 [==============================] - 110s 234ms/step - loss: 0.1186 - accuracy: 0.9732\n",
      "Epoch 13/25\n",
      "469/469 [==============================] - 109s 233ms/step - loss: 0.1223 - accuracy: 0.9734\n",
      "Epoch 14/25\n",
      "469/469 [==============================] - 110s 234ms/step - loss: 0.1258 - accuracy: 0.9741\n",
      "Epoch 15/25\n",
      "469/469 [==============================] - 110s 234ms/step - loss: 0.1280 - accuracy: 0.9744\n",
      "Epoch 16/25\n",
      "469/469 [==============================] - 110s 234ms/step - loss: 0.1267 - accuracy: 0.9740\n",
      "Epoch 17/25\n",
      "469/469 [==============================] - 110s 234ms/step - loss: 0.1350 - accuracy: 0.9747\n",
      "Epoch 18/25\n",
      "469/469 [==============================] - 110s 234ms/step - loss: 0.1292 - accuracy: 0.9753\n",
      "Epoch 19/25\n",
      "469/469 [==============================] - 110s 234ms/step - loss: 0.1366 - accuracy: 0.9771\n",
      "Epoch 20/25\n",
      "469/469 [==============================] - 110s 234ms/step - loss: 0.1375 - accuracy: 0.9757\n",
      "Epoch 21/25\n",
      "469/469 [==============================] - 110s 234ms/step - loss: 0.1485 - accuracy: 0.9758\n",
      "Epoch 22/25\n",
      "469/469 [==============================] - 110s 234ms/step - loss: 0.1441 - accuracy: 0.9751\n",
      "Epoch 23/25\n",
      "469/469 [==============================] - 109s 233ms/step - loss: 0.1542 - accuracy: 0.9754\n",
      "Epoch 24/25\n",
      "469/469 [==============================] - 110s 234ms/step - loss: 0.1420 - accuracy: 0.9761\n",
      "Epoch 25/25\n",
      "469/469 [==============================] - 110s 234ms/step - loss: 0.1499 - accuracy: 0.9779\n",
      "Model: \"sequential_186\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_186 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_106 (Conv2D)         (None, 22, 22, 32)        1600      \n",
      "                                                                 \n",
      " conv2d_107 (Conv2D)         (None, 16, 16, 64)        100416    \n",
      "                                                                 \n",
      " flatten_162 (Flatten)       (None, 16384)             0         \n",
      "                                                                 \n",
      " dense_450 (Dense)           (None, 512)               8389120   \n",
      "                                                                 \n",
      " dropout_262 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_451 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_263 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_452 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,758,922\n",
      "Trainable params: 8,758,922\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 113s 120ms/step - loss: 2.5777 - accuracy: 0.5575\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 113s 120ms/step - loss: 0.8162 - accuracy: 0.7403\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 113s 120ms/step - loss: 0.6306 - accuracy: 0.8029\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 113s 120ms/step - loss: 1.2069 - accuracy: 0.6021\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 113s 120ms/step - loss: 0.6231 - accuracy: 0.8083\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 113s 121ms/step - loss: 0.4678 - accuracy: 0.8553\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 113s 121ms/step - loss: 0.4127 - accuracy: 0.8730\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 113s 121ms/step - loss: 0.3770 - accuracy: 0.8843\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 113s 121ms/step - loss: 0.3407 - accuracy: 0.8953\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 113s 120ms/step - loss: 0.3207 - accuracy: 0.9015\n",
      "Model: \"sequential_187\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_187 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_108 (Conv2D)         (None, 22, 22, 32)        1600      \n",
      "                                                                 \n",
      " conv2d_109 (Conv2D)         (None, 16, 16, 64)        100416    \n",
      "                                                                 \n",
      " flatten_163 (Flatten)       (None, 16384)             0         \n",
      "                                                                 \n",
      " dense_453 (Dense)           (None, 512)               8389120   \n",
      "                                                                 \n",
      " dropout_264 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_454 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_265 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_455 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,758,922\n",
      "Trainable params: 8,758,922\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "938/938 [==============================] - 110s 117ms/step - loss: 1.0841 - accuracy: 0.7667\n",
      "Epoch 2/25\n",
      "938/938 [==============================] - 110s 117ms/step - loss: 0.3944 - accuracy: 0.8780\n",
      "Epoch 3/25\n",
      "938/938 [==============================] - 110s 117ms/step - loss: 0.3169 - accuracy: 0.9026\n",
      "Epoch 4/25\n",
      "938/938 [==============================] - 110s 117ms/step - loss: 0.2766 - accuracy: 0.9144\n",
      "Epoch 5/25\n",
      "938/938 [==============================] - 110s 117ms/step - loss: 0.2685 - accuracy: 0.9165\n",
      "Epoch 6/25\n",
      "938/938 [==============================] - 110s 117ms/step - loss: 0.2326 - accuracy: 0.9282\n",
      "Epoch 7/25\n",
      "938/938 [==============================] - 110s 117ms/step - loss: 0.2345 - accuracy: 0.9274\n",
      "Epoch 8/25\n",
      "938/938 [==============================] - 110s 117ms/step - loss: 0.2244 - accuracy: 0.9330\n",
      "Epoch 9/25\n",
      "938/938 [==============================] - 110s 117ms/step - loss: 0.2148 - accuracy: 0.9358\n",
      "Epoch 10/25\n",
      "938/938 [==============================] - 110s 117ms/step - loss: 0.2010 - accuracy: 0.9405\n",
      "Epoch 11/25\n",
      "938/938 [==============================] - 110s 117ms/step - loss: 0.1989 - accuracy: 0.9414\n",
      "Epoch 12/25\n",
      "938/938 [==============================] - 110s 117ms/step - loss: 0.2049 - accuracy: 0.9402\n",
      "Epoch 13/25\n",
      "938/938 [==============================] - 110s 117ms/step - loss: 0.1817 - accuracy: 0.9478\n",
      "Epoch 14/25\n",
      "938/938 [==============================] - 110s 117ms/step - loss: 0.1843 - accuracy: 0.9471\n",
      "Epoch 15/25\n",
      "938/938 [==============================] - 110s 117ms/step - loss: 0.1740 - accuracy: 0.9507\n",
      "Epoch 16/25\n",
      "938/938 [==============================] - 110s 117ms/step - loss: 0.1880 - accuracy: 0.9482\n",
      "Epoch 17/25\n",
      "938/938 [==============================] - 110s 117ms/step - loss: 0.1689 - accuracy: 0.9535\n",
      "Epoch 18/25\n",
      "938/938 [==============================] - 110s 117ms/step - loss: 0.1749 - accuracy: 0.9520\n",
      "Epoch 19/25\n",
      "938/938 [==============================] - 110s 117ms/step - loss: 0.1615 - accuracy: 0.9547\n",
      "Epoch 20/25\n",
      "938/938 [==============================] - 110s 117ms/step - loss: 0.1712 - accuracy: 0.9541\n",
      "Epoch 21/25\n",
      "938/938 [==============================] - 110s 117ms/step - loss: 0.1766 - accuracy: 0.9528\n",
      "Epoch 22/25\n",
      "938/938 [==============================] - 110s 117ms/step - loss: 0.1628 - accuracy: 0.9570\n",
      "Epoch 23/25\n",
      "938/938 [==============================] - 110s 117ms/step - loss: 0.1522 - accuracy: 0.9596\n",
      "Epoch 24/25\n",
      "938/938 [==============================] - 110s 117ms/step - loss: 0.1612 - accuracy: 0.9573\n",
      "Epoch 25/25\n",
      "938/938 [==============================] - 110s 117ms/step - loss: 0.1793 - accuracy: 0.9548\n",
      "Model: \"sequential_188\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_188 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_110 (Conv2D)         (None, 22, 22, 32)        1600      \n",
      "                                                                 \n",
      " conv2d_111 (Conv2D)         (None, 16, 16, 64)        100416    \n",
      "                                                                 \n",
      " flatten_164 (Flatten)       (None, 16384)             0         \n",
      "                                                                 \n",
      " dense_456 (Dense)           (None, 512)               8389120   \n",
      "                                                                 \n",
      " dropout_266 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_457 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_267 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_458 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,758,922\n",
      "Trainable params: 8,758,922\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "469/469 [==============================] - 93s 198ms/step - loss: 1.3495 - accuracy: 0.7670\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 93s 198ms/step - loss: 0.3701 - accuracy: 0.8850\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 93s 199ms/step - loss: 0.2896 - accuracy: 0.9094\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 93s 199ms/step - loss: 0.2541 - accuracy: 0.9218\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 93s 199ms/step - loss: 0.2244 - accuracy: 0.9298\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 93s 199ms/step - loss: 0.2042 - accuracy: 0.9367\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 93s 199ms/step - loss: 0.1883 - accuracy: 0.9423\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 93s 199ms/step - loss: 0.1712 - accuracy: 0.9463\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 93s 198ms/step - loss: 0.1626 - accuracy: 0.9496\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 93s 198ms/step - loss: 0.1536 - accuracy: 0.9527\n",
      "Model: \"sequential_189\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_189 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_112 (Conv2D)         (None, 22, 22, 32)        1600      \n",
      "                                                                 \n",
      " conv2d_113 (Conv2D)         (None, 16, 16, 64)        100416    \n",
      "                                                                 \n",
      " flatten_165 (Flatten)       (None, 16384)             0         \n",
      "                                                                 \n",
      " dense_459 (Dense)           (None, 512)               8389120   \n",
      "                                                                 \n",
      " dropout_268 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_460 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_269 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_461 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,758,922\n",
      "Trainable params: 8,758,922\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "469/469 [==============================] - 91s 194ms/step - loss: 2.6815 - accuracy: 0.3548\n",
      "Epoch 2/25\n",
      "469/469 [==============================] - 91s 194ms/step - loss: 1.0753 - accuracy: 0.6298\n",
      "Epoch 3/25\n",
      "469/469 [==============================] - 91s 194ms/step - loss: 0.6763 - accuracy: 0.7879\n",
      "Epoch 4/25\n",
      "469/469 [==============================] - 91s 194ms/step - loss: 0.5091 - accuracy: 0.8412\n",
      "Epoch 5/25\n",
      "469/469 [==============================] - 91s 194ms/step - loss: 0.4271 - accuracy: 0.8672\n",
      "Epoch 6/25\n",
      "469/469 [==============================] - 91s 195ms/step - loss: 0.3748 - accuracy: 0.8833\n",
      "Epoch 7/25\n",
      "469/469 [==============================] - 91s 194ms/step - loss: 0.3373 - accuracy: 0.8958\n",
      "Epoch 8/25\n",
      "469/469 [==============================] - 91s 194ms/step - loss: 0.3133 - accuracy: 0.9025\n",
      "Epoch 9/25\n",
      "469/469 [==============================] - 91s 194ms/step - loss: 0.2805 - accuracy: 0.9126\n",
      "Epoch 10/25\n",
      "469/469 [==============================] - 91s 194ms/step - loss: 0.2608 - accuracy: 0.9187\n",
      "Epoch 11/25\n",
      "469/469 [==============================] - 91s 194ms/step - loss: 0.2361 - accuracy: 0.9264\n",
      "Epoch 12/25\n",
      "469/469 [==============================] - 91s 194ms/step - loss: 0.2311 - accuracy: 0.9282\n",
      "Epoch 13/25\n",
      "469/469 [==============================] - 91s 194ms/step - loss: 0.2100 - accuracy: 0.9349\n",
      "Epoch 14/25\n",
      "469/469 [==============================] - 91s 194ms/step - loss: 0.1995 - accuracy: 0.9383\n",
      "Epoch 15/25\n",
      "469/469 [==============================] - 91s 194ms/step - loss: 0.1928 - accuracy: 0.9391\n",
      "Epoch 16/25\n",
      "469/469 [==============================] - 91s 194ms/step - loss: 0.1825 - accuracy: 0.9431\n",
      "Epoch 17/25\n",
      "469/469 [==============================] - 91s 194ms/step - loss: 0.1709 - accuracy: 0.9464\n",
      "Epoch 18/25\n",
      "469/469 [==============================] - 91s 194ms/step - loss: 0.1630 - accuracy: 0.9489\n",
      "Epoch 19/25\n",
      "469/469 [==============================] - 91s 194ms/step - loss: 0.1573 - accuracy: 0.9512\n",
      "Epoch 20/25\n",
      "469/469 [==============================] - 91s 194ms/step - loss: 0.1537 - accuracy: 0.9518\n",
      "Epoch 21/25\n",
      "469/469 [==============================] - 91s 194ms/step - loss: 0.1423 - accuracy: 0.9557\n",
      "Epoch 22/25\n",
      "469/469 [==============================] - 91s 194ms/step - loss: 0.1362 - accuracy: 0.9589\n",
      "Epoch 23/25\n",
      "469/469 [==============================] - 91s 194ms/step - loss: 0.1316 - accuracy: 0.9594\n",
      "Epoch 24/25\n",
      "469/469 [==============================] - 91s 194ms/step - loss: 0.1305 - accuracy: 0.9607\n",
      "Epoch 25/25\n",
      "469/469 [==============================] - 91s 194ms/step - loss: 0.1267 - accuracy: 0.9615\n",
      "Model: \"sequential_190\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_190 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_114 (Conv2D)         (None, 22, 22, 32)        1600      \n",
      "                                                                 \n",
      " conv2d_115 (Conv2D)         (None, 16, 16, 64)        100416    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  multiple                 0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_166 (Flatten)       (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_462 (Dense)           (None, 512)               2097664   \n",
      "                                                                 \n",
      " dropout_270 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_463 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_271 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_464 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,467,466\n",
      "Trainable params: 2,467,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 87s 92ms/step - loss: 0.3153 - accuracy: 0.9034\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 87s 93ms/step - loss: 0.1371 - accuracy: 0.9611\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 87s 93ms/step - loss: 0.1106 - accuracy: 0.9713\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 87s 93ms/step - loss: 0.0970 - accuracy: 0.9748\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 87s 93ms/step - loss: 0.0958 - accuracy: 0.9769\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 87s 93ms/step - loss: 0.0998 - accuracy: 0.9783\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 87s 93ms/step - loss: 0.0994 - accuracy: 0.9798\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 87s 93ms/step - loss: 0.1036 - accuracy: 0.9808\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 87s 93ms/step - loss: 0.1089 - accuracy: 0.9808\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 87s 93ms/step - loss: 0.1012 - accuracy: 0.9814\n",
      "Model: \"sequential_191\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_191 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_116 (Conv2D)         (None, 22, 22, 32)        1600      \n",
      "                                                                 \n",
      " conv2d_117 (Conv2D)         (None, 16, 16, 64)        100416    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  multiple                 0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_167 (Flatten)       (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_465 (Dense)           (None, 512)               2097664   \n",
      "                                                                 \n",
      " dropout_272 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_466 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_273 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_467 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,467,466\n",
      "Trainable params: 2,467,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "938/938 [==============================] - 84s 89ms/step - loss: 0.3176 - accuracy: 0.9029\n",
      "Epoch 2/25\n",
      "938/938 [==============================] - 84s 89ms/step - loss: 0.1384 - accuracy: 0.9603\n",
      "Epoch 3/25\n",
      "938/938 [==============================] - 84s 89ms/step - loss: 0.1112 - accuracy: 0.9699\n",
      "Epoch 4/25\n",
      "938/938 [==============================] - 84s 89ms/step - loss: 0.0988 - accuracy: 0.9740\n",
      "Epoch 5/25\n",
      "938/938 [==============================] - 84s 89ms/step - loss: 0.1006 - accuracy: 0.9758\n",
      "Epoch 6/25\n",
      "938/938 [==============================] - 84s 89ms/step - loss: 0.1027 - accuracy: 0.9781\n",
      "Epoch 7/25\n",
      "938/938 [==============================] - 84s 89ms/step - loss: 0.1035 - accuracy: 0.9786\n",
      "Epoch 8/25\n",
      "938/938 [==============================] - 84s 89ms/step - loss: 0.1043 - accuracy: 0.9799\n",
      "Epoch 9/25\n",
      "938/938 [==============================] - 84s 89ms/step - loss: 0.1154 - accuracy: 0.9800\n",
      "Epoch 10/25\n",
      "938/938 [==============================] - 84s 89ms/step - loss: 0.1144 - accuracy: 0.9806\n",
      "Epoch 11/25\n",
      "938/938 [==============================] - 84s 89ms/step - loss: 0.1242 - accuracy: 0.9804\n",
      "Epoch 12/25\n",
      "938/938 [==============================] - 84s 89ms/step - loss: 0.1273 - accuracy: 0.9815\n",
      "Epoch 13/25\n",
      "938/938 [==============================] - 84s 89ms/step - loss: 0.1247 - accuracy: 0.9821\n",
      "Epoch 14/25\n",
      "938/938 [==============================] - 84s 89ms/step - loss: 0.1221 - accuracy: 0.9829\n",
      "Epoch 15/25\n",
      "938/938 [==============================] - 84s 89ms/step - loss: 0.1403 - accuracy: 0.9815\n",
      "Epoch 16/25\n",
      "938/938 [==============================] - 84s 89ms/step - loss: 0.1280 - accuracy: 0.9816\n",
      "Epoch 17/25\n",
      "938/938 [==============================] - 84s 89ms/step - loss: 0.1340 - accuracy: 0.9825\n",
      "Epoch 18/25\n",
      "938/938 [==============================] - 84s 90ms/step - loss: 0.1446 - accuracy: 0.9832\n",
      "Epoch 19/25\n",
      "938/938 [==============================] - 84s 90ms/step - loss: 0.1296 - accuracy: 0.9833\n",
      "Epoch 20/25\n",
      "938/938 [==============================] - 84s 89ms/step - loss: 0.1546 - accuracy: 0.9833\n",
      "Epoch 21/25\n",
      "938/938 [==============================] - 83s 89ms/step - loss: 0.1633 - accuracy: 0.9830\n",
      "Epoch 22/25\n",
      "938/938 [==============================] - 83s 89ms/step - loss: 0.1514 - accuracy: 0.9845\n",
      "Epoch 23/25\n",
      "938/938 [==============================] - 83s 89ms/step - loss: 0.1458 - accuracy: 0.9837\n",
      "Epoch 24/25\n",
      "938/938 [==============================] - 83s 89ms/step - loss: 0.1426 - accuracy: 0.9843\n",
      "Epoch 25/25\n",
      "938/938 [==============================] - 83s 89ms/step - loss: 0.1510 - accuracy: 0.9827\n",
      "Model: \"sequential_192\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_192 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_118 (Conv2D)         (None, 22, 22, 32)        1600      \n",
      "                                                                 \n",
      " conv2d_119 (Conv2D)         (None, 16, 16, 64)        100416    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  multiple                 0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_168 (Flatten)       (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_468 (Dense)           (None, 512)               2097664   \n",
      "                                                                 \n",
      " dropout_274 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_469 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_275 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_470 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,467,466\n",
      "Trainable params: 2,467,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "469/469 [==============================] - 71s 151ms/step - loss: 0.3614 - accuracy: 0.8909\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 71s 151ms/step - loss: 0.1219 - accuracy: 0.9634\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 71s 151ms/step - loss: 0.0851 - accuracy: 0.9743\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 71s 151ms/step - loss: 0.0653 - accuracy: 0.9808\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 71s 151ms/step - loss: 0.0563 - accuracy: 0.9835\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 71s 151ms/step - loss: 0.0483 - accuracy: 0.9864\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 71s 151ms/step - loss: 0.0464 - accuracy: 0.9880\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 71s 151ms/step - loss: 0.0425 - accuracy: 0.9888\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 71s 151ms/step - loss: 0.0413 - accuracy: 0.9900\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 71s 151ms/step - loss: 0.0389 - accuracy: 0.9906\n",
      "Model: \"sequential_193\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_193 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_120 (Conv2D)         (None, 22, 22, 32)        1600      \n",
      "                                                                 \n",
      " conv2d_121 (Conv2D)         (None, 16, 16, 64)        100416    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  multiple                 0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_169 (Flatten)       (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_471 (Dense)           (None, 512)               2097664   \n",
      "                                                                 \n",
      " dropout_276 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_472 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_277 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_473 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,467,466\n",
      "Trainable params: 2,467,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "469/469 [==============================] - 68s 144ms/step - loss: 0.3548 - accuracy: 0.8907\n",
      "Epoch 2/25\n",
      "469/469 [==============================] - 68s 144ms/step - loss: 0.1305 - accuracy: 0.9612\n",
      "Epoch 3/25\n",
      "469/469 [==============================] - 68s 144ms/step - loss: 0.0880 - accuracy: 0.9737\n",
      "Epoch 4/25\n",
      "469/469 [==============================] - 68s 144ms/step - loss: 0.0675 - accuracy: 0.9804\n",
      "Epoch 5/25\n",
      "469/469 [==============================] - 68s 144ms/step - loss: 0.0589 - accuracy: 0.9841\n",
      "Epoch 6/25\n",
      "469/469 [==============================] - 68s 144ms/step - loss: 0.0504 - accuracy: 0.9857\n",
      "Epoch 7/25\n",
      "469/469 [==============================] - 68s 144ms/step - loss: 0.0479 - accuracy: 0.9874\n",
      "Epoch 8/25\n",
      "469/469 [==============================] - 68s 144ms/step - loss: 0.0459 - accuracy: 0.9887\n",
      "Epoch 9/25\n",
      "469/469 [==============================] - 67s 144ms/step - loss: 0.0463 - accuracy: 0.9887\n",
      "Epoch 10/25\n",
      "469/469 [==============================] - 68s 144ms/step - loss: 0.0451 - accuracy: 0.9894\n",
      "Epoch 11/25\n",
      "469/469 [==============================] - 68s 145ms/step - loss: 0.0415 - accuracy: 0.9907\n",
      "Epoch 12/25\n",
      "469/469 [==============================] - 68s 144ms/step - loss: 0.0423 - accuracy: 0.9908\n",
      "Epoch 13/25\n",
      "469/469 [==============================] - 68s 144ms/step - loss: 0.0434 - accuracy: 0.9906\n",
      "Epoch 14/25\n",
      "469/469 [==============================] - 68s 144ms/step - loss: 0.0433 - accuracy: 0.9916\n",
      "Epoch 15/25\n",
      "469/469 [==============================] - 67s 144ms/step - loss: 0.0439 - accuracy: 0.9917\n",
      "Epoch 16/25\n",
      "469/469 [==============================] - 68s 144ms/step - loss: 0.0439 - accuracy: 0.9918\n",
      "Epoch 17/25\n",
      "469/469 [==============================] - 67s 144ms/step - loss: 0.0411 - accuracy: 0.9924\n",
      "Epoch 18/25\n",
      "469/469 [==============================] - 67s 144ms/step - loss: 0.0446 - accuracy: 0.9920\n",
      "Epoch 19/25\n",
      "469/469 [==============================] - 67s 144ms/step - loss: 0.0411 - accuracy: 0.9927\n",
      "Epoch 20/25\n",
      "469/469 [==============================] - 68s 144ms/step - loss: 0.0455 - accuracy: 0.9928\n",
      "Epoch 21/25\n",
      "469/469 [==============================] - 67s 144ms/step - loss: 0.0487 - accuracy: 0.9925\n",
      "Epoch 22/25\n",
      "469/469 [==============================] - 67s 144ms/step - loss: 0.0469 - accuracy: 0.9931\n",
      "Epoch 23/25\n",
      "469/469 [==============================] - 67s 144ms/step - loss: 0.0464 - accuracy: 0.9933\n",
      "Epoch 24/25\n",
      "469/469 [==============================] - 67s 144ms/step - loss: 0.0481 - accuracy: 0.9930\n",
      "Epoch 25/25\n",
      "469/469 [==============================] - 67s 144ms/step - loss: 0.0480 - accuracy: 0.9934\n",
      "Model: \"sequential_194\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_194 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_122 (Conv2D)         (None, 22, 22, 32)        1600      \n",
      "                                                                 \n",
      " conv2d_123 (Conv2D)         (None, 16, 16, 64)        100416    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  multiple                 0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_170 (Flatten)       (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_474 (Dense)           (None, 512)               2097664   \n",
      "                                                                 \n",
      " dropout_278 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_475 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_279 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_476 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,467,466\n",
      "Trainable params: 2,467,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 76s 81ms/step - loss: 0.7183 - accuracy: 0.8016\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 76s 81ms/step - loss: 0.2348 - accuracy: 0.9282\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 76s 81ms/step - loss: 0.1580 - accuracy: 0.9511\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 76s 81ms/step - loss: 0.1252 - accuracy: 0.9609\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 76s 81ms/step - loss: 0.1095 - accuracy: 0.9661\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 76s 81ms/step - loss: 0.0984 - accuracy: 0.9700\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 76s 81ms/step - loss: 0.0887 - accuracy: 0.9732\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 76s 81ms/step - loss: 0.0956 - accuracy: 0.9719\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 76s 81ms/step - loss: 0.0802 - accuracy: 0.9765\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 76s 81ms/step - loss: 0.0799 - accuracy: 0.9773\n",
      "Model: \"sequential_195\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_195 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_124 (Conv2D)         (None, 22, 22, 32)        1600      \n",
      "                                                                 \n",
      " conv2d_125 (Conv2D)         (None, 16, 16, 64)        100416    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  multiple                 0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_171 (Flatten)       (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_477 (Dense)           (None, 512)               2097664   \n",
      "                                                                 \n",
      " dropout_280 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_478 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_281 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_479 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,467,466\n",
      "Trainable params: 2,467,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "938/938 [==============================] - 89s 95ms/step - loss: 0.6372 - accuracy: 0.8382\n",
      "Epoch 2/25\n",
      "938/938 [==============================] - 89s 95ms/step - loss: 0.2204 - accuracy: 0.9335\n",
      "Epoch 3/25\n",
      "938/938 [==============================] - 89s 95ms/step - loss: 0.1520 - accuracy: 0.9535\n",
      "Epoch 4/25\n",
      "938/938 [==============================] - 89s 95ms/step - loss: 0.1160 - accuracy: 0.9644\n",
      "Epoch 5/25\n",
      "938/938 [==============================] - 90s 95ms/step - loss: 0.1099 - accuracy: 0.9662\n",
      "Epoch 6/25\n",
      "938/938 [==============================] - 90s 96ms/step - loss: 0.1017 - accuracy: 0.9699\n",
      "Epoch 7/25\n",
      "938/938 [==============================] - 90s 96ms/step - loss: 0.0964 - accuracy: 0.9713\n",
      "Epoch 8/25\n",
      "938/938 [==============================] - 90s 96ms/step - loss: 0.0875 - accuracy: 0.9744\n",
      "Epoch 9/25\n",
      "938/938 [==============================] - 88s 94ms/step - loss: 0.0837 - accuracy: 0.9760\n",
      "Epoch 10/25\n",
      "938/938 [==============================] - 89s 95ms/step - loss: 0.0842 - accuracy: 0.9763\n",
      "Epoch 11/25\n",
      "938/938 [==============================] - 89s 95ms/step - loss: 0.0779 - accuracy: 0.9783\n",
      "Epoch 12/25\n",
      "938/938 [==============================] - 88s 94ms/step - loss: 0.0740 - accuracy: 0.9797\n",
      "Epoch 13/25\n",
      "938/938 [==============================] - 89s 95ms/step - loss: 0.0741 - accuracy: 0.9791\n",
      "Epoch 14/25\n",
      "938/938 [==============================] - 90s 96ms/step - loss: 0.0717 - accuracy: 0.9807\n",
      "Epoch 15/25\n",
      "938/938 [==============================] - 88s 94ms/step - loss: 0.0772 - accuracy: 0.9804\n",
      "Epoch 16/25\n",
      "938/938 [==============================] - 88s 94ms/step - loss: 0.0640 - accuracy: 0.9834\n",
      "Epoch 17/25\n",
      "938/938 [==============================] - 89s 95ms/step - loss: 0.0654 - accuracy: 0.9830\n",
      "Epoch 18/25\n",
      "938/938 [==============================] - 89s 95ms/step - loss: 0.0746 - accuracy: 0.9820\n",
      "Epoch 19/25\n",
      "938/938 [==============================] - 89s 95ms/step - loss: 0.0604 - accuracy: 0.9857\n",
      "Epoch 20/25\n",
      "938/938 [==============================] - 89s 95ms/step - loss: 0.0680 - accuracy: 0.9840\n",
      "Epoch 21/25\n",
      "938/938 [==============================] - 89s 95ms/step - loss: 0.0680 - accuracy: 0.9845\n",
      "Epoch 22/25\n",
      "938/938 [==============================] - 89s 95ms/step - loss: 0.0668 - accuracy: 0.9844\n",
      "Epoch 23/25\n",
      "938/938 [==============================] - 89s 95ms/step - loss: 0.0709 - accuracy: 0.9839\n",
      "Epoch 24/25\n",
      "938/938 [==============================] - 90s 95ms/step - loss: 0.0677 - accuracy: 0.9859\n",
      "Epoch 25/25\n",
      "938/938 [==============================] - 90s 96ms/step - loss: 0.0662 - accuracy: 0.9854\n",
      "Model: \"sequential_196\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_196 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_126 (Conv2D)         (None, 22, 22, 32)        1600      \n",
      "                                                                 \n",
      " conv2d_127 (Conv2D)         (None, 16, 16, 64)        100416    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  multiple                 0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_172 (Flatten)       (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_480 (Dense)           (None, 512)               2097664   \n",
      "                                                                 \n",
      " dropout_282 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_481 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_283 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_482 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,467,466\n",
      "Trainable params: 2,467,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "469/469 [==============================] - 83s 176ms/step - loss: 0.5604 - accuracy: 0.8569\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 83s 178ms/step - loss: 0.1636 - accuracy: 0.9495\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 84s 178ms/step - loss: 0.1119 - accuracy: 0.9656\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 84s 178ms/step - loss: 0.0858 - accuracy: 0.9730\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 83s 178ms/step - loss: 0.0710 - accuracy: 0.9771\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 84s 178ms/step - loss: 0.0589 - accuracy: 0.9813\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 84s 178ms/step - loss: 0.0526 - accuracy: 0.9830\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 83s 178ms/step - loss: 0.0516 - accuracy: 0.9833\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 84s 178ms/step - loss: 0.0463 - accuracy: 0.9854\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 83s 178ms/step - loss: 0.0482 - accuracy: 0.9855\n",
      "Model: \"sequential_197\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_197 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_128 (Conv2D)         (None, 22, 22, 32)        1600      \n",
      "                                                                 \n",
      " conv2d_129 (Conv2D)         (None, 16, 16, 64)        100416    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  multiple                 0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_173 (Flatten)       (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_483 (Dense)           (None, 512)               2097664   \n",
      "                                                                 \n",
      " dropout_284 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_484 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_285 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_485 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,467,466\n",
      "Trainable params: 2,467,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "469/469 [==============================] - 90s 190ms/step - loss: 0.5956 - accuracy: 0.8427\n",
      "Epoch 2/25\n",
      "469/469 [==============================] - 89s 191ms/step - loss: 0.1871 - accuracy: 0.9436\n",
      "Epoch 3/25\n",
      "469/469 [==============================] - 90s 191ms/step - loss: 0.1311 - accuracy: 0.9600\n",
      "Epoch 4/25\n",
      "469/469 [==============================] - 89s 191ms/step - loss: 0.0998 - accuracy: 0.9689\n",
      "Epoch 5/25\n",
      "469/469 [==============================] - 90s 191ms/step - loss: 0.0825 - accuracy: 0.9735\n",
      "Epoch 6/25\n",
      "469/469 [==============================] - 90s 191ms/step - loss: 0.0732 - accuracy: 0.9770\n",
      "Epoch 7/25\n",
      "469/469 [==============================] - 89s 191ms/step - loss: 0.0612 - accuracy: 0.9809\n",
      "Epoch 8/25\n",
      "469/469 [==============================] - 90s 191ms/step - loss: 0.0594 - accuracy: 0.9808\n",
      "Epoch 9/25\n",
      "469/469 [==============================] - 90s 191ms/step - loss: 0.0543 - accuracy: 0.9827\n",
      "Epoch 10/25\n",
      "469/469 [==============================] - 91s 195ms/step - loss: 0.0506 - accuracy: 0.9845\n",
      "Epoch 11/25\n",
      "469/469 [==============================] - 89s 190ms/step - loss: 0.0507 - accuracy: 0.9848\n",
      "Epoch 12/25\n",
      "469/469 [==============================] - 89s 191ms/step - loss: 0.0540 - accuracy: 0.9838\n",
      "Epoch 13/25\n",
      "469/469 [==============================] - 89s 191ms/step - loss: 0.0466 - accuracy: 0.9860\n",
      "Epoch 14/25\n",
      "469/469 [==============================] - 89s 191ms/step - loss: 0.0453 - accuracy: 0.9866\n",
      "Epoch 15/25\n",
      "469/469 [==============================] - 89s 190ms/step - loss: 0.0458 - accuracy: 0.9867\n",
      "Epoch 16/25\n",
      "469/469 [==============================] - 89s 191ms/step - loss: 0.0518 - accuracy: 0.9855\n",
      "Epoch 17/25\n",
      "469/469 [==============================] - 89s 191ms/step - loss: 0.0360 - accuracy: 0.9891\n",
      "Epoch 18/25\n",
      "469/469 [==============================] - 89s 191ms/step - loss: 0.0428 - accuracy: 0.9880\n",
      "Epoch 19/25\n",
      "469/469 [==============================] - 90s 191ms/step - loss: 0.0367 - accuracy: 0.9896\n",
      "Epoch 20/25\n",
      "469/469 [==============================] - 90s 191ms/step - loss: 0.0417 - accuracy: 0.9889\n",
      "Epoch 21/25\n",
      "469/469 [==============================] - 90s 191ms/step - loss: 0.0362 - accuracy: 0.9900\n",
      "Epoch 22/25\n",
      "469/469 [==============================] - 90s 191ms/step - loss: 0.0429 - accuracy: 0.9888\n",
      "Epoch 23/25\n",
      "469/469 [==============================] - 90s 191ms/step - loss: 0.0479 - accuracy: 0.9875\n",
      "Epoch 24/25\n",
      "469/469 [==============================] - 90s 191ms/step - loss: 0.0341 - accuracy: 0.9908\n",
      "Epoch 25/25\n",
      "469/469 [==============================] - 90s 191ms/step - loss: 0.0387 - accuracy: 0.9901\n",
      "Model: \"sequential_198\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_198 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_130 (Conv2D)         (None, 22, 22, 32)        1600      \n",
      "                                                                 \n",
      " conv2d_131 (Conv2D)         (None, 16, 16, 64)        100416    \n",
      "                                                                 \n",
      " global_max_pooling2d (Globa  multiple                 0         \n",
      " lMaxPooling2D)                                                  \n",
      "                                                                 \n",
      " dense_486 (Dense)           (None, 512)               33280     \n",
      "                                                                 \n",
      " dropout_286 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_487 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_287 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_488 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 403,082\n",
      "Trainable params: 403,082\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 82s 86ms/step - loss: 0.4909 - accuracy: 0.8421\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 82s 87ms/step - loss: 0.2031 - accuracy: 0.9392\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 81s 87ms/step - loss: 0.1642 - accuracy: 0.9515\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 82s 87ms/step - loss: 0.1539 - accuracy: 0.9559\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 82s 87ms/step - loss: 0.1482 - accuracy: 0.9595\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 82s 87ms/step - loss: 0.1467 - accuracy: 0.9599\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 82s 87ms/step - loss: 0.1494 - accuracy: 0.9612\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 82s 87ms/step - loss: 0.1496 - accuracy: 0.9621\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 82s 87ms/step - loss: 0.1506 - accuracy: 0.9626\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 82s 87ms/step - loss: 0.1589 - accuracy: 0.9616\n",
      "Model: \"sequential_199\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_199 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_132 (Conv2D)         (None, 22, 22, 32)        1600      \n",
      "                                                                 \n",
      " conv2d_133 (Conv2D)         (None, 16, 16, 64)        100416    \n",
      "                                                                 \n",
      " global_max_pooling2d (Globa  multiple                 0         \n",
      " lMaxPooling2D)                                                  \n",
      "                                                                 \n",
      " dense_489 (Dense)           (None, 512)               33280     \n",
      "                                                                 \n",
      " dropout_288 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_490 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_289 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_491 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 403,082\n",
      "Trainable params: 403,082\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "938/938 [==============================] - 77s 81ms/step - loss: 0.4730 - accuracy: 0.8500\n",
      "Epoch 2/25\n",
      "938/938 [==============================] - 76s 82ms/step - loss: 0.1970 - accuracy: 0.9393\n",
      "Epoch 3/25\n",
      "938/938 [==============================] - 77s 82ms/step - loss: 0.1642 - accuracy: 0.9520\n",
      "Epoch 4/25\n",
      "938/938 [==============================] - 76s 82ms/step - loss: 0.1504 - accuracy: 0.9567\n",
      "Epoch 5/25\n",
      "938/938 [==============================] - 77s 82ms/step - loss: 0.1473 - accuracy: 0.9593\n",
      "Epoch 6/25\n",
      "938/938 [==============================] - 77s 82ms/step - loss: 0.1474 - accuracy: 0.9610\n",
      "Epoch 7/25\n",
      "938/938 [==============================] - 77s 82ms/step - loss: 0.1481 - accuracy: 0.9621\n",
      "Epoch 8/25\n",
      "938/938 [==============================] - 77s 82ms/step - loss: 0.1485 - accuracy: 0.9619\n",
      "Epoch 9/25\n",
      "938/938 [==============================] - 77s 82ms/step - loss: 0.1548 - accuracy: 0.9614\n",
      "Epoch 10/25\n",
      "938/938 [==============================] - 77s 82ms/step - loss: 0.1593 - accuracy: 0.9621\n",
      "Epoch 11/25\n",
      "938/938 [==============================] - 77s 82ms/step - loss: 0.1551 - accuracy: 0.9620\n",
      "Epoch 12/25\n",
      "938/938 [==============================] - 77s 82ms/step - loss: 0.1552 - accuracy: 0.9633\n",
      "Epoch 13/25\n",
      "938/938 [==============================] - 77s 82ms/step - loss: 0.1670 - accuracy: 0.9627\n",
      "Epoch 14/25\n",
      "938/938 [==============================] - 77s 82ms/step - loss: 0.1661 - accuracy: 0.9624\n",
      "Epoch 15/25\n",
      "938/938 [==============================] - 77s 82ms/step - loss: 0.1633 - accuracy: 0.9631\n",
      "Epoch 16/25\n",
      "938/938 [==============================] - 77s 82ms/step - loss: 0.1679 - accuracy: 0.9638\n",
      "Epoch 17/25\n",
      "938/938 [==============================] - 77s 82ms/step - loss: 0.1735 - accuracy: 0.9616\n",
      "Epoch 18/25\n",
      "938/938 [==============================] - 76s 82ms/step - loss: 0.1781 - accuracy: 0.9615\n",
      "Epoch 19/25\n",
      "938/938 [==============================] - 77s 82ms/step - loss: 0.1785 - accuracy: 0.9621\n",
      "Epoch 20/25\n",
      "938/938 [==============================] - 77s 82ms/step - loss: 0.1936 - accuracy: 0.9607\n",
      "Epoch 21/25\n",
      "938/938 [==============================] - 77s 82ms/step - loss: 0.1879 - accuracy: 0.9617\n",
      "Epoch 22/25\n",
      "938/938 [==============================] - 77s 82ms/step - loss: 0.1908 - accuracy: 0.9604\n",
      "Epoch 23/25\n",
      "938/938 [==============================] - 77s 82ms/step - loss: 0.1892 - accuracy: 0.9610\n",
      "Epoch 24/25\n",
      "938/938 [==============================] - 77s 82ms/step - loss: 0.1965 - accuracy: 0.9607\n",
      "Epoch 25/25\n",
      "938/938 [==============================] - 77s 82ms/step - loss: 0.2044 - accuracy: 0.9600\n",
      "Model: \"sequential_200\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_200 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_134 (Conv2D)         (None, 22, 22, 32)        1600      \n",
      "                                                                 \n",
      " conv2d_135 (Conv2D)         (None, 16, 16, 64)        100416    \n",
      "                                                                 \n",
      " global_max_pooling2d (Globa  multiple                 0         \n",
      " lMaxPooling2D)                                                  \n",
      "                                                                 \n",
      " dense_492 (Dense)           (None, 512)               33280     \n",
      "                                                                 \n",
      " dropout_290 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_493 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_291 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_494 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 403,082\n",
      "Trainable params: 403,082\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "469/469 [==============================] - 87s 185ms/step - loss: 0.5972 - accuracy: 0.8063\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 87s 185ms/step - loss: 0.2103 - accuracy: 0.9353\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 87s 185ms/step - loss: 0.1472 - accuracy: 0.9538\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 87s 185ms/step - loss: 0.1203 - accuracy: 0.9625\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 87s 185ms/step - loss: 0.1044 - accuracy: 0.9683\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 87s 185ms/step - loss: 0.0953 - accuracy: 0.9704\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 87s 185ms/step - loss: 0.0889 - accuracy: 0.9728\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 87s 185ms/step - loss: 0.0829 - accuracy: 0.9753\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 87s 185ms/step - loss: 0.0805 - accuracy: 0.9765\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 87s 184ms/step - loss: 0.0760 - accuracy: 0.9771\n",
      "Model: \"sequential_201\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_201 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_136 (Conv2D)         (None, 22, 22, 32)        1600      \n",
      "                                                                 \n",
      " conv2d_137 (Conv2D)         (None, 16, 16, 64)        100416    \n",
      "                                                                 \n",
      " global_max_pooling2d (Globa  multiple                 0         \n",
      " lMaxPooling2D)                                                  \n",
      "                                                                 \n",
      " dense_495 (Dense)           (None, 512)               33280     \n",
      "                                                                 \n",
      " dropout_292 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_496 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_293 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_497 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 403,082\n",
      "Trainable params: 403,082\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "469/469 [==============================] - 83s 176ms/step - loss: 0.5784 - accuracy: 0.8128\n",
      "Epoch 2/25\n",
      "469/469 [==============================] - 83s 177ms/step - loss: 0.2057 - accuracy: 0.9349\n",
      "Epoch 3/25\n",
      "469/469 [==============================] - 83s 177ms/step - loss: 0.1460 - accuracy: 0.9554\n",
      "Epoch 4/25\n",
      "469/469 [==============================] - 83s 177ms/step - loss: 0.1201 - accuracy: 0.9622\n",
      "Epoch 5/25\n",
      "469/469 [==============================] - 83s 177ms/step - loss: 0.1055 - accuracy: 0.9673\n",
      "Epoch 6/25\n",
      "469/469 [==============================] - 83s 177ms/step - loss: 0.0957 - accuracy: 0.9716\n",
      "Epoch 7/25\n",
      "469/469 [==============================] - 83s 177ms/step - loss: 0.0906 - accuracy: 0.9722\n",
      "Epoch 8/25\n",
      "469/469 [==============================] - 83s 177ms/step - loss: 0.0840 - accuracy: 0.9751\n",
      "Epoch 9/25\n",
      "469/469 [==============================] - 83s 177ms/step - loss: 0.0806 - accuracy: 0.9756\n",
      "Epoch 10/25\n",
      "469/469 [==============================] - 83s 177ms/step - loss: 0.0810 - accuracy: 0.9766\n",
      "Epoch 11/25\n",
      "469/469 [==============================] - 83s 177ms/step - loss: 0.0789 - accuracy: 0.9779\n",
      "Epoch 12/25\n",
      "469/469 [==============================] - 83s 177ms/step - loss: 0.0767 - accuracy: 0.9779\n",
      "Epoch 13/25\n",
      "469/469 [==============================] - 83s 177ms/step - loss: 0.0755 - accuracy: 0.9792\n",
      "Epoch 14/25\n",
      "469/469 [==============================] - 83s 177ms/step - loss: 0.0768 - accuracy: 0.9796\n",
      "Epoch 15/25\n",
      "469/469 [==============================] - 83s 177ms/step - loss: 0.0755 - accuracy: 0.9798\n",
      "Epoch 16/25\n",
      "469/469 [==============================] - 83s 177ms/step - loss: 0.0786 - accuracy: 0.9789\n",
      "Epoch 17/25\n",
      "469/469 [==============================] - 83s 177ms/step - loss: 0.0746 - accuracy: 0.9807\n",
      "Epoch 18/25\n",
      "469/469 [==============================] - 83s 177ms/step - loss: 0.0803 - accuracy: 0.9801\n",
      "Epoch 19/25\n",
      "469/469 [==============================] - 83s 177ms/step - loss: 0.0795 - accuracy: 0.9799\n",
      "Epoch 20/25\n",
      "469/469 [==============================] - 83s 177ms/step - loss: 0.0803 - accuracy: 0.9803\n",
      "Epoch 21/25\n",
      "469/469 [==============================] - 83s 177ms/step - loss: 0.0768 - accuracy: 0.9803\n",
      "Epoch 22/25\n",
      "469/469 [==============================] - 83s 177ms/step - loss: 0.0785 - accuracy: 0.9804\n",
      "Epoch 23/25\n",
      "469/469 [==============================] - 83s 177ms/step - loss: 0.0747 - accuracy: 0.9814\n",
      "Epoch 24/25\n",
      "469/469 [==============================] - 83s 177ms/step - loss: 0.0777 - accuracy: 0.9811\n",
      "Epoch 25/25\n",
      "469/469 [==============================] - 83s 177ms/step - loss: 0.0794 - accuracy: 0.9808\n",
      "Model: \"sequential_202\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_202 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_138 (Conv2D)         (None, 22, 22, 32)        1600      \n",
      "                                                                 \n",
      " conv2d_139 (Conv2D)         (None, 16, 16, 64)        100416    \n",
      "                                                                 \n",
      " global_max_pooling2d (Globa  multiple                 0         \n",
      " lMaxPooling2D)                                                  \n",
      "                                                                 \n",
      " dense_498 (Dense)           (None, 512)               33280     \n",
      "                                                                 \n",
      " dropout_294 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_499 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_295 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_500 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 403,082\n",
      "Trainable params: 403,082\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 87s 92ms/step - loss: 0.4366 - accuracy: 0.8598\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 87s 93ms/step - loss: 0.1728 - accuracy: 0.9459\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 87s 92ms/step - loss: 0.1329 - accuracy: 0.9583\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 87s 93ms/step - loss: 0.1149 - accuracy: 0.9640\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 87s 93ms/step - loss: 0.1016 - accuracy: 0.9683\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 87s 93ms/step - loss: 0.0911 - accuracy: 0.9717\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 87s 93ms/step - loss: 0.0875 - accuracy: 0.9729\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 87s 93ms/step - loss: 0.0796 - accuracy: 0.9749\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 87s 93ms/step - loss: 0.0756 - accuracy: 0.9768\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 86s 92ms/step - loss: 0.0706 - accuracy: 0.9779\n",
      "Model: \"sequential_203\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_203 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_140 (Conv2D)         (None, 22, 22, 32)        1600      \n",
      "                                                                 \n",
      " conv2d_141 (Conv2D)         (None, 16, 16, 64)        100416    \n",
      "                                                                 \n",
      " global_max_pooling2d (Globa  multiple                 0         \n",
      " lMaxPooling2D)                                                  \n",
      "                                                                 \n",
      " dense_501 (Dense)           (None, 512)               33280     \n",
      "                                                                 \n",
      " dropout_296 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_502 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_297 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_503 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 403,082\n",
      "Trainable params: 403,082\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "938/938 [==============================] - 84s 89ms/step - loss: 0.4339 - accuracy: 0.8594\n",
      "Epoch 2/25\n",
      "938/938 [==============================] - 84s 90ms/step - loss: 0.1763 - accuracy: 0.9453\n",
      "Epoch 3/25\n",
      "938/938 [==============================] - 84s 90ms/step - loss: 0.1341 - accuracy: 0.9586\n",
      "Epoch 4/25\n",
      "938/938 [==============================] - 84s 90ms/step - loss: 0.1168 - accuracy: 0.9640\n",
      "Epoch 5/25\n",
      "938/938 [==============================] - 84s 90ms/step - loss: 0.0992 - accuracy: 0.9689\n",
      "Epoch 6/25\n",
      "938/938 [==============================] - 84s 90ms/step - loss: 0.0918 - accuracy: 0.9716\n",
      "Epoch 7/25\n",
      "938/938 [==============================] - 84s 89ms/step - loss: 0.0858 - accuracy: 0.9729\n",
      "Epoch 8/25\n",
      "938/938 [==============================] - 84s 89ms/step - loss: 0.0794 - accuracy: 0.9754\n",
      "Epoch 9/25\n",
      "938/938 [==============================] - 84s 90ms/step - loss: 0.0691 - accuracy: 0.9783\n",
      "Epoch 10/25\n",
      "938/938 [==============================] - 84s 89ms/step - loss: 0.0690 - accuracy: 0.9786\n",
      "Epoch 11/25\n",
      "938/938 [==============================] - 84s 90ms/step - loss: 0.0643 - accuracy: 0.9804\n",
      "Epoch 12/25\n",
      "938/938 [==============================] - 84s 89ms/step - loss: 0.0665 - accuracy: 0.9786\n",
      "Epoch 13/25\n",
      "938/938 [==============================] - 84s 89ms/step - loss: 0.0629 - accuracy: 0.9805\n",
      "Epoch 14/25\n",
      "938/938 [==============================] - 84s 89ms/step - loss: 0.0631 - accuracy: 0.9805\n",
      "Epoch 15/25\n",
      "938/938 [==============================] - 84s 89ms/step - loss: 0.0572 - accuracy: 0.9825\n",
      "Epoch 16/25\n",
      "938/938 [==============================] - 84s 89ms/step - loss: 0.0563 - accuracy: 0.9833\n",
      "Epoch 17/25\n",
      "938/938 [==============================] - 84s 90ms/step - loss: 0.0568 - accuracy: 0.9828\n",
      "Epoch 18/25\n",
      "938/938 [==============================] - 84s 89ms/step - loss: 0.0538 - accuracy: 0.9841\n",
      "Epoch 19/25\n",
      "938/938 [==============================] - 84s 89ms/step - loss: 0.0557 - accuracy: 0.9837\n",
      "Epoch 20/25\n",
      "938/938 [==============================] - 84s 90ms/step - loss: 0.0501 - accuracy: 0.9844\n",
      "Epoch 21/25\n",
      "938/938 [==============================] - 84s 90ms/step - loss: 0.0563 - accuracy: 0.9837\n",
      "Epoch 22/25\n",
      "938/938 [==============================] - 84s 89ms/step - loss: 0.0485 - accuracy: 0.9851\n",
      "Epoch 23/25\n",
      "938/938 [==============================] - 84s 90ms/step - loss: 0.0531 - accuracy: 0.9843\n",
      "Epoch 24/25\n",
      "938/938 [==============================] - 84s 90ms/step - loss: 0.0478 - accuracy: 0.9857\n",
      "Epoch 25/25\n",
      "938/938 [==============================] - 84s 89ms/step - loss: 0.0485 - accuracy: 0.9862\n",
      "Model: \"sequential_204\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_204 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_142 (Conv2D)         (None, 22, 22, 32)        1600      \n",
      "                                                                 \n",
      " conv2d_143 (Conv2D)         (None, 16, 16, 64)        100416    \n",
      "                                                                 \n",
      " global_max_pooling2d (Globa  multiple                 0         \n",
      " lMaxPooling2D)                                                  \n",
      "                                                                 \n",
      " dense_504 (Dense)           (None, 512)               33280     \n",
      "                                                                 \n",
      " dropout_298 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_505 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_299 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_506 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 403,082\n",
      "Trainable params: 403,082\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "469/469 [==============================] - 75s 159ms/step - loss: 0.4355 - accuracy: 0.8574\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 75s 159ms/step - loss: 0.1619 - accuracy: 0.9508\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 75s 159ms/step - loss: 0.1176 - accuracy: 0.9636\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 75s 159ms/step - loss: 0.0971 - accuracy: 0.9692\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 75s 160ms/step - loss: 0.0831 - accuracy: 0.9742\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 75s 159ms/step - loss: 0.0720 - accuracy: 0.9767\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 75s 159ms/step - loss: 0.0655 - accuracy: 0.9794\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 75s 159ms/step - loss: 0.0614 - accuracy: 0.9799\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 75s 159ms/step - loss: 0.0560 - accuracy: 0.9819\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 75s 159ms/step - loss: 0.0506 - accuracy: 0.9833\n",
      "Model: \"sequential_205\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_205 (Rescaling)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_144 (Conv2D)         (None, 22, 22, 32)        1600      \n",
      "                                                                 \n",
      " conv2d_145 (Conv2D)         (None, 16, 16, 64)        100416    \n",
      "                                                                 \n",
      " global_max_pooling2d (Globa  multiple                 0         \n",
      " lMaxPooling2D)                                                  \n",
      "                                                                 \n",
      " dense_507 (Dense)           (None, 512)               33280     \n",
      "                                                                 \n",
      " dropout_300 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_508 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_301 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_509 (Dense)           (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 403,082\n",
      "Trainable params: 403,082\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "469/469 [==============================] - 73s 154ms/step - loss: 0.4142 - accuracy: 0.8658\n",
      "Epoch 2/25\n",
      "469/469 [==============================] - 73s 155ms/step - loss: 0.1569 - accuracy: 0.9518\n",
      "Epoch 3/25\n",
      "469/469 [==============================] - 73s 155ms/step - loss: 0.1160 - accuracy: 0.9639\n",
      "Epoch 4/25\n",
      "469/469 [==============================] - 73s 155ms/step - loss: 0.0934 - accuracy: 0.9700\n",
      "Epoch 5/25\n",
      "469/469 [==============================] - 73s 155ms/step - loss: 0.0830 - accuracy: 0.9738\n",
      "Epoch 6/25\n",
      "469/469 [==============================] - 73s 155ms/step - loss: 0.0703 - accuracy: 0.9770\n",
      "Epoch 7/25\n",
      "469/469 [==============================] - 73s 155ms/step - loss: 0.0657 - accuracy: 0.9784\n",
      "Epoch 8/25\n",
      "469/469 [==============================] - 73s 155ms/step - loss: 0.0592 - accuracy: 0.9810\n",
      "Epoch 9/25\n",
      "469/469 [==============================] - 73s 155ms/step - loss: 0.0521 - accuracy: 0.9833\n",
      "Epoch 10/25\n",
      "469/469 [==============================] - 73s 155ms/step - loss: 0.0493 - accuracy: 0.9845\n",
      "Epoch 11/25\n",
      "469/469 [==============================] - 73s 155ms/step - loss: 0.0471 - accuracy: 0.9844\n",
      "Epoch 12/25\n",
      "469/469 [==============================] - 73s 155ms/step - loss: 0.0442 - accuracy: 0.9856\n",
      "Epoch 13/25\n",
      "469/469 [==============================] - 73s 155ms/step - loss: 0.0441 - accuracy: 0.9861\n",
      "Epoch 14/25\n",
      "469/469 [==============================] - 73s 155ms/step - loss: 0.0395 - accuracy: 0.9869\n",
      "Epoch 15/25\n",
      "469/469 [==============================] - 73s 155ms/step - loss: 0.0386 - accuracy: 0.9871\n",
      "Epoch 16/25\n",
      "469/469 [==============================] - 73s 155ms/step - loss: 0.0376 - accuracy: 0.9874\n",
      "Epoch 17/25\n",
      "469/469 [==============================] - 73s 155ms/step - loss: 0.0354 - accuracy: 0.9887\n",
      "Epoch 18/25\n",
      "469/469 [==============================] - 73s 155ms/step - loss: 0.0354 - accuracy: 0.9886\n",
      "Epoch 19/25\n",
      "469/469 [==============================] - 73s 155ms/step - loss: 0.0332 - accuracy: 0.9900\n",
      "Epoch 20/25\n",
      "469/469 [==============================] - 73s 155ms/step - loss: 0.0346 - accuracy: 0.9888\n",
      "Epoch 21/25\n",
      "469/469 [==============================] - 73s 155ms/step - loss: 0.0316 - accuracy: 0.9900\n",
      "Epoch 22/25\n",
      "469/469 [==============================] - 73s 155ms/step - loss: 0.0280 - accuracy: 0.9910\n",
      "Epoch 23/25\n",
      "469/469 [==============================] - 73s 156ms/step - loss: 0.0295 - accuracy: 0.9909\n",
      "Epoch 24/25\n",
      "469/469 [==============================] - 73s 155ms/step - loss: 0.0294 - accuracy: 0.9907\n",
      "Epoch 25/25\n",
      "469/469 [==============================] - 73s 155ms/step - loss: 0.0325 - accuracy: 0.9902\n"
     ]
    }
   ],
   "source": [
    "build_model_params = {\n",
    "    'n_filters': [[16], [32, 64]],\n",
    "    'kernel_size': [(5, 5), (7, 7)],\n",
    "    'pooling': [None, MaxPooling2D(pool_size=(2, 2)), GlobalMaxPooling2D()],\n",
    "    'optimizer': [RMSprop(), Adam()]\n",
    "}\n",
    "fit_and_predict_params = {\n",
    "    'batch_size': [64, 128],\n",
    "    'epochs': [10, 25]\n",
    "}\n",
    "\n",
    "keys, values = zip(*build_model_params.items())\n",
    "build_model_kwargses = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "keys, values = zip(*fit_and_predict_params.items())\n",
    "fit_and_predict_kwargses = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "\n",
    "cnn_results = []\n",
    "for build_model_kwargs in build_model_kwargses:\n",
    "    for fit_and_predict_kwargs in fit_and_predict_kwargses:\n",
    "        model = build_cnn_model(**build_model_kwargs)\n",
    "        acc, cm = fit_and_predict(model, **fit_and_predict_kwargs)\n",
    "        cnn_results.append((build_model_kwargs, fit_and_predict_kwargs, acc, cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "|accuracy|n_filters|kernel_size|pooling|optimizer|batch_size|epochs|\n",
       "|--------|---------|-----------|-------|---------|----------|------|\n",
       "|87.78%|[16]|(5, 5)|<class 'NoneType'>|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|64|10|\n",
       "|86.74%|[16]|(5, 5)|<class 'NoneType'>|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|64|25|\n",
       "|90.10%|[16]|(5, 5)|<class 'NoneType'>|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|128|10|\n",
       "|89.41%|[16]|(5, 5)|<class 'NoneType'>|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|128|25|\n",
       "|90.56%|[16]|(5, 5)|<class 'NoneType'>|<class 'keras.optimizer_v2.adam.Adam'>|64|10|\n",
       "|90.88%|[16]|(5, 5)|<class 'NoneType'>|<class 'keras.optimizer_v2.adam.Adam'>|64|25|\n",
       "|90.90%|[16]|(5, 5)|<class 'NoneType'>|<class 'keras.optimizer_v2.adam.Adam'>|128|10|\n",
       "|90.69%|[16]|(5, 5)|<class 'NoneType'>|<class 'keras.optimizer_v2.adam.Adam'>|128|25|\n",
       "|93.65%|[16]|(5, 5)|<class 'keras.layers.pooling.MaxPooling2D'>|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|64|10|\n",
       "|93.44%|[16]|(5, 5)|<class 'keras.layers.pooling.MaxPooling2D'>|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|64|25|\n",
       "|94.15%|[16]|(5, 5)|<class 'keras.layers.pooling.MaxPooling2D'>|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|128|10|\n",
       "|94.01%|[16]|(5, 5)|<class 'keras.layers.pooling.MaxPooling2D'>|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|128|25|\n",
       "|93.37%|[16]|(5, 5)|<class 'keras.layers.pooling.MaxPooling2D'>|<class 'keras.optimizer_v2.adam.Adam'>|64|10|\n",
       "|94.56%|[16]|(5, 5)|<class 'keras.layers.pooling.MaxPooling2D'>|<class 'keras.optimizer_v2.adam.Adam'>|64|25|\n",
       "|93.23%|[16]|(5, 5)|<class 'keras.layers.pooling.MaxPooling2D'>|<class 'keras.optimizer_v2.adam.Adam'>|128|10|\n",
       "|94.06%|[16]|(5, 5)|<class 'keras.layers.pooling.MaxPooling2D'>|<class 'keras.optimizer_v2.adam.Adam'>|128|25|\n",
       "|59.23%|[16]|(5, 5)|<class 'keras.layers.pooling.GlobalMaxPooling2D'>|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|64|10|\n",
       "|62.19%|[16]|(5, 5)|<class 'keras.layers.pooling.GlobalMaxPooling2D'>|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|64|25|\n",
       "|57.19%|[16]|(5, 5)|<class 'keras.layers.pooling.GlobalMaxPooling2D'>|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|128|10|\n",
       "|59.71%|[16]|(5, 5)|<class 'keras.layers.pooling.GlobalMaxPooling2D'>|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|128|25|\n",
       "|60.18%|[16]|(5, 5)|<class 'keras.layers.pooling.GlobalMaxPooling2D'>|<class 'keras.optimizer_v2.adam.Adam'>|64|10|\n",
       "|63.41%|[16]|(5, 5)|<class 'keras.layers.pooling.GlobalMaxPooling2D'>|<class 'keras.optimizer_v2.adam.Adam'>|64|25|\n",
       "|57.30%|[16]|(5, 5)|<class 'keras.layers.pooling.GlobalMaxPooling2D'>|<class 'keras.optimizer_v2.adam.Adam'>|128|10|\n",
       "|61.76%|[16]|(5, 5)|<class 'keras.layers.pooling.GlobalMaxPooling2D'>|<class 'keras.optimizer_v2.adam.Adam'>|128|25|\n",
       "|88.49%|[16]|(7, 7)|<class 'NoneType'>|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|64|10|\n",
       "|87.67%|[16]|(7, 7)|<class 'NoneType'>|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|64|25|\n",
       "|90.32%|[16]|(7, 7)|<class 'NoneType'>|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|128|10|\n",
       "|89.91%|[16]|(7, 7)|<class 'NoneType'>|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|128|25|\n",
       "|90.36%|[16]|(7, 7)|<class 'NoneType'>|<class 'keras.optimizer_v2.adam.Adam'>|64|10|\n",
       "|91.05%|[16]|(7, 7)|<class 'NoneType'>|<class 'keras.optimizer_v2.adam.Adam'>|64|25|\n",
       "|91.43%|[16]|(7, 7)|<class 'NoneType'>|<class 'keras.optimizer_v2.adam.Adam'>|128|10|\n",
       "|91.23%|[16]|(7, 7)|<class 'NoneType'>|<class 'keras.optimizer_v2.adam.Adam'>|128|25|\n",
       "|93.58%|[16]|(7, 7)|<class 'keras.layers.pooling.MaxPooling2D'>|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|64|10|\n",
       "|93.62%|[16]|(7, 7)|<class 'keras.layers.pooling.MaxPooling2D'>|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|64|25|\n",
       "|93.84%|[16]|(7, 7)|<class 'keras.layers.pooling.MaxPooling2D'>|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|128|10|\n",
       "|93.77%|[16]|(7, 7)|<class 'keras.layers.pooling.MaxPooling2D'>|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|128|25|\n",
       "|94.00%|[16]|(7, 7)|<class 'keras.layers.pooling.MaxPooling2D'>|<class 'keras.optimizer_v2.adam.Adam'>|64|10|\n",
       "|94.36%|[16]|(7, 7)|<class 'keras.layers.pooling.MaxPooling2D'>|<class 'keras.optimizer_v2.adam.Adam'>|64|25|\n",
       "|94.09%|[16]|(7, 7)|<class 'keras.layers.pooling.MaxPooling2D'>|<class 'keras.optimizer_v2.adam.Adam'>|128|10|\n",
       "|94.75%|[16]|(7, 7)|<class 'keras.layers.pooling.MaxPooling2D'>|<class 'keras.optimizer_v2.adam.Adam'>|128|25|\n",
       "|68.10%|[16]|(7, 7)|<class 'keras.layers.pooling.GlobalMaxPooling2D'>|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|64|10|\n",
       "|70.62%|[16]|(7, 7)|<class 'keras.layers.pooling.GlobalMaxPooling2D'>|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|64|25|\n",
       "|66.11%|[16]|(7, 7)|<class 'keras.layers.pooling.GlobalMaxPooling2D'>|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|128|10|\n",
       "|71.82%|[16]|(7, 7)|<class 'keras.layers.pooling.GlobalMaxPooling2D'>|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|128|25|\n",
       "|67.95%|[16]|(7, 7)|<class 'keras.layers.pooling.GlobalMaxPooling2D'>|<class 'keras.optimizer_v2.adam.Adam'>|64|10|\n",
       "|72.02%|[16]|(7, 7)|<class 'keras.layers.pooling.GlobalMaxPooling2D'>|<class 'keras.optimizer_v2.adam.Adam'>|64|25|\n",
       "|69.55%|[16]|(7, 7)|<class 'keras.layers.pooling.GlobalMaxPooling2D'>|<class 'keras.optimizer_v2.adam.Adam'>|128|10|\n",
       "|70.80%|[16]|(7, 7)|<class 'keras.layers.pooling.GlobalMaxPooling2D'>|<class 'keras.optimizer_v2.adam.Adam'>|128|25|\n",
       "|85.05%|[32, 64]|(5, 5)|<class 'NoneType'>|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|64|10|\n",
       "|85.07%|[32, 64]|(5, 5)|<class 'NoneType'>|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|64|25|\n",
       "|90.02%|[32, 64]|(5, 5)|<class 'NoneType'>|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|128|10|\n",
       "|89.18%|[32, 64]|(5, 5)|<class 'NoneType'>|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|128|25|\n",
       "|87.01%|[32, 64]|(5, 5)|<class 'NoneType'>|<class 'keras.optimizer_v2.adam.Adam'>|64|10|\n",
       "|89.06%|[32, 64]|(5, 5)|<class 'NoneType'>|<class 'keras.optimizer_v2.adam.Adam'>|64|25|\n",
       "|88.33%|[32, 64]|(5, 5)|<class 'NoneType'>|<class 'keras.optimizer_v2.adam.Adam'>|128|10|\n",
       "|89.57%|[32, 64]|(5, 5)|<class 'NoneType'>|<class 'keras.optimizer_v2.adam.Adam'>|128|25|\n",
       "|93.81%|[32, 64]|(5, 5)|<class 'keras.layers.pooling.MaxPooling2D'>|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|64|10|\n",
       "|94.55%|[32, 64]|(5, 5)|<class 'keras.layers.pooling.MaxPooling2D'>|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|64|25|\n",
       "|94.32%|[32, 64]|(5, 5)|<class 'keras.layers.pooling.MaxPooling2D'>|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|128|10|\n",
       "|94.92%|[32, 64]|(5, 5)|<class 'keras.layers.pooling.MaxPooling2D'>|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|128|25|\n",
       "|93.08%|[32, 64]|(5, 5)|<class 'keras.layers.pooling.MaxPooling2D'>|<class 'keras.optimizer_v2.adam.Adam'>|64|10|\n",
       "|94.65%|[32, 64]|(5, 5)|<class 'keras.layers.pooling.MaxPooling2D'>|<class 'keras.optimizer_v2.adam.Adam'>|64|25|\n",
       "|94.32%|[32, 64]|(5, 5)|<class 'keras.layers.pooling.MaxPooling2D'>|<class 'keras.optimizer_v2.adam.Adam'>|128|10|\n",
       "|94.63%|[32, 64]|(5, 5)|<class 'keras.layers.pooling.MaxPooling2D'>|<class 'keras.optimizer_v2.adam.Adam'>|128|25|\n",
       "|88.01%|[32, 64]|(5, 5)|<class 'keras.layers.pooling.GlobalMaxPooling2D'>|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|64|10|\n",
       "|81.77%|[32, 64]|(5, 5)|<class 'keras.layers.pooling.GlobalMaxPooling2D'>|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|64|25|\n",
       "|88.00%|[32, 64]|(5, 5)|<class 'keras.layers.pooling.GlobalMaxPooling2D'>|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|128|10|\n",
       "|90.23%|[32, 64]|(5, 5)|<class 'keras.layers.pooling.GlobalMaxPooling2D'>|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|128|25|\n",
       "|88.96%|[32, 64]|(5, 5)|<class 'keras.layers.pooling.GlobalMaxPooling2D'>|<class 'keras.optimizer_v2.adam.Adam'>|64|10|\n",
       "|90.81%|[32, 64]|(5, 5)|<class 'keras.layers.pooling.GlobalMaxPooling2D'>|<class 'keras.optimizer_v2.adam.Adam'>|64|25|\n",
       "|90.17%|[32, 64]|(5, 5)|<class 'keras.layers.pooling.GlobalMaxPooling2D'>|<class 'keras.optimizer_v2.adam.Adam'>|128|10|\n",
       "|91.38%|[32, 64]|(5, 5)|<class 'keras.layers.pooling.GlobalMaxPooling2D'>|<class 'keras.optimizer_v2.adam.Adam'>|128|25|\n",
       "|81.82%|[32, 64]|(7, 7)|<class 'NoneType'>|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|64|10|\n",
       "|78.74%|[32, 64]|(7, 7)|<class 'NoneType'>|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|64|25|\n",
       "|90.61%|[32, 64]|(7, 7)|<class 'NoneType'>|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|128|10|\n",
       "|89.39%|[32, 64]|(7, 7)|<class 'NoneType'>|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|128|25|\n",
       "|83.34%|[32, 64]|(7, 7)|<class 'NoneType'>|<class 'keras.optimizer_v2.adam.Adam'>|64|10|\n",
       "|88.34%|[32, 64]|(7, 7)|<class 'NoneType'>|<class 'keras.optimizer_v2.adam.Adam'>|64|25|\n",
       "|89.14%|[32, 64]|(7, 7)|<class 'NoneType'>|<class 'keras.optimizer_v2.adam.Adam'>|128|10|\n",
       "|89.24%|[32, 64]|(7, 7)|<class 'NoneType'>|<class 'keras.optimizer_v2.adam.Adam'>|128|25|\n",
       "|93.23%|[32, 64]|(7, 7)|<class 'keras.layers.pooling.MaxPooling2D'>|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|64|10|\n",
       "|93.00%|[32, 64]|(7, 7)|<class 'keras.layers.pooling.MaxPooling2D'>|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|64|25|\n",
       "|93.60%|[32, 64]|(7, 7)|<class 'keras.layers.pooling.MaxPooling2D'>|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|128|10|\n",
       "|94.07%|[32, 64]|(7, 7)|<class 'keras.layers.pooling.MaxPooling2D'>|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|128|25|\n",
       "|93.75%|[32, 64]|(7, 7)|<class 'keras.layers.pooling.MaxPooling2D'>|<class 'keras.optimizer_v2.adam.Adam'>|64|10|\n",
       "|92.72%|[32, 64]|(7, 7)|<class 'keras.layers.pooling.MaxPooling2D'>|<class 'keras.optimizer_v2.adam.Adam'>|64|25|\n",
       "|93.78%|[32, 64]|(7, 7)|<class 'keras.layers.pooling.MaxPooling2D'>|<class 'keras.optimizer_v2.adam.Adam'>|128|10|\n",
       "|93.99%|[32, 64]|(7, 7)|<class 'keras.layers.pooling.MaxPooling2D'>|<class 'keras.optimizer_v2.adam.Adam'>|128|25|\n",
       "|91.22%|[32, 64]|(7, 7)|<class 'keras.layers.pooling.GlobalMaxPooling2D'>|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|64|10|\n",
       "|91.11%|[32, 64]|(7, 7)|<class 'keras.layers.pooling.GlobalMaxPooling2D'>|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|64|25|\n",
       "|92.01%|[32, 64]|(7, 7)|<class 'keras.layers.pooling.GlobalMaxPooling2D'>|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|128|10|\n",
       "|91.51%|[32, 64]|(7, 7)|<class 'keras.layers.pooling.GlobalMaxPooling2D'>|<class 'keras.optimizer_v2.rmsprop.RMSprop'>|128|25|\n",
       "|92.46%|[32, 64]|(7, 7)|<class 'keras.layers.pooling.GlobalMaxPooling2D'>|<class 'keras.optimizer_v2.adam.Adam'>|64|10|\n",
       "|92.82%|[32, 64]|(7, 7)|<class 'keras.layers.pooling.GlobalMaxPooling2D'>|<class 'keras.optimizer_v2.adam.Adam'>|64|25|\n",
       "|92.82%|[32, 64]|(7, 7)|<class 'keras.layers.pooling.GlobalMaxPooling2D'>|<class 'keras.optimizer_v2.adam.Adam'>|128|10|\n",
       "|93.71%|[32, 64]|(7, 7)|<class 'keras.layers.pooling.GlobalMaxPooling2D'>|<class 'keras.optimizer_v2.adam.Adam'>|128|25|\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_acc = 0\n",
    "md =  \"|accuracy|n_filters|kernel_size|pooling|optimizer|batch_size|epochs|\\n\"\n",
    "md += \"|--------|---------|-----------|-------|---------|----------|------|\\n\"\n",
    "for result in cnn_results:\n",
    "    acc = result[2]\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_build_model_params = result[0]\n",
    "        best_fit_and_predict_params = result[1]\n",
    "        best_cm = result[3]\n",
    "    md += f\"|{acc:.2f}%|{result[0]['n_filters']}|{result[0]['kernel_size']}|{type(result[0]['pooling'])}|{type(result[0]['optimizer'])}|{result[1]['batch_size']}|{result[1]['epochs']}|\\n\"\n",
    "display(Markdown(md))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best accuracy: 94.92% - {'n_filters': [32, 64], 'kernel_size': (5, 5), 'pooling': <keras.layers.pooling.MaxPooling2D object at 0x000001CC613F2080>, 'optimizer': <keras.optimizer_v2.rmsprop.RMSprop object at 0x000001CC624C4370>} {'batch_size': 128, 'epochs': 25}\n",
      "\n",
      "Best Confusion Matrix:\n",
      "[[958   1   3   2  10   6   2   9   7   2]\n",
      " [  2 932  12   1  13   2  22   4   8   4]\n",
      " [ 10   2 914  37   5   7   7   8   4   6]\n",
      " [  0   0   6 983   0   6   5   0   0   0]\n",
      " [ 16   2   5  14 930   2   7   3  16   5]\n",
      " [  2   2  24   5   3 942   6   3  10   3]\n",
      " [  4   7  16   2   4   2 955   2   7   1]\n",
      " [  5   3   4   1  10   1  11 954   6   5]\n",
      " [  2   3   3   8   6   7   3   2 965   1]\n",
      " [  6   2   8   2   7   0   8   2   6 959]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nBest accuracy: {best_acc:.2f}% - {best_build_model_params} {best_fit_and_predict_params}\\n\")\n",
    "print(\"Best Confusion Matrix:\")\n",
    "print(best_cm)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "32a282a87d2449fec7e9b04fa9cf8e162c47c13b3b2e5daacb2cbdfd25191a73"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('.env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
